# -*- coding: utf-8 -*-
"""Saturation experiments.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A-hkExlVJX16NNC3MetqNTJ-IJdjQwzr
"""

""" 
# Plot settings

"""

# %matplotlib inline
import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import LogNorm
import seaborn as sns
import re
import matplotlib.ticker as ticker
import matplotlib as mpl
import omegaconf
from matplotlib.ticker import PercentFormatter, FormatStrFormatter
custom_RS_18_RF = [3, 5, 7, 9, 11, 13, 17, 21, 25, 29, 37, 45, 53, 61, 77, 109, 133]

pytorch_RS_18_RF = [11, 19, 27, 35, 43, 51, 67, 83, 99, 115, 147, 179, 211, 243, 307, 371, 435]

resnets_rfs = [108, 110, 213, 318, 423, 1415, 1920, 3100]

vgg_rfs = [180, 181, 359, 537, 715]

vgg_inter_layers = ["features.4", "features.8", "features.11", "features.15",
                    "features.18", "features.21", "features.24", "features.28",
                    "features.31", "features.34", "features.37", "features.40",
                    "features.43", "features.46", "features.49"]

resnet_intermediate_layers = ["layer1.0.conv1", "layer1.0.conv2", "layer1.0.conv3", "layer1.0.shortcut.0",
                              "layer1.1.conv1", "layer1.1.conv2", "layer1.1.conv3", "layer1.2.conv1", "layer1.2.conv2",
                              "layer1.2.conv3", "layer2.0.conv1", "layer2.0.conv2", "layer2.0.conv3",
                              "layer2.0.shortcut.0", "layer2.1.conv1", "layer2.1.conv2", "layer2.1.conv3",
                              "layer2.2.conv1", "layer2.2.conv2", "layer2.2.conv3", "layer2.3.conv1", "layer2.3.conv2",
                              "layer2.3.conv3", "layer3.0.conv1", "layer3.0.conv2", "layer3.0.conv3",
                              "layer3.0.shortcut.0", "layer3.1.conv1", "layer3.1.conv2", "layer3.1.conv3",
                              "layer3.2.conv1", "layer3.2.conv2", "layer3.2.conv3", "layer3.3.conv1", "layer3.3.conv2",
                              "layer3.3.conv3", "layer3.4.conv1", "layer3.4.conv2", "layer3.4.conv3", "layer3.5.conv1",
                              "layer3.5.conv2", "layer3.5.conv3", "layer4.0.conv1", "layer4.0.conv2", "layer4.0.conv3",
                              "layer4.0.shortcut.0", "layer4.1.conv1", "layer4.1.conv2", "layer4.1.conv3",
                              "layer4.2.conv1", "layer4.2.conv2", "layer4.2.conv3"]
# in_block_layers_index= [resnet_intermediate_layers.index(l) for l in resnet_intermediate_layers if "conv1" in l or "conv2" in l]
# out_of_block_layer_index=[resnet_intermediate_layers.index(l) for l in resnet_intermediate_layers if "conv3" in l or "shortcut" in l]
resnet50_ticks = np.array(range(49))
resnet18_ticks = np.array(range(17))


def combine_mean_std(mean_and_std):
    mean, std = mean_and_std
    return "{} $\pm$ {}".format(mean, std)


def get_accuracy(el_string):
    new_string = el_string.split(" ")[0]
    list_of_string = re.findall("\d+\.\d+", el_string)
    return float(list_of_string[0])


# fs = 12
# fig_size = (6, 5)
# sns.reset_orig()
# sns.reset_defaults()
# matplotlib.rc_file_defaults()

in_block_layers_index = [1, 2, 4, 5, 7, 8, 10, 11, 13, 14, 16, 17, 19, 20, 22, 23, 25, 26, 28, 29, 31, 32, 34, 35, 37, 38, 40,
                   41, 43, 44, 46, 47]
out_of_block_layer_index= [0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48]

in_block_layers = [1, 2, 4, 5, 7, 8, 10, 11, 13, 14, 16, 17, 19, 20, 22, 23, 25, 26, 28, 29, 31, 32, 34, 35, 37, 38, 40,
                         41, 43, 44, 46, 47]
out_block_layers = [0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48]

resnets_rfs_values = [108, 110, 213, 318, 423, 538, 645, 752, 859, 1415, 1920, 3100]

resnet_rfs_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]

resnets_rfs = dict(zip(resnet_rfs_keys, resnets_rfs_values))

small_resnets_rfs_values = [30, 39, 129, 174, 309, 399, 487, 568]
small_resnets_rfs_keys = [3, 4, 5, 6, 7, 8, 9, 10]

small_resnets_rfs = dict(zip(small_resnets_rfs_keys, small_resnets_rfs_values))

vgg_rfs = [180, 181, 359, 537, 715]

# plt.rcParams.update({
#     "axes.linewidth": 0.5,
#     'axes.edgecolor': 'black',
#     "grid.linewidth": 0.4,
#     "lines.linewidth": 1,
#     'xtick.bottom': True,
#     'xtick.color': 'black',
#     "xtick.direction": "out",
#     "xtick.major.size": 3,
#     "xtick.major.width": 0.5,
#     "xtick.minor.size": 1.5,
#     "xtick.minor.width": 0.5,
#     'ytick.left': True,
#     'ytick.color': 'black',
#     "ytick.major.size": 3,
#     "ytick.major.width": 0.5,
#     "ytick.minor.size": 1.5,
#     "ytick.minor.width": 0.5,
#     "figure.figsize": [3.3, 2.5],
#     'axes.labelsize': 'xx-large',
#     'axes.titlesize': 'xx-large',
#     "text.usetex": True,
#     "font.family": "serif",
#     # "text.tex.preamble": r"\usepackage{bm} \usepackage{amsmath}",
# })

fs = 12
# fig_size = (3, 2.5) # For the large_input_experiments_only_sgd_paper()
fig_size = (4
            , 2.5) # For the vgg19_cifar10_saturation()

legends_multiplier = 0.5
# labels_multiplier = 1 # For the large_input_experiments_only_sgd_paper()
# ticks_multiplier = 0.8 # For the large_input_experiments_only_sgd_paper()

labels_multiplier = 1.7 # For the vgg19_cifar10_saturation()
ticks_multiplier = 1.1 # For the vgg19_cifar10_saturation()
plt.rcParams.update({
    "axes.linewidth": 0.5,
    'axes.edgecolor': 'black',
    "grid.linewidth": 0.4,
    "lines.linewidth": 1,
    'xtick.bottom': True,
    'xtick.color': 'black',
    "xtick.direction": "out",
    "xtick.major.size": 3,
    "xtick.major.width": 0.5,
    "xtick.minor.size": 1.5,
    "xtick.minor.width": 0.5,
    'ytick.left': True,
    'ytick.color': 'black',
    "ytick.major.size": 3,
    "ytick.major.width": 0.5,
    "ytick.minor.size": 1.5,
    "ytick.minor.width": 0.5,
    # "figure.figsize": [3.3, 2.5],
    'axes.labelsize': 'xx-large',
    'axes.titlesize': 'xx-large',
    "text.usetex": True,
    "font.family": "serif",
    "text.latex.preamble": r"\usepackage{bm} \usepackage{amsmath}",
})

from typing import Callable, Dict, List, Tuple


def extract_layer_stat(df,
                       epoch=19,
                       primary_metric=None,
                       stat='saturation',
                       state_mode="train") -> Tuple[pd.DataFrame, float]:
    """
    Extracts a specific statistic for a single epoch from a result dataframe as produced by the CSV-writer
    :param df: The dataframe produced by a CSVWriter
    :param epoch: Epoch to filter by
    :param primary_metric: Primary metric for performance evaluation (optional)
    :param stat: The statistic to match. Must be a substring matching all columns belonging to stat statistic like "saturation"
    :return: A dataframe with a single row, corresponding to the epoch containing only the columns that contain the substring
    described in the stat-parameter in their name. Second return value is the primary metric value
    """
    cols = list(df.columns)
    train_cols = [
        col for col in cols
        if state_mode in col and 'accuracy' not in col and stat in col
    ]
    if not np.any(epoch == df.index.values):
        raise ValueError(
            f'Epoch {epoch} could not be recoreded, dataframe has only the following indices: {df.index.values}'
        )
    epoch_df = df[df.index.values == epoch]
    pm = None if primary_metric is None else epoch_df[primary_metric].values[0]
    epoch_df = epoch_df[train_cols]
    return epoch_df, pm


def plot_stat(df,
              stat,
              pm=-1,
              savepath='run.png',
              epoch=0,
              primary_metric=None,
              fontsize=16,
              figsize=None,
              line=True,
              scatter=True,
              ylim=(0, 1.0),
              alpha_line=.6,
              alpha_scatter=1.0,
              color_line=None,
              color_scatter=None,
              primary_metric_loc=(0.7, 0.8),
              show_col_label_x=True,
              show_col_label_y=True,
              show_grid=True,
              save=True,
              samples=False,
              stat_mode="train") -> matplotlib.axes.Axes:
    """Plot statistics

        :param df:
        :param stat:
        :param pm:
        :param savepath:
        :param epoch:
        :param primary_metric:
        :param fontsize:
        :param figsize:
        :param line:
        :param scatter:
        :param ylim:
        :param alpha_line:
        :param alpha_scatter:
        :param color_line:
        :param color_scatter:
        :param primary_metric_loc:
        :param show_col_label_x:
        :param show_col_label_y:
        :param show_grid:
        :param save:
        :return:
        """
    plt.clf()
    plt.cla()
    plt.close()
    if epoch == -1:
        epoch = df.index.values[-1]
    if figsize is not None:
        print(figsize)
        plt.figure(figsize=figsize)
    ax = plt.gca()
    col_names = [i for i in df.columns]
    try:
        if len(df.values[0]) == 0 or (isinstance(df.values[0][0], list) and
                                      isinstance(df.values[0][0][0], tuple)):
            pass
        elif np.all(np.isnan(df.values[0])):
            return ax
    except TypeError:
        warnings.warn(
            "Experienced a TypeError during checking for nan values in, likely caused by non float or int values. "
            "Plotting non np.ndarray may lead to crashes or inconsistent results"
        )
        log.exception(
            "Experienced a TypeError during checking for nan values in, likely caused by non float or int values. "
            "Plotting non np.ndarray may lead to crashes or inconsistent results"
        )
    if line:
        if samples:
            pass
        else:
            ax.plot(list(range(len(col_names))),
                    df.values[0],
                    alpha=alpha_line,
                    color=color_line)
    if scatter:
        if samples:
            for sample in df.values[0][0]:
                x = float(sample[0])
                y = float(sample[1])
                ax.scatter(x, y, alpha=alpha_scatter, color=color_scatter)
        else:
            ax.scatter(list(range(len(col_names))),
                       df.values[0],
                       alpha=alpha_scatter,
                       color=color_scatter)
    if not samples:
        plt.xticks(list(range(len(col_names))),
                   [col_name.split('_', )[1] for col_name in col_names],
                   rotation=90)
    if ylim is not None:
        ax.set_ylim(ylim)
    if primary_metric is not None:
        ax.text(primary_metric_loc[0], primary_metric_loc[1],
                f'{primary_metric}: {pm}')
    plt.yticks(fontsize=fontsize)
    if show_col_label_x:
        plt.xlabel('layers', fontsize=fontsize)
    plt.title(pathlib.Path(savepath).name.replace('_', ' ').replace(
        '.csv', f' epoch: {epoch}'),
        fontsize=fontsize)
    if show_col_label_y:
        plt.ylabel(stat if stat not in STATMAP else STATMAP[stat],
                   rotation='vertical',
                   fontsize=fontsize)
    if show_grid:
        plt.grid()
    plt.tight_layout()
    if save:
        final_savepath = savepath.replace(
            '.csv', f'_{stat}_{stat_mode}_epoch_{epoch}.png')
        log.info(final_savepath)
        plt.savefig(final_savepath)
    return ax


def plot_saturation(epoch_df, ax, color="blue", label="", log=False, ewma=False, window=0.5, index_to_keep=[],pos="best"):
    col_names = epoch_df.columns

    alpha_line = .6
    alpha_scatter = 1.0
    if index_to_keep:
        col_names = col_names.values[index_to_keep]
        if log:
            if ewma:
                ax.plot(list(range(len(col_names))),
                        np.log(numpy_ewma_vectorized_v2(epoch_df.values[0][index_to_keep]), window),
                        alpha=alpha_line,
                        color=color)

                ax.scatter(list(range(len(col_names))),
                           np.log(numpy_ewma_vectorized_v2(epoch_df.values[0][index_to_keep], window)),
                           alpha=alpha_scatter,
                           color=color, label=label if label != "" else None)
                ax.set_ylabel("$\log($Saturation$)$")
                ax.set_xlabel("Layer")
                ax.set_xticks(index_to_keep,
                              [col_name.split('_', )[1] for col_name in col_names])
            else:
                ax.plot(list(range(len(col_names))),
                        np.log(epoch_df.values[0][index_to_keep]),
                        alpha=alpha_line,
                        color=color)

                ax.scatter(list(range(len(col_names))),
                           np.log(epoch_df.values[0][index_to_keep]),
                           alpha=alpha_scatter,
                           color=color, label=label if label != "" else None)
                ax.set_ylabel("$\log($Saturation$)$")
                ax.set_xlabel("Layer")
                ax.set_xticks(index_to_keep,
                              [col_name.split('_', )[1] for col_name in col_names])
            if label:
                ax.legend()
        else:
            if ewma:
                ax.plot(list(range(len(col_names))),
                        numpy_ewma_vectorized_v2(epoch_df.values[0][index_to_keep], window),
                        alpha=0.6,
                        color=color)

                ax.scatter(list(range(len(col_names))),
                           numpy_ewma_vectorized_v2(epoch_df.values[0][index_to_keep], window),
                           alpha=1,
                           color=color, label=label, s=25)
                ax.set_ylabel("Saturation")
                ax.set_xlabel("Layer")
                ax.set_xticks(index_to_keep,
                              [col_name.split('_', )[1] for col_name in col_names])
            else:
                ax.plot(list(range(len(col_names))),
                        epoch_df.values[0][index_to_keep],
                        alpha=0.6,
                        color=color)

                ax.scatter(list(range(len(col_names))),

                           epoch_df.values[0][index_to_keep],
                           alpha=1,
                           color=color, label=label, s=25)
                ax.set_ylabel("Saturation")
                ax.set_xlabel("Layer")

                ax.set_xticks(range(len(index_to_keep)),
                              [col_name.split('_', )[1] for col_name in col_names])
            if label:
                ax.legend(loc=pos)
    else:
        if log:
            if ewma:
                ax.plot(list(range(len(col_names))),
                        np.log(numpy_ewma_vectorized_v2(epoch_df.values[0]), window),
                        alpha=alpha_line,
                        color=color)

                ax.scatter(list(range(len(col_names))),
                           np.log(numpy_ewma_vectorized_v2(epoch_df.values[0], window)),
                           alpha=alpha_scatter,
                           color=color, label=label if label != "" else None)
                ax.set_ylabel("$\log($Saturation$)$")
                ax.set_xlabel("Layer")
                ax.set_xticks(list(range(len(col_names))),
                              [col_name.split('_', )[1] for col_name in col_names])
            else:
                ax.plot(list(range(len(col_names))),
                        np.log(epoch_df.values[0]),
                        alpha=alpha_line,
                        color=color)

                ax.scatter(list(range(len(col_names))),
                           np.log(epoch_df.values[0]),
                           alpha=alpha_scatter,
                           color=color, label=label if label != "" else None)
                ax.set_ylabel("$\log($Saturation$)$")
                ax.set_xlabel("Layer")
                ax.set_xticks(list(range(len(col_names))),
                              [col_name.split('_', )[1] for col_name in col_names])
            if label:
                ax.legend()
                # ax.set_xticklabels(labels, rotation=45)

        else:
            if ewma:
                ax.plot(list(range(len(col_names))),
                        numpy_ewma_vectorized_v2(epoch_df.values[0], window),
                        alpha=0.6,
                        color=color)

                ax.scatter(list(range(len(col_names))),
                           numpy_ewma_vectorized_v2(epoch_df.values[0], window),
                           alpha=1,
                           color=color, label=label)
                ax.set_ylabel("Saturation")
                ax.set_xlabel("Layer")
                ax.set_xticks(list(range(len(col_names))),
                              [col_name.split('_', )[1] for col_name in col_names])
            else:
                ax.plot(list(range(len(col_names))),
                        epoch_df.values[0],
                        alpha=0.6,
                        color=color)

                ax.scatter(list(range(len(col_names))),
                           epoch_df.values[0],
                           alpha=1,
                           color=color, label=label)
                ax.set_ylabel("Saturation")
                ax.set_xlabel("Layer")
                ax.set_xticks(list(range(len(col_names))),
                              [col_name.split('_', )[1] for col_name in col_names])
            if label:
                ax.legend(loc=pos)
    # ax.set_xticklabels(labels, rotation=45)


def optimisers_saturation():
    """# TODO: Diiferent optimisers pruning results for all levels

    # Vgg19
    """

    # Average saturation of each method
    # EKFac

    saturation_lvl1_ekfac = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    saturation_lvl2_ekfac = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_2_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    saturation_lvl3_ekfac = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_3_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    saturation_lvl4_ekfac = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_4_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")

    saturation_ekfac = [saturation_lvl1_ekfac, saturation_lvl2_ekfac, saturation_lvl3_ekfac, saturation_lvl4_ekfac]
    # ASAM

    saturation_lvl1_sam = pd.read_csv(
        "saturation_results/cifar10/vgg19/ASAM/vgg19_normal_cifar10_rf_level_1_sam_optim_saturation_200_gc_0.csv",
        delimiter=";")
    saturation_lvl2_sam = pd.read_csv(
        "saturation_results/cifar10/vgg19/ASAM/vgg19_normal_cifar10_rf_level_2_sam_optim_saturation_200_gc_0.csv",
        delimiter=";")
    saturation_lvl3_sam = pd.read_csv(
        "saturation_results/cifar10/vgg19/ASAM/vgg19_normal_cifar10_rf_level_3_sam_optim_saturation_200_gc_0.csv",
        delimiter=";")
    saturation_lvl4_sam = pd.read_csv(
        "saturation_results/cifar10/vgg19/ASAM/vgg19_normal_cifar10_rf_level_4_sam_optim_saturation_200_gc_0.csv",
        delimiter=";")
    saturation_sam = [saturation_lvl1_sam, saturation_lvl2_sam, saturation_lvl3_sam, saturation_lvl4_sam]

    # SGD

    saturation_lvl1_sgd = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",
        delimiter=";")
    saturation_lvl2_sgd = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726773380.2706754_rf_level_2_recording_200_no_ffcv.csv",
        delimiter=";")
    saturation_lvl3_sgd = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1725639932.8630962_rf_level_3_recording_200_no_ffcv.csv",
        delimiter=";")
    saturation_lvl4_sgd = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1725640015.7435527_rf_level_4_recording_200_no_ffcv.csv",
        delimiter=";")

    saturation_sgd = [saturation_lvl1_sgd, saturation_lvl2_sgd, saturation_lvl3_sgd, saturation_lvl4_sgd]

    def get_average_saturation_epoch(df, epoch, accumulators):
        current_df = df[df["Epoch"] == epoch]
        train_sat = current_df.filter(regex="train-saturation")
        eval_sat = current_df.filter(regex="eval-saturation")
        train_average = train_sat.mean(axis=1)
        eval_average = eval_sat.mean(axis=1)
        print("\n train saturation\n")
        print("{}".format(float(train_average)))
        print("\n Eval saturation \n")
        print("{}\n\n\n".format(float(eval_average)))
        return train_average, eval_average

    optim_list = []
    level_list = []
    sat_train_list = []
    sat_eval_list = []
    print("\n ========================= EKFAC =========================== \n")
    for i in range(1, 5):
        print("\t Level {}".format(i))
        train_sat, eval_sat = get_average_saturation_epoch(saturation_ekfac[i - 1], 199, 0)
        optim_list.extend(["EKFAC"])
        level_list.append(resnets_rfs[i])
        sat_train_list.extend(train_sat)
        sat_eval_list.extend(eval_sat)
    print("\n======================= ASAM ============================\n")
    for i in range(1, 5):
        print("\t Level {}".format(i))
        train_sat, eval_sat = get_average_saturation_epoch(saturation_sam[i - 1], 199, 0)
        optim_list.extend(["ASAM"])
        level_list.append(resnets_rfs[i])
        sat_train_list.extend(train_sat)
        sat_eval_list.extend(eval_sat)
    print("\n======================== SGD ===========================\n")
    for i in range(1, 5):
        print("\t Level {}".format(i))
        train_sat, eval_sat = get_average_saturation_epoch(saturation_sgd[i - 1], 199, 0)
        optim_list.extend(["SGD"])
        level_list.append(resnets_rfs[i])
        sat_train_list.extend(train_sat)
        sat_eval_list.extend(eval_sat)

    average_saturation_df = pd.DataFrame({"optimiser": optim_list, "RF": level_list, "train saturation": sat_train_list,
                                          "eval saturation": sat_eval_list})
    average_saturation_df

    average_saturation_df["Saturation Gap"] = average_saturation_df["eval saturation"] - average_saturation_df[
        "train saturation"]

    sns.pairplot(average_saturation_df, hue="optimiser", markers=["o", "s", "D"])
    plt.close()

    # all_df=pd.concat([lvl5,lvl6,lvl7,lvl8,lvl10,lvl11,lvl12,lvl13],ignore_index=True)

    # average_saturation_df["Saturation Gap"]=average_saturation_df["eval saturation"]-average_saturation_df["train saturation"]
    average_saturation_df = average_saturation_df[average_saturation_df["optimiser"] == "SGD"]
    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed")

    sns.barplot(data=average_saturation_df, x="RF", y="train saturation", ax=axs[0])
    sns.barplot(data=average_saturation_df, x="RF", y="eval saturation", ax=axs[1])

    sns.stripplot(
        x="RF",
        y="train saturation",
        data=average_saturation_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)

    sns.stripplot(
        x="RF",
        y="eval saturation",
        data=average_saturation_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)
    # plt.grid(ls="--")
    axs[0].set_ylabel('Average Train Saturation')
    axs[1].set_ylabel('Average Test Saturation')
    plt.close()

    """## 0.8"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    # level 1 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_1_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[1]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_1_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[1]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv("second_order_pruning/RF_vgg19_1_cifar10_0.8_recording_200_global_one_shot_summary.csv",
                                delimiter=",")
    RF = []
    RF.extend([vgg_rfs[1]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 2 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_2_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[2]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_2_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[2]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv("second_order_pruning/RF_vgg19_2_cifar10_0.8_recording_200_global_one_shot_summary.csv",
                                delimiter=",")
    RF = []
    RF.extend([vgg_rfs[2]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 3 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_3_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[3]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_3_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[3]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv("second_order_pruning/RF_vgg19_3_cifar10_0.8_recording_200_global_one_shot_summary.csv",
                                delimiter=",")
    RF = []
    RF.extend([vgg_rfs[3]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 4 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_4_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[4]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_4_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[4]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv("second_order_pruning/RF_vgg19_4_cifar10_0.8_recording_200_global_one_shot_summary.csv",
                                delimiter=",")
    RF = []
    RF.extend([vgg_rfs[4]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])

    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser")
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False)

    axs[0].legend(prop={"size": fs * 1.2}, loc="upper left")

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))
    secay.set_ylabel('Absolute Pruned Accuracy')
    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)
    plt.close()

    #

    # print(len(df_level1))
    # all_df=df_level1
    # all_df["Receptive Field"]=RF
    # # sns.scatterplot(data=all_df, x="Dense Accuracy", y="Pruned Fine Tuned Accuracy", hue="Receptive Field",size="Receptive Field",sizes=(20, 200))
    # df=all_df
    # df["Accuracy Reduction (Dense-Pruned)"]= df["Dense Accuracy"]-df["Pruned Accuracy"]
    # means = df.groupby(["Receptive Field"]).mean()
    # stds =df.groupby(["Receptive Field"]).std()
    # pt_means=means['Pruned Accuracy'].values
    # dt_means=means['Dense Accuracy'].values
    # difference_means=means['Accuracy Reduction (Dense-Pruned)'].values
    # pt_stds=stds['Pruned Accuracy'].values
    # dt_stds=stds['Dense Accuracy'].values
    # difference_stds=stds['Accuracy Reduction (Dense-Pruned)'].values

    # new_df = pd.DataFrame({
    #     "Pruned Test Accuracy":pt_means,
    #     "Dense Test Accuracy":dt_means,
    #     "Difference in Accuracy":difference_means,
    #     "Error PT":pt_stds,
    #     "Error DT":dt_stds,
    #     "Error difference":difference_stds,

    # })

    # def combine_mean_std(mean_and_std):
    #   mean,std =mean_and_std
    #   if mean>=10:
    #     if std>=10:
    #       return "{:0.2f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.2f}$\pm${:0.3f}".format(mean,std)
    #   else:
    #     if std>=10:
    #       return "{:0.3f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.3f}$\pm${:0.3f}".format(mean,std)

    """## 0.9"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    # level 1 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_1_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[1]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_1_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[1]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv("second_order_pruning/RF_vgg19_1_cifar10_0.9_recording_200_global_one_shot_summary.csv",
                                delimiter=",")
    RF = []
    RF.extend([vgg_rfs[1]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 2 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_2_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[2]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_2_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[2]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv("second_order_pruning/RF_vgg19_2_cifar10_0.9_recording_200_global_one_shot_summary.csv",
                                delimiter=",")
    RF = []
    RF.extend([vgg_rfs[2]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 3 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_3_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[3]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_3_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[3]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv("second_order_pruning/RF_vgg19_3_cifar10_0.9_recording_200_global_one_shot_summary.csv",
                                delimiter=",")
    RF = []
    RF.extend([vgg_rfs[3]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 4 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_4_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[4]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_4_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[4]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv("second_order_pruning/RF_vgg19_4_cifar10_0.9_recording_200_global_one_shot_summary.csv",
                                delimiter=",")
    RF = []
    RF.extend([vgg_rfs[4]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])

    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    # sns.barplot(ax=axs[0],data=all_df,x="RF",y="Scaled Pruned Accuracy",hue="optimiser")
    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False)

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser", alpha=0.5)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False, alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Scaled Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)
    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    axs[0].legend(prop={"size": fs * 1.2}, loc="upper left")

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))
    secay.set_ylabel('Absolute Pruned Accuracy')

    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)
        ax.grid(ls="--")

    # plt.grid(ls="--")
    # plt.savefig()
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/vgg19_cifar10_pr_0.9_all_optimisers.pdf")

    plt.close()

    #

    # print(len(df_level1))
    # all_df=df_level1
    # all_df["Receptive Field"]=RF
    # # sns.scatterplot(data=all_df, x="Dense Accuracy", y="Pruned Fine Tuned Accuracy", hue="Receptive Field",size="Receptive Field",sizes=(20, 200))
    # df=all_df
    # df["Accuracy Reduction (Dense-Pruned)"]= df["Dense Accuracy"]-df["Pruned Accuracy"]
    # means = df.groupby(["Receptive Field"]).mean()
    # stds =df.groupby(["Receptive Field"]).std()
    # pt_means=means['Pruned Accuracy'].values
    # dt_means=means['Dense Accuracy'].values
    # difference_means=means['Accuracy Reduction (Dense-Pruned)'].values
    # pt_stds=stds['Pruned Accuracy'].values
    # dt_stds=stds['Dense Accuracy'].values
    # difference_stds=stds['Accuracy Reduction (Dense-Pruned)'].values

    # new_df = pd.DataFrame({
    #     "Pruned Test Accuracy":pt_means,
    #     "Dense Test Accuracy":dt_means,
    #     "Difference in Accuracy":difference_means,
    #     "Error PT":pt_stds,
    #     "Error DT":dt_stds,
    #     "Error difference":difference_stds,

    # })

    # def combine_mean_std(mean_and_std):
    #   mean,std =mean_and_std
    #   if mean>=10:
    #     if std>=10:
    #       return "{:0.2f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.2f}$\pm${:0.3f}".format(mean,std)
    #   else:
    #     if std>=10:
    #       return "{:0.3f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.3f}$\pm${:0.3f}".format(mean,std)

    """## 0.95"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    # level 1 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_1_cifar10_0.95_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[1]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_1_cifar10_0.95_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[1]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "second_order_pruning/RF_vgg19_1_cifar10_0.95_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([vgg_rfs[1]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 2 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_2_cifar10_0.95_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[2]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_2_cifar10_0.95_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[2]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "second_order_pruning/RF_vgg19_2_cifar10_0.95._recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([vgg_rfs[2]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 3 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_3_cifar10_0.95_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[3]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_3_cifar10_0.95_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[3]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "second_order_pruning/RF_vgg19_3_cifar10_0.95_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([vgg_rfs[3]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 4 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_4_cifar10_0.95_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[4]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_4_cifar10_0.95_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[4]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "second_order_pruning/RF_vgg19_4_cifar10_0.95_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([vgg_rfs[4]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])

    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser")
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False)

    axs[0].legend(prop={"size": fs * 1.2}, loc="upper left")

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))
    secay.set_ylabel('Absolute Pruned Accuracy')

    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)
    plt.close()

    #

    # print(len(df_level1))
    # all_df=df_level1
    # all_df["Receptive Field"]=RF
    # # sns.scatterplot(data=all_df, x="Dense Accuracy", y="Pruned Fine Tuned Accuracy", hue="Receptive Field",size="Receptive Field",sizes=(20, 200))
    # df=all_df
    # df["Accuracy Reduction (Dense-Pruned)"]= df["Dense Accuracy"]-df["Pruned Accuracy"]
    # means = df.groupby(["Receptive Field"]).mean()
    # stds =df.groupby(["Receptive Field"]).std()
    # pt_means=means['Pruned Accuracy'].values
    # dt_means=means['Dense Accuracy'].values
    # difference_means=means['Accuracy Reduction (Dense-Pruned)'].values
    # pt_stds=stds['Pruned Accuracy'].values
    # dt_stds=stds['Dense Accuracy'].values
    # difference_stds=stds['Accuracy Reduction (Dense-Pruned)'].values

    # new_df = pd.DataFrame({
    #     "Pruned Test Accuracy":pt_means,
    #     "Dense Test Accuracy":dt_means,
    #     "Difference in Accuracy":difference_means,
    #     "Error PT":pt_stds,
    #     "Error DT":dt_stds,
    #     "Error difference":difference_stds,

    # })

    # def combine_mean_std(mean_and_std):
    #   mean,std =mean_and_std
    #   if mean>=10:
    #     if std>=10:
    #       return "{:0.2f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.2f}$\pm${:0.3f}".format(mean,std)
    #   else:
    #     if std>=10:
    #       return "{:0.3f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.3f}$\pm${:0.3f}".format(mean,std)


def batchnorm_pruning_acuracies_vgg19_cifar10():
    # TODO:not implemented yet
    """# TODO: Bach norm adjusted pruning accuracies **TODO**

    # Vgg19
    """

    # Average saturation of each method
    # EKFac

    saturation_lvl1_ekfac = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    saturation_lvl2_ekfac = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_2_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    saturation_lvl3_ekfac = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_3_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    saturation_lvl4_ekfac = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_4_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")

    saturation_ekfac = [saturation_lvl1_ekfac, saturation_lvl2_ekfac, saturation_lvl3_ekfac, saturation_lvl4_ekfac]
    # AASAM

    saturation_lvl1_sam = pd.read_csv(
        "saturation_results/cifar10/vgg19/ASAM/vgg19_normal_cifar10_rf_level_1_sam_optim_saturation_200_gc_0.csv",
        delimiter=";")
    saturation_lvl2_sam = pd.read_csv(
        "saturation_results/cifar10/vgg19/ASAM/vgg19_normal_cifar10_rf_level_2_sam_optim_saturation_200_gc_0.csv",
        delimiter=";")
    saturation_lvl3_sam = pd.read_csv(
        "saturation_results/cifar10/vgg19/ASAM/vgg19_normal_cifar10_rf_level_3_sam_optim_saturation_200_gc_0.csv",
        delimiter=";")
    saturation_lvl4_sam = pd.read_csv(
        "saturation_results/cifar10/vgg19/ASAM/vgg19_normal_cifar10_rf_level_4_sam_optim_saturation_200_gc_0.csv",
        delimiter=";")
    saturation_sam = [saturation_lvl1_sam, saturation_lvl2_sam, saturation_lvl3_sam, saturation_lvl4_sam]

    # SGD

    saturation_lvl1_sgd = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",
        delimiter=";")
    saturation_lvl2_sgd = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726773380.2706754_rf_level_2_recording_200_no_ffcv.csv",
        delimiter=";")
    saturation_lvl3_sgd = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1725639932.8630962_rf_level_3_recording_200_no_ffcv.csv",
        delimiter=";")
    saturation_lvl4_sgd = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1725640015.7435527_rf_level_4_recording_200_no_ffcv.csv",
        delimiter=";")
    saturation_sgd = [saturation_lvl1_sgd, saturation_lvl2_sgd, saturation_lvl3_sgd, saturation_lvl4_sgd]

    def get_average_saturation_epoch(df, epoch, accumulators):
        current_df = df[df["Epoch"] == epoch]
        train_sat = current_df.filter(regex="train-saturation")
        eval_sat = current_df.filter(regex="eval-saturation")
        train_average = train_sat.mean(axis=1)
        eval_average = eval_sat.mean(axis=1)
        print("\n train saturation\n")
        print("{}".format(float(train_average)))
        print("\n Eval saturation \n")
        print("{}\n\n\n".format(float(eval_average)))
        return train_average, eval_average

    optim_list = []
    level_list = []
    sat_train_list = []
    sat_eval_list = []
    print("\n ========================= EKFAC =========================== \n")
    for i in range(1, 5):
        print("\t Level {}".format(i))
        train_sat, eval_sat = get_average_saturation_epoch(saturation_ekfac[i - 1], 199, 0)
        optim_list.extend(["EKFAC"])
        level_list.append(resnet_rfs[i])
        sat_train_list.extend(train_sat)
        sat_eval_list.extend(eval_sat)
    print("\n======================= ASAM ============================\n")
    for i in range(1, 5):
        print("\t Level {}".format(i))
        train_sat, eval_sat = get_average_saturation_epoch(saturation_sam[i - 1], 199, 0)
        optim_list.extend(["ASAM"])
        level_list.append(resnet_rfs[i])
        sat_train_list.extend(train_sat)
        sat_eval_list.extend(eval_sat)
    print("\n======================== SGD ===========================\n")
    for i in range(1, 5):
        print("\t Level {}".format(i))
        train_sat, eval_sat = get_average_saturation_epoch(saturation_sgd[i - 1], 199, 0)
        optim_list.extend(["SGD"])
        level_list.append(resnet_rfs[i])
        sat_train_list.extend(train_sat)
        sat_eval_list.extend(eval_sat)

    average_saturation_df = pd.DataFrame({"optimiser": optim_list, "RF": level_list, "train saturation": sat_train_list,
                                          "eval saturation": sat_eval_list})
    average_saturation_df

    average_saturation_df["Saturation Gap"] = average_saturation_df["eval saturation"] - average_saturation_df[
        "train saturation"]

    sns.pairplot(average_saturation_df, hue="optimiser", markers=["o", "s", "D"])
    plt.close()

    """## 0.8"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    # level 1 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_1_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[1]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_1_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[1]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "second_order_pruning/RF_vgg19_1_cifar10_0.8_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[1]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 2 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_2_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[2]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_2_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[2]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "second_order_pruning/RF_vgg19_2_cifar10_0.8_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[2]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 3 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_3_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[3]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_3_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[3]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "second_order_pruning/RF_vgg19_3_cifar10_0.8_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[3]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 4 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_4_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[4]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_4_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[4]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "second_order_pruning/RF_vgg19_4_cifar10_0.8_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[4]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])

    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser")
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False)

    axs[0].legend(prop={"size": fs * 1.2}, loc="upper left")

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))
    secay.set_ylabel('Absolute Pruned Accuracy')
    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)
    plt.close()

    #

    # print(len(df_level1))
    # all_df=df_level1
    # all_df["Receptive Field"]=RF
    # # sns.scatterplot(data=all_df, x="Dense Accuracy", y="Pruned Fine Tuned Accuracy", hue="Receptive Field",size="Receptive Field",sizes=(20, 200))
    # df=all_df
    # df["Accuracy Reduction (Dense-Pruned)"]= df["Dense Accuracy"]-df["Pruned Accuracy"]
    # means = df.groupby(["Receptive Field"]).mean()
    # stds =df.groupby(["Receptive Field"]).std()
    # pt_means=means['Pruned Accuracy'].values
    # dt_means=means['Dense Accuracy'].values
    # difference_means=means['Accuracy Reduction (Dense-Pruned)'].values
    # pt_stds=stds['Pruned Accuracy'].values
    # dt_stds=stds['Dense Accuracy'].values
    # difference_stds=stds['Accuracy Reduction (Dense-Pruned)'].values

    # new_df = pd.DataFrame({
    #     "Pruned Test Accuracy":pt_means,
    #     "Dense Test Accuracy":dt_means,
    #     "Difference in Accuracy":difference_means,
    #     "Error PT":pt_stds,
    #     "Error DT":dt_stds,
    #     "Error difference":difference_stds,

    # })

    # def combine_mean_std(mean_and_std):
    #   mean,std =mean_and_std
    #   if mean>=10:
    #     if std>=10:
    #       return "{:0.2f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.2f}$\pm${:0.3f}".format(mean,std)
    #   else:
    #     if std>=10:
    #       return "{:0.3f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.3f}$\pm${:0.3f}".format(mean,std)

    """## 0.9"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    # level 1 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_1_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[1]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_1_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[1]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "second_order_pruning/RF_vgg19_1_cifar10_0.9_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[1]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 2 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_2_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[2]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_2_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[2]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "second_order_pruning/RF_vgg19_2_cifar10_0.9_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[2]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 3 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_3_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[3]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_3_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[3]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "second_order_pruning/RF_vgg19_3_cifar10_0.9_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[3]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 4 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_4_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[4]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_4_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[4]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "second_order_pruning/RF_vgg19_4_cifar10_0.9_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[4]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])

    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser")
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False)

    axs[0].legend(prop={"size": fs * 1.2}, loc="upper left")

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))
    secay.set_ylabel('Absolute Pruned Accuracy')

    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)
    plt.close()

    #

    # print(len(df_level1))
    # all_df=df_level1
    # all_df["Receptive Field"]=RF
    # # sns.scatterplot(data=all_df, x="Dense Accuracy", y="Pruned Fine Tuned Accuracy", hue="Receptive Field",size="Receptive Field",sizes=(20, 200))
    # df=all_df
    # df["Accuracy Reduction (Dense-Pruned)"]= df["Dense Accuracy"]-df["Pruned Accuracy"]
    # means = df.groupby(["Receptive Field"]).mean()
    # stds =df.groupby(["Receptive Field"]).std()
    # pt_means=means['Pruned Accuracy'].values
    # dt_means=means['Dense Accuracy'].values
    # difference_means=means['Accuracy Reduction (Dense-Pruned)'].values
    # pt_stds=stds['Pruned Accuracy'].values
    # dt_stds=stds['Dense Accuracy'].values
    # difference_stds=stds['Accuracy Reduction (Dense-Pruned)'].values

    # new_df = pd.DataFrame({
    #     "Pruned Test Accuracy":pt_means,
    #     "Dense Test Accuracy":dt_means,
    #     "Difference in Accuracy":difference_means,
    #     "Error PT":pt_stds,
    #     "Error DT":dt_stds,
    #     "Error difference":difference_stds,

    # })

    # def combine_mean_std(mean_and_std):
    #   mean,std =mean_and_std
    #   if mean>=10:
    #     if std>=10:
    #       return "{:0.2f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.2f}$\pm${:0.3f}".format(mean,std)
    #   else:
    #     if std>=10:
    #       return "{:0.3f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.3f}$\pm${:0.3f}".format(mean,std)

    """## 0.95"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    # level 1 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_1_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[1]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_1_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[1]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "second_order_pruning/RF_vgg19_1_cifar10_0.9_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[1]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 2 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_2_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[2]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_2_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[2]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "second_order_pruning/RF_vgg19_2_cifar10_0.9_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[2]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 3 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_3_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[3]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_3_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[3]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "second_order_pruning/RF_vgg19_3_cifar10_0.9_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[3]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 4 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "second_order_pruning/RF_vgg19_4_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[4]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "second_order_pruning/RF_vgg19_4_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[4]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "second_order_pruning/RF_vgg19_4_cifar10_0.9_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([vgg_rfs[4]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])

    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser")
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False)

    axs[0].legend(prop={"size": fs * 1.2}, loc="upper left")

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))
    secay.set_ylabel('Absolute Pruned Accuracy')

    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)
    plt.close()

    #

    # print(len(df_level1))
    # all_df=df_level1
    # all_df["Receptive Field"]=RF
    # # sns.scatterplot(data=all_df, x="Dense Accuracy", y="Pruned Fine Tuned Accuracy", hue="Receptive Field",size="Receptive Field",sizes=(20, 200))
    # df=all_df
    # df["Accuracy Reduction (Dense-Pruned)"]= df["Dense Accuracy"]-df["Pruned Accuracy"]
    # means = df.groupby(["Receptive Field"]).mean()
    # stds =df.groupby(["Receptive Field"]).std()
    # pt_means=means['Pruned Accuracy'].values
    # dt_means=means['Dense Accuracy'].values
    # difference_means=means['Accuracy Reduction (Dense-Pruned)'].values
    # pt_stds=stds['Pruned Accuracy'].values
    # dt_stds=stds['Dense Accuracy'].values
    # difference_stds=stds['Accuracy Reduction (Dense-Pruned)'].values

    # new_df = pd.DataFrame({
    #     "Pruned Test Accuracy":pt_means,
    #     "Dense Test Accuracy":dt_means,
    #     "Difference in Accuracy":difference_means,
    #     "Error PT":pt_stds,
    #     "Error DT":dt_stds,
    #     "Error difference":difference_stds,

    # })

    # def combine_mean_std(mean_and_std):
    #   mean,std =mean_and_std
    #   if mean>=10:
    #     if std>=10:
    #       return "{:0.2f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.2f}$\pm${:0.3f}".format(mean,std)
    #   else:
    #     if std>=10:
    #       return "{:0.3f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.3f}$\pm${:0.3f}".format(mean,std)


def saturation_resnet50_cifar50_all_optim():
    """# TODO: Resnet50"""

    # Average saturation of each method
    # EKFac

    saturation_lvl1_ekfac = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    saturation_lvl2_ekfac = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_2_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    saturation_lvl3_ekfac = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_3_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    saturation_lvl4_ekfac = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_4_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")

    saturation_ekfac = [saturation_lvl1_ekfac, saturation_lvl2_ekfac, saturation_lvl3_ekfac, saturation_lvl4_ekfac]
    # ASAM

    saturation_lvl1_sam = pd.read_csv(
        "saturation_results/cifar10/resnet50/ASAM/resnet50_normal_cifar10_rf_level_1_sam_optim_saturation_200_gc_0.csv",
        delimiter=";")
    saturation_lvl2_sam = pd.read_csv(
        "saturation_results/cifar10/resnet50/ASAM/resnet50_normal_cifar10_rf_level_2_sam_optim_saturation_200_gc_0.csv",
        delimiter=";")
    saturation_lvl3_sam = pd.read_csv(
        "saturation_results/cifar10/resnet50/ASAM/resnet50_normal_cifar10_rf_level_3_sam_optim_saturation_200_gc_0.csv",
        delimiter=";")
    saturation_lvl4_sam = pd.read_csv(
        "saturation_results/cifar10/resnet50/ASAM/resnet50_normal_cifar10_rf_level_4_sam_optim_saturation_200_gc_0.csv",
        delimiter=";")
    saturation_sam = [saturation_lvl1_sam, saturation_lvl2_sam, saturation_lvl3_sam, saturation_lvl4_sam]

    # SGD

    saturation_lvl1_sgd = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1726773378.6547081_rf_level_1_recording_200_no_ffcv.csv",
        delimiter=";")

    saturation_lvl1_sgd_2 = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1727020462.8526177_rf_level_1_recording_200_no_ffcv.csv",
        delimiter=";")
    saturation_lvl1_sgd_3 = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1727020463.0153637_rf_level_1_recording_200_no_ffcv.csv",
        delimiter=";")

    saturation_lvl2_sgd = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1727020462.50258_rf_level_2_recording_200_no_ffcv.csv",
        delimiter=";")
    saturation_lvl2_sgd_2 = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1726773352.3026712_rf_level_2_recording_200_no_ffcv.csv",
        delimiter=";")
    # saturation_lvl2_sgd_3 = pd.read_csv("saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1727020462.50258_rf_level_2_recording_200_no_ffcv.csv",delimiter=";")

    saturation_lvl3_sgd = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1726248344.7113843_rf_level_3_recording_200_no_ffcv.csv",
        delimiter=";")
    saturation_lvl4_sgd = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1726248344.4095678_rf_level_4_recording_200_no_ffcv.csv",
        delimiter=";")
    saturation_sgd = [saturation_lvl1_sgd_3, saturation_lvl2_sgd, saturation_lvl3_sgd, saturation_lvl4_sgd]

    def get_average_saturation_epoch(df, epoch, accumulators):
        current_df = df[df["Epoch"] == epoch]
        train_sat = current_df.filter(regex="train-saturation")
        eval_sat = current_df.filter(regex="eval-saturation")
        train_average = train_sat.mean(axis=1)
        eval_average = eval_sat.mean(axis=1)
        print("\n train saturation\n")
        print("{}".format(float(train_average)))
        print("\n Eval saturation \n")
        print("{}\n\n\n".format(float(eval_average)))
        return train_average, eval_average

    optim_list = []
    level_list = []
    sat_train_list = []
    sat_eval_list = []
    print("\n ========================= EKFAC =========================== \n")
    for i in range(1, 5):
        print("\t Level {}".format(i))
        train_sat, eval_sat = get_average_saturation_epoch(saturation_ekfac[i - 1], 199, 0)
        optim_list.extend(["EKFAC"])
        level_list.append(resnets_rfs[i])
        sat_train_list.extend(train_sat)
        sat_eval_list.extend(eval_sat)
    print("\n======================= ASAM ============================\n")
    for i in range(1, 5):
        print("\t Level {}".format(i))
        train_sat, eval_sat = get_average_saturation_epoch(saturation_sam[i - 1], 199, 0)
        optim_list.extend(["ASAM"])
        level_list.append(resnets_rfs[i])
        sat_train_list.extend(train_sat)
        sat_eval_list.extend(eval_sat)
    print("\n======================== SGD ===========================\n")
    for i in range(1, 5):
        print("\t Level {}".format(i))
        train_sat, eval_sat = get_average_saturation_epoch(saturation_sgd[i - 1], 199, 0)
        optim_list.extend(["SGD"])
        level_list.append(resnets_rfs[i])
        sat_train_list.extend(train_sat)
        sat_eval_list.extend(eval_sat)

    average_saturation_df = pd.DataFrame({"optimiser": optim_list, "RF": level_list, "train saturation": sat_train_list,
                                          "eval saturation": sat_eval_list})
    average_saturation_df

    average_saturation_df["Saturation Gap"] = average_saturation_df["eval saturation"] - average_saturation_df[
        "train saturation"]

    sns.pairplot(average_saturation_df, hue="optimiser", markers=["o", "s", "D"])
    plt.close()

    """ the effect of the optimisers is perpendicular and different from the effect of the receptive field, both of them affect pruning. beacuse both of them affect the saturation."""

    # all_df=pd.concat([lvl5,lvl6,lvl7,lvl8,lvl10,lvl11,lvl12,lvl13],ignore_index=True)

    # average_saturation_df["Saturation Gap"]=average_saturation_df["eval saturation"]-average_saturation_df["train saturation"]
    average_saturation_df = average_saturation_df[average_saturation_df["optimiser"] == "SGD"]
    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed")

    sns.barplot(data=average_saturation_df, x="RF", y="train saturation", ax=axs[0])
    sns.barplot(data=average_saturation_df, x="RF", y="eval saturation", ax=axs[1])

    sns.stripplot(
        x="RF",
        y="train saturation",
        data=average_saturation_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)

    sns.stripplot(
        x="RF",
        y="eval saturation",
        data=average_saturation_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)
    # plt.grid(ls="--")
    axs[0].set_ylabel('Average Train Saturation')
    axs[1].set_ylabel('Average Test Saturation')
    plt.close()

    sns.pairplot(average_saturation_df[average_saturation_df["optimiser"] == "EKFAC"], hue="RF",
                 markers=["o", "s", "D"])
    plt.close()

    sns.pairplot(average_saturation_df[average_saturation_df["optimiser"] == "ASAM"], hue="RF", markers=["o", "s", "D"])
    plt.close()

    sns.pairplot(average_saturation_df[average_saturation_df["optimiser"] == "SGD"], hue="RF", markers=["o", "s", "D"])
    plt.close()

    epoch = 199
    df = saturation_lvl4_sam
    current_df = df[df["Epoch"] == epoch]
    train_sat = current_df.filter(regex="train-saturation")
    eval_sat = current_df.filter(regex="eval-saturation")
    train_average = train_sat.mean(axis=1)
    df

    current_df

    """## 0.7"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    # level 1 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.7_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.7_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.7_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 2 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.7_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.7_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.7_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 3 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.7_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.7_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.7_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 4 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.7_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.7_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.7_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 5 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_5_cifar10_0.7_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim
    # level 6 ############################ ############################ ############################ ############################ ############################ ############################

    df_level6_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_6_cifar10_0.7_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level6_ekfac))
    df_level6_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level6_ekfac))
    df_level6_ekfac["optimiser"] = optim
    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level7_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_7_cifar10_0.7_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level7_ekfac))
    df_level7_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level7_ekfac))
    df_level7_ekfac["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])

    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4, df_level7_ekfac, df_level6_ekfac, df_level5_ekfac])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser")
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False)

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))
    secay.set_ylabel('Absolute Pruned Accuracy')
    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)
    plt.close()

    #

    # print(len(df_level1))
    # all_df=df_level1
    # all_df["Receptive Field"]=RF
    # # sns.scatterplot(data=all_df, x="Dense Accuracy", y="Pruned Fine Tuned Accuracy", hue="Receptive Field",size="Receptive Field",sizes=(20, 200))
    # df=all_df
    # df["Accuracy Reduction (Dense-Pruned)"]= df["Dense Accuracy"]-df["Pruned Accuracy"]
    # means = df.groupby(["Receptive Field"]).mean()
    # stds =df.groupby(["Receptive Field"]).std()
    # pt_means=means['Pruned Accuracy'].values
    # dt_means=means['Dense Accuracy'].values
    # difference_means=means['Accuracy Reduction (Dense-Pruned)'].values
    # pt_stds=stds['Pruned Accuracy'].values
    # dt_stds=stds['Dense Accuracy'].values
    # difference_stds=stds['Accuracy Reduction (Dense-Pruned)'].values

    # new_df = pd.DataFrame({
    #     "Pruned Test Accuracy":pt_means,
    #     "Dense Test Accuracy":dt_means,
    #     "Difference in Accuracy":difference_means,
    #     "Error PT":pt_stds,
    #     "Error DT":dt_stds,
    #     "Error difference":difference_stds,

    # })

    # def combine_mean_std(mean_and_std):
    #   mean,std =mean_and_std
    #   if mean>=10:
    #     if std>=10:
    #       return "{:0.2f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.2f}$\pm${:0.3f}".format(mean,std)
    #   else:
    #     if std>=10:
    #       return "{:0.3f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.3f}$\pm${:0.3f}".format(mean,std)

    """## 0.6"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    # level 1 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.8_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 2 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.8_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 3 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.8_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 4 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.8_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 5 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_5_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim
    # level 6 ############################ ############################ ############################ ############################ ############################ ############################

    df_level6_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_6_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level6_ekfac))
    df_level6_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level6_ekfac))
    df_level6_ekfac["optimiser"] = optim
    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level7_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_7_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level7_ekfac))
    df_level7_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level7_ekfac))
    df_level7_ekfac["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])

    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4, df_level7_ekfac, df_level6_ekfac, df_level5_ekfac])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser")
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False)

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))
    secay.set_ylabel('Absolute Pruned Accuracy')
    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)
    plt.close()

    #

    # print(len(df_level1))
    # all_df=df_level1
    # all_df["Receptive Field"]=RF
    # # sns.scatterplot(data=all_df, x="Dense Accuracy", y="Pruned Fine Tuned Accuracy", hue="Receptive Field",size="Receptive Field",sizes=(20, 200))
    # df=all_df
    # df["Accuracy Reduction (Dense-Pruned)"]= df["Dense Accuracy"]-df["Pruned Accuracy"]
    # means = df.groupby(["Receptive Field"]).mean()
    # stds =df.groupby(["Receptive Field"]).std()
    # pt_means=means['Pruned Accuracy'].values
    # dt_means=means['Dense Accuracy'].values
    # difference_means=means['Accuracy Reduction (Dense-Pruned)'].values
    # pt_stds=stds['Pruned Accuracy'].values
    # dt_stds=stds['Dense Accuracy'].values
    # difference_stds=stds['Accuracy Reduction (Dense-Pruned)'].values

    # new_df = pd.DataFrame({
    #     "Pruned Test Accuracy":pt_means,
    #     "Dense Test Accuracy":dt_means,
    #     "Difference in Accuracy":difference_means,
    #     "Error PT":pt_stds,
    #     "Error DT":dt_stds,
    #     "Error difference":difference_stds,

    # })

    # def combine_mean_std(mean_and_std):
    #   mean,std =mean_and_std
    #   if mean>=10:
    #     if std>=10:
    #       return "{:0.2f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.2f}$\pm${:0.3f}".format(mean,std)
    #   else:
    #     if std>=10:
    #       return "{:0.3f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.3f}$\pm${:0.3f}".format(mean,std)

    """## 0.8"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    # level 1 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.8_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 2 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.8_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 3 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.8_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 4 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.8_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 5 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_5_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim
    # level 6 ############################ ############################ ############################ ############################ ############################ ############################

    df_level6_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_6_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level6_ekfac))
    df_level6_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level6_ekfac))
    df_level6_ekfac["optimiser"] = optim
    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level7_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_7_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level7_ekfac))
    df_level7_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level7_ekfac))
    df_level7_ekfac["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])

    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4, df_level7_ekfac, df_level6_ekfac, df_level5_ekfac])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser", alpha=0.5)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False, alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Scaled Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)
    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))
    secay.set_ylabel('Absolute Pruned Accuracy')
    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)
    plt.close()

    #

    # print(len(df_level1))
    # all_df=df_level1
    # all_df["Receptive Field"]=RF
    # # sns.scatterplot(data=all_df, x="Dense Accuracy", y="Pruned Fine Tuned Accuracy", hue="Receptive Field",size="Receptive Field",sizes=(20, 200))
    # df=all_df
    # df["Accuracy Reduction (Dense-Pruned)"]= df["Dense Accuracy"]-df["Pruned Accuracy"]
    # means = df.groupby(["Receptive Field"]).mean()
    # stds =df.groupby(["Receptive Field"]).std()
    # pt_means=means['Pruned Accuracy'].values
    # dt_means=means['Dense Accuracy'].values
    # difference_means=means['Accuracy Reduction (Dense-Pruned)'].values
    # pt_stds=stds['Pruned Accuracy'].values
    # dt_stds=stds['Dense Accuracy'].values
    # difference_stds=stds['Accuracy Reduction (Dense-Pruned)'].values

    # new_df = pd.DataFrame({
    #     "Pruned Test Accuracy":pt_means,
    #     "Dense Test Accuracy":dt_means,
    #     "Difference in Accuracy":difference_means,
    #     "Error PT":pt_stds,
    #     "Error DT":dt_stds,
    #     "Error difference":difference_stds,

    # })

    # def combine_mean_std(mean_and_std):
    #   mean,std =mean_and_std
    #   if mean>=10:
    #     if std>=10:
    #       return "{:0.2f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.2f}$\pm${:0.3f}".format(mean,std)
    #   else:
    #     if std>=10:
    #       return "{:0.3f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.3f}$\pm${:0.3f}".format(mean,std)

    df_level3_ekfac

    (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    """## 0.9"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    resnets_rfs_values = [108, 110, 213, 318, 423, 538, 645, 752, 859, 1415, 1920, 3100]

    resnet_rfs_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]

    resnets_rfs = dict(zip(resnet_rfs_keys, resnets_rfs_values))

    # level 1 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.9_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 2 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.9_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 3 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.9_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 4 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.9_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 5 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_5_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################ ############################

    df_level6_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_6_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level6_ekfac))
    df_level6_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level6_ekfac))
    df_level6_ekfac["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level7_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_7_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level7_ekfac))
    df_level7_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level7_ekfac))
    df_level7_ekfac["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4],ignore_index=True)
    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4, df_level7_ekfac, df_level6_ekfac, df_level5_ekfac])

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser", alpha=0.5)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False, alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Scaled Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)
    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))
    secay.set_ylabel('Absolute Pruned Accuracy')
    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)
        ax.grid(ls="--")

        # plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet50_cifar10_pr_0.9_all_optimisers.pdf")
        plt.close()

    all_df_original_lrs = all_df

    all_df_original_lrs

    from matplotlib import pyplot as plt
    import seaborn as sns

    # level 1 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.9_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 2 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.9_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 3 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.9_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 4 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.9_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 5 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_5_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################ ############################

    df_level6_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_6_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level6_ekfac))
    df_level6_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level6_ekfac))
    df_level6_ekfac["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level7_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_7_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level7_ekfac))
    df_level7_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level7_ekfac))
    df_level7_ekfac["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4],ignore_index=True)
    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4, df_level7_ekfac, df_level6_ekfac, df_level5_ekfac])

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    """## 0.95"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    # level 1 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.95_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.95_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.95_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 2 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.95_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.95_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.95_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 3 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.95_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.95_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.95_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 4 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.95_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.95_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.95_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 5 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_5_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim
    # level 6 ############################ ############################ ############################ ############################ ############################ ############################

    df_level6_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_6_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level6_ekfac))
    df_level6_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level6_ekfac))
    df_level6_ekfac["optimiser"] = optim
    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level7_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_7_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level7_ekfac))
    df_level7_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level7_ekfac))
    df_level7_ekfac["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])

    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4, df_level7_ekfac, df_level6_ekfac, df_level5_ekfac])

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser")
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False)

    # sns.barplot(data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",errorbar="ci")

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))
    secay.set_ylabel('Absolute Pruned Accuracy')

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")
    for ax in axs:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        # ax.set_xlabel("RF")
        # ax.set_ylabel("Scaled Pruned Accuracy")

    plt.close()


def saturation_resnet50_cifar50_batchnorm_all_optim():
    # TODO: has not been run yet
    """# TODO: Bach norm adjusted pruning accuracies  **TODO**

    # Resnet50

    ## 0.7
    """

    from matplotlib import pyplot as plt
    import seaborn as sns

    # level 1 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.7_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.7_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.7_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 2 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.7_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.7_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.7_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 3 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.7_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.7_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.7_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 4 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.7_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.7_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.7_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 5 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_5_cifar10_0.7_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim
    # level 6 ############################ ############################ ############################ ############################ ############################ ############################

    df_level6_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_6_cifar10_0.7_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level6_ekfac))
    df_level6_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level6_ekfac))
    df_level6_ekfac["optimiser"] = optim
    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level7_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_7_cifar10_0.7_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level7_ekfac))
    df_level7_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level7_ekfac))
    df_level7_ekfac["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])

    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4, df_level7_ekfac, df_level6_ekfac, df_level5_ekfac])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser")
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False)

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))
    secay.set_ylabel('Absolute Pruned Accuracy')
    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)
    plt.close()

    #

    # print(len(df_level1))
    # all_df=df_level1
    # all_df["Receptive Field"]=RF
    # # sns.scatterplot(data=all_df, x="Dense Accuracy", y="Pruned Fine Tuned Accuracy", hue="Receptive Field",size="Receptive Field",sizes=(20, 200))
    # df=all_df
    # df["Accuracy Reduction (Dense-Pruned)"]= df["Dense Accuracy"]-df["Pruned Accuracy"]
    # means = df.groupby(["Receptive Field"]).mean()
    # stds =df.groupby(["Receptive Field"]).std()
    # pt_means=means['Pruned Accuracy'].values
    # dt_means=means['Dense Accuracy'].values
    # difference_means=means['Accuracy Reduction (Dense-Pruned)'].values
    # pt_stds=stds['Pruned Accuracy'].values
    # dt_stds=stds['Dense Accuracy'].values
    # difference_stds=stds['Accuracy Reduction (Dense-Pruned)'].values

    # new_df = pd.DataFrame({
    #     "Pruned Test Accuracy":pt_means,
    #     "Dense Test Accuracy":dt_means,
    #     "Difference in Accuracy":difference_means,
    #     "Error PT":pt_stds,
    #     "Error DT":dt_stds,
    #     "Error difference":difference_stds,

    # })

    # def combine_mean_std(mean_and_std):
    #   mean,std =mean_and_std
    #   if mean>=10:
    #     if std>=10:
    #       return "{:0.2f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.2f}$\pm${:0.3f}".format(mean,std)
    #   else:
    #     if std>=10:
    #       return "{:0.3f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.3f}$\pm${:0.3f}".format(mean,std)

    """## 0.6"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    # level 1 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.8_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 2 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.8_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 3 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.8_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 4 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.8_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 5 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_5_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim
    # level 6 ############################ ############################ ############################ ############################ ############################ ############################

    df_level6_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_6_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level6_ekfac))
    df_level6_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level6_ekfac))
    df_level6_ekfac["optimiser"] = optim
    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level7_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_7_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level7_ekfac))
    df_level7_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level7_ekfac))
    df_level7_ekfac["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])

    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4, df_level7_ekfac, df_level6_ekfac, df_level5_ekfac])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser")
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False)

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))
    secay.set_ylabel('Absolute Pruned Accuracy')
    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)
    plt.close()

    #

    # print(len(df_level1))
    # all_df=df_level1
    # all_df["Receptive Field"]=RF
    # # sns.scatterplot(data=all_df, x="Dense Accuracy", y="Pruned Fine Tuned Accuracy", hue="Receptive Field",size="Receptive Field",sizes=(20, 200))
    # df=all_df
    # df["Accuracy Reduction (Dense-Pruned)"]= df["Dense Accuracy"]-df["Pruned Accuracy"]
    # means = df.groupby(["Receptive Field"]).mean()
    # stds =df.groupby(["Receptive Field"]).std()
    # pt_means=means['Pruned Accuracy'].values
    # dt_means=means['Dense Accuracy'].values
    # difference_means=means['Accuracy Reduction (Dense-Pruned)'].values
    # pt_stds=stds['Pruned Accuracy'].values
    # dt_stds=stds['Dense Accuracy'].values
    # difference_stds=stds['Accuracy Reduction (Dense-Pruned)'].values

    # new_df = pd.DataFrame({
    #     "Pruned Test Accuracy":pt_means,
    #     "Dense Test Accuracy":dt_means,
    #     "Difference in Accuracy":difference_means,
    #     "Error PT":pt_stds,
    #     "Error DT":dt_stds,
    #     "Error difference":difference_stds,

    # })

    # def combine_mean_std(mean_and_std):
    #   mean,std =mean_and_std
    #   if mean>=10:
    #     if std>=10:
    #       return "{:0.2f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.2f}$\pm${:0.3f}".format(mean,std)
    #   else:
    #     if std>=10:
    #       return "{:0.3f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.3f}$\pm${:0.3f}".format(mean,std)

    """## 0.8"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    # level 1 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.8_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 2 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.8_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 3 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.8_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 4 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.8_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.8_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 5 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_5_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim
    # level 6 ############################ ############################ ############################ ############################ ############################ ############################

    df_level6_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_6_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level6_ekfac))
    df_level6_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level6_ekfac))
    df_level6_ekfac["optimiser"] = optim
    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level7_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_7_cifar10_0.8_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level7_ekfac))
    df_level7_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level7_ekfac))
    df_level7_ekfac["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])

    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4, df_level7_ekfac, df_level6_ekfac, df_level5_ekfac])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser", alpha=0.5)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False, alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Scaled Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)
    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))
    secay.set_ylabel('Absolute Pruned Accuracy')
    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)
    plt.close()

    #

    # print(len(df_level1))
    # all_df=df_level1
    # all_df["Receptive Field"]=RF
    # # sns.scatterplot(data=all_df, x="Dense Accuracy", y="Pruned Fine Tuned Accuracy", hue="Receptive Field",size="Receptive Field",sizes=(20, 200))
    # df=all_df
    # df["Accuracy Reduction (Dense-Pruned)"]= df["Dense Accuracy"]-df["Pruned Accuracy"]
    # means = df.groupby(["Receptive Field"]).mean()
    # stds =df.groupby(["Receptive Field"]).std()
    # pt_means=means['Pruned Accuracy'].values
    # dt_means=means['Dense Accuracy'].values
    # difference_means=means['Accuracy Reduction (Dense-Pruned)'].values
    # pt_stds=stds['Pruned Accuracy'].values
    # dt_stds=stds['Dense Accuracy'].values
    # difference_stds=stds['Accuracy Reduction (Dense-Pruned)'].values

    # new_df = pd.DataFrame({
    #     "Pruned Test Accuracy":pt_means,
    #     "Dense Test Accuracy":dt_means,
    #     "Difference in Accuracy":difference_means,
    #     "Error PT":pt_stds,
    #     "Error DT":dt_stds,
    #     "Error difference":difference_stds,

    # })

    # def combine_mean_std(mean_and_std):
    #   mean,std =mean_and_std
    #   if mean>=10:
    #     if std>=10:
    #       return "{:0.2f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.2f}$\pm${:0.3f}".format(mean,std)
    #   else:
    #     if std>=10:
    #       return "{:0.3f}$\pm${:0.2f}".format(mean,std)
    #     else:
    #       return "{:0.3f}$\pm${:0.3f}".format(mean,std)

    df_level3_ekfac

    (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    """## 0.9"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    # level 1 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.9_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 2 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.9_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 3 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.9_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 4 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.9_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 5 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_5_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################ ############################

    df_level6_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_6_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level6_ekfac))
    df_level6_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level6_ekfac))
    df_level6_ekfac["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level7_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_7_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level7_ekfac))
    df_level7_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level7_ekfac))
    df_level7_ekfac["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4],ignore_index=True)
    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4, df_level7_ekfac, df_level6_ekfac, df_level5_ekfac])

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser", alpha=0.5)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False, alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Scaled Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)
    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))
    secay.set_ylabel('Absolute Pruned Accuracy')
    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)
    plt.close()

    from matplotlib import pyplot as plt
    import seaborn as sns

    # level 1 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.9_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 2 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.9_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 3 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.9_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 4 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.9_sam_optim_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.9_recording_200_global_one_shot_summary.csv", delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 5 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_5_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################ ############################

    df_level6_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_6_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level6_ekfac))
    df_level6_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level6_ekfac))
    df_level6_ekfac["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level7_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_7_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level7_ekfac))
    df_level7_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level7_ekfac))
    df_level7_ekfac["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4],ignore_index=True)
    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4, df_level7_ekfac, df_level6_ekfac, df_level5_ekfac])

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100
    all_df_orignal_lrs = all_df

    all_df_orignal_lrs

    """## 0.95"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    # level 1 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.95_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.95_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_1_cifar10_0.95_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 2 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.95_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.95_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_2_cifar10_0.95_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 3 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.95_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.95_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_3_cifar10_0.95_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 4 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.95_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.95_sam_optim_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "second_order_pruning/RF_resnet50_4_cifar10_0.95_recording_200_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 5 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_5_cifar10_0.95_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim
    # level 6 ############################ ############################ ############################ ############################ ############################ ############################

    df_level6_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_6_cifar10_0.95_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level6_ekfac))
    df_level6_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level6_ekfac))
    df_level6_ekfac["optimiser"] = optim
    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level7_ekfac = pd.read_csv(
        "second_order_pruning/RF_resnet50_7_cifar10_0.95_ekfac_optim_hyper_saturation_200_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level7_ekfac))
    df_level7_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level7_ekfac))
    df_level7_ekfac["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])

    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4, df_level7_ekfac, df_level6_ekfac, df_level5_ekfac])

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser")
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False)

    # sns.barplot(data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",errorbar="ci")

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))
    secay.set_ylabel('Absolute Pruned Accuracy')

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")
    for ax in axs:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        # ax.set_xlabel("RF")
        # ax.set_ylabel("Scaled Pruned Accuracy")

    plt.close()


def weight_inspection_resnet50_cifar10():
    """# TODO: weight inspection of ResNet50"""

    from matplotlib import pyplot as plt
    import seaborn as sns
    import pickle
    def read_string(name):
        with open(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/{name}.pkl", "rb") as f:
            return pickle.load(f)

    # CDFs

    ## Means

    ###Level1

    cdf_mean_1_sgd = read_string("resnet50_cifar10_1_recording_200_whole_model_cdf_mean")
    cdf_mean_1_sam = read_string("resnet50_cifar10_1_sam_optim_saturation_200_gc_0_whole_model_cdf_mean")
    cdf_mean_1_ekfac = read_string("resnet50_cifar10_1_ekfac_optim_hyper_saturation_200_gc_0_whole_model_cdf_mean")

    ###Level2

    cdf_mean_2_sgd = read_string("resnet50_cifar10_2_recording_200_whole_model_cdf_mean")
    cdf_mean_2_sam = read_string("resnet50_cifar10_2_sam_optim_saturation_200_gc_0_whole_model_cdf_mean")
    cdf_mean_2_ekfac = read_string("resnet50_cifar10_2_ekfac_optim_hyper_saturation_200_gc_0_whole_model_cdf_mean")

    ###Level3

    cdf_mean_3_sgd = read_string("resnet50_cifar10_3_recording_200_whole_model_cdf_mean")
    cdf_mean_3_sam = read_string("resnet50_cifar10_3_sam_optim_saturation_200_gc_0_whole_model_cdf_mean")
    cdf_mean_3_ekfac = read_string("resnet50_cifar10_3_ekfac_optim_hyper_saturation_200_gc_0_whole_model_cdf_mean")

    ###Level4

    cdf_mean_4_sgd = read_string("resnet50_cifar10_4_recording_200_whole_model_cdf_mean")
    cdf_mean_4_sam = read_string("resnet50_cifar10_4_sam_optim_saturation_200_gc_0_whole_model_cdf_mean")
    cdf_mean_4_ekfac = read_string("resnet50_cifar10_4_ekfac_optim_hyper_saturation_200_gc_0_whole_model_cdf_mean")

    ## STD
    ###Level1

    cdf_std_1_sgd = read_string("resnet50_cifar10_1_recording_200_whole_model_cdf_std")
    cdf_std_1_sam = read_string("resnet50_cifar10_1_sam_optim_saturation_200_gc_0_whole_model_cdf_std")
    cdf_std_1_ekfac = read_string("resnet50_cifar10_1_ekfac_optim_hyper_saturation_200_gc_0_whole_model_cdf_std")

    ###Level2

    cdf_std_2_sgd = read_string("resnet50_cifar10_2_recording_200_whole_model_cdf_std")
    cdf_std_2_sam = read_string("resnet50_cifar10_2_sam_optim_saturation_200_gc_0_whole_model_cdf_std")
    cdf_std_2_ekfac = read_string("resnet50_cifar10_2_ekfac_optim_hyper_saturation_200_gc_0_whole_model_cdf_std")
    ###Level3

    cdf_std_3_sgd = read_string("resnet50_cifar10_3_recording_200_whole_model_cdf_std")
    cdf_std_3_sam = read_string("resnet50_cifar10_3_sam_optim_saturation_200_gc_0_whole_model_cdf_std")
    cdf_std_3_ekfac = read_string("resnet50_cifar10_3_ekfac_optim_hyper_saturation_200_gc_0_whole_model_cdf_std")

    ###Level4

    cdf_std_4_sgd = read_string("resnet50_cifar10_4_recording_200_whole_model_cdf_std")
    cdf_std_4_sam = read_string("resnet50_cifar10_4_sam_optim_saturation_200_gc_0_whole_model_cdf_std")
    cdf_std_4_ekfac = read_string("resnet50_cifar10_4_ekfac_optim_hyper_saturation_200_gc_0_whole_model_cdf_std")

    ## Bins
    cfd_bins_1_sgd = read_string("resnet50_cifar10_1_recording_200_whole_model_cdf_bin")

    # histograms  abs range(0,0.1)

    ## Means

    ###Level1
    histogram_abs_mean_1_sgd = read_string("resnet50_cifar10_1_recording_200_whole_model_histogram_abs_mean")
    histogram_abs_mean_1_sam = read_string(
        "resnet50_cifar10_1_sam_optim_saturation_200_gc_0_whole_model_histogram_abs_mean")
    histogram_abs_mean_1_ekfac = read_string(
        "resnet50_cifar10_1_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_abs_mean")

    ###Level2
    histogram_abs_mean_2_sgd = read_string("resnet50_cifar10_2_recording_200_whole_model_histogram_abs_mean")
    histogram_abs_mean_2_sam = read_string(
        "resnet50_cifar10_2_sam_optim_saturation_200_gc_0_whole_model_histogram_abs_mean")
    histogram_abs_mean_2_ekfac = read_string(
        "resnet50_cifar10_2_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_abs_mean")
    ###Level3
    histogram_abs_mean_3_sgd = read_string("resnet50_cifar10_3_recording_200_whole_model_histogram_abs_mean")
    histogram_abs_mean_3_sam = read_string(
        "resnet50_cifar10_3_sam_optim_saturation_200_gc_0_whole_model_histogram_abs_mean")
    histogram_abs_mean_3_ekfac = read_string(
        "resnet50_cifar10_3_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_abs_mean")
    ###Level4
    histogram_abs_mean_4_sgd = read_string("resnet50_cifar10_4_recording_200_whole_model_histogram_abs_mean")
    histogram_abs_mean_4_sam = read_string(
        "resnet50_cifar10_4_sam_optim_saturation_200_gc_0_whole_model_histogram_abs_mean")
    histogram_abs_mean_4_ekfac = read_string(
        "resnet50_cifar10_4_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_abs_mean")
    ## STD
    ###Level1
    histogram_abs_std_1_sgd = read_string("resnet50_cifar10_1_recording_200_whole_model_histogram_abs_std")
    histogram_abs_std_1_sam = read_string(
        "resnet50_cifar10_1_sam_optim_saturation_200_gc_0_whole_model_histogram_abs_std")
    histogram_abs_std_1_ekfac = read_string(
        "resnet50_cifar10_1_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_abs_std")
    ###Level2
    histogram_abs_std_2_sgd = read_string("resnet50_cifar10_2_recording_200_whole_model_histogram_abs_std")
    histogram_abs_std_2_sam = read_string(
        "resnet50_cifar10_2_sam_optim_saturation_200_gc_0_whole_model_histogram_abs_std")
    histogram_abs_std_2_ekfac = read_string(
        "resnet50_cifar10_2_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_abs_std")
    ###Level3
    histogram_abs_std_3_sgd = read_string("resnet50_cifar10_3_recording_200_whole_model_histogram_abs_std")
    histogram_abs_std_3_sam = read_string(
        "resnet50_cifar10_3_sam_optim_saturation_200_gc_0_whole_model_histogram_abs_std")
    histogram_abs_std_3_ekfac = read_string(
        "resnet50_cifar10_3_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_abs_std")

    ###Level4
    histogram_abs_std_4_sgd = read_string("resnet50_cifar10_4_recording_200_whole_model_histogram_abs_std")
    histogram_abs_std_4_sam = read_string(
        "resnet50_cifar10_4_sam_optim_saturation_200_gc_0_whole_model_histogram_abs_std")
    histogram_abs_std_4_ekfac = read_string(
        "resnet50_cifar10_4_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_abs_std")

    ## Bin

    histogram_abs_bins_1_sgd = read_string("resnet50_cifar10_1_recording_200_whole_model_histogram_abs_bin")

    # histograms  range (-0.1.0.1)

    ## Means
    ###Level1
    histogram_mean_1_sgd = read_string("resnet50_cifar10_1_recording_200_whole_model_histogram_mean")
    histogram_mean_1_sam = read_string("resnet50_cifar10_1_sam_optim_saturation_200_gc_0_whole_model_histogram_mean")
    histogram_mean_1_ekfac = read_string(
        "resnet50_cifar10_1_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_mean")

    ###Level2
    histogram_mean_2_sgd = read_string("resnet50_cifar10_2_recording_200_whole_model_histogram_mean")
    histogram_mean_2_sam = read_string("resnet50_cifar10_2_sam_optim_saturation_200_gc_0_whole_model_histogram_mean")
    histogram_mean_2_ekfac = read_string(
        "resnet50_cifar10_2_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_mean")

    ###Level3
    histogram_mean_3_sgd = read_string("resnet50_cifar10_3_recording_200_whole_model_histogram_mean")
    histogram_mean_3_sam = read_string("resnet50_cifar10_3_sam_optim_saturation_200_gc_0_whole_model_histogram_mean")
    histogram_mean_3_ekfac = read_string(
        "resnet50_cifar10_3_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_mean")
    ###Level4
    histogram_mean_4_sgd = read_string("resnet50_cifar10_4_recording_200_whole_model_histogram_mean")
    histogram_mean_4_sam = read_string("resnet50_cifar10_4_sam_optim_saturation_200_gc_0_whole_model_histogram_mean")
    histogram_mean_4_ekfac = read_string(
        "resnet50_cifar10_4_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_mean")
    ## STD
    ###Level1
    histogram_std_1_sgd = read_string("resnet50_cifar10_1_recording_200_whole_model_histogram_std")
    histogram_std_1_sam = read_string("resnet50_cifar10_1_sam_optim_saturation_200_gc_0_whole_model_histogram_std")
    histogram_std_1_ekfac = read_string(
        "resnet50_cifar10_1_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_std")
    ###Level2
    histogram_std_2_sgd = read_string("resnet50_cifar10_2_recording_200_whole_model_histogram_std")
    histogram_std_2_sam = read_string("resnet50_cifar10_2_sam_optim_saturation_200_gc_0_whole_model_histogram_std")
    histogram_std_2_ekfac = read_string(
        "resnet50_cifar10_2_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_std")
    ###Level3
    histogram_std_3_sgd = read_string("resnet50_cifar10_3_recording_200_whole_model_histogram_std")
    histogram_std_3_sam = read_string("resnet50_cifar10_3_sam_optim_saturation_200_gc_0_whole_model_histogram_std")
    histogram_std_3_ekfac = read_string(
        "resnet50_cifar10_3_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_std")
    ###Level4
    histogram_std_4_sgd = read_string("resnet50_cifar10_4_recording_200_whole_model_histogram_std")
    histogram_std_4_sam = read_string("resnet50_cifar10_4_sam_optim_saturation_200_gc_0_whole_model_histogram_std")
    histogram_std_4_ekfac = read_string(
        "resnet50_cifar10_4_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_std")

    ## Bin
    histogram_bins_1_sgd = read_string("resnet50_cifar10_1_recording_200_whole_model_histogram_bin")

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    def get_percentile_value(mean, bin, percentile):
        percentile_index = find_nearest(mean, percentile)
        value = bin[percentile_index]
        return value

    resnets_rfs = [108, 110, 213, 318, 423, 1415, 1920, 3100]

    percentile_95 = []
    optim = []
    learning_rate = []
    rf = []

    percentile_95_mean_1_sgd = get_percentile_value(cdf_mean_1_sgd, cfd_bins_1_sgd, 0.95)
    percentile_95.append(percentile_95_mean_1_sgd)
    optim.append("SGD")
    learning_rate.append(0.1)
    rf.append(resnets_rfs[1])
    percentile_95_mean_1_sam = get_percentile_value(cdf_mean_1_sam, cfd_bins_1_sgd, 0.95)
    percentile_95.append(percentile_95_mean_1_sam)
    optim.append("SAM")
    learning_rate.append(0.1)
    rf.append(resnets_rfs[1])
    percentile_95_mean_1_ekfac = get_percentile_value(cdf_mean_1_ekfac, cfd_bins_1_sgd, 0.95)

    percentile_95.append(percentile_95_mean_1_ekfac)
    optim.append("EKFAC")
    learning_rate.append(0.01)

    rf.append(resnets_rfs[1])

    percentile_95_mean_2_sgd = get_percentile_value(cdf_mean_2_sgd, cfd_bins_1_sgd, 0.95)
    percentile_95.append(percentile_95_mean_2_sgd)
    optim.append("SGD")
    learning_rate.append(0.1)

    rf.append(resnets_rfs[2])

    percentile_95_mean_2_sam = get_percentile_value(cdf_mean_2_sam, cfd_bins_1_sgd, 0.95)

    percentile_95.append(percentile_95_mean_2_sam)
    optim.append("SAM")
    learning_rate.append(0.1)

    rf.append(resnets_rfs[2])

    percentile_95_mean_2_ekfac = get_percentile_value(cdf_mean_2_ekfac, cfd_bins_1_sgd, 0.95)

    percentile_95.append(percentile_95_mean_2_ekfac)
    optim.append("EKFAC")
    learning_rate.append(0.01)

    rf.append(resnets_rfs[2])

    percentile_95_mean_3_sgd = get_percentile_value(cdf_mean_3_sgd, cfd_bins_1_sgd, 0.95)

    percentile_95.append(percentile_95_mean_3_sgd)
    optim.append("SGD")
    learning_rate.append(0.1)

    rf.append(resnets_rfs[3])

    percentile_95_mean_3_sam = get_percentile_value(cdf_mean_3_sam, cfd_bins_1_sgd, 0.95)
    percentile_95.append(percentile_95_mean_3_sam)
    optim.append("SAM")
    learning_rate.append(0.1)

    rf.append(resnets_rfs[3])

    percentile_95_mean_3_ekfac = get_percentile_value(cdf_mean_3_ekfac, cfd_bins_1_sgd, 0.95)

    percentile_95.append(percentile_95_mean_3_ekfac)
    optim.append("EKFAC")
    learning_rate.append(0.01)

    rf.append(resnets_rfs[3])

    percentile_95_mean_4_sgd = get_percentile_value(cdf_mean_4_sgd, cfd_bins_1_sgd, 0.95)

    percentile_95.append(percentile_95_mean_4_sgd)
    optim.append("SGD")
    learning_rate.append(0.1)

    rf.append(resnets_rfs[4])

    percentile_95_mean_4_sam = get_percentile_value(cdf_mean_4_sam, cfd_bins_1_sgd, 0.95)

    percentile_95.append(percentile_95_mean_4_sam)
    optim.append("SAM")
    learning_rate.append(0.1)

    rf.append(resnets_rfs[4])

    percentile_95_mean_4_ekfac = get_percentile_value(cdf_mean_4_ekfac, cfd_bins_1_sgd, 0.95)

    percentile_95.append(percentile_95_mean_4_ekfac)
    optim.append("EKFAC")
    learning_rate.append(0.01)

    rf.append(resnets_rfs[4])

    df = pd.DataFrame(
        {"95 Percentile": percentile_95, "Optimiser": optim, "Learning Rate": learning_rate, "Receptive Field": rf})

    df

    # all_cdf_mean = [cdf_mean_1_sgd,cdf_mean_1_sam,cdf_mean_1_ekfac]
    # all_cdf_std = [cdf_std_1_sgd,cdf_std_1_sam,cdf_std_1_ekfac]
    # labels=["SGD","ASAM","EKFAC"]

    """## CDFs"""

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')
    import gc

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_cdf_mean = [cdf_mean_1_sgd, cdf_mean_1_sam, cdf_mean_1_ekfac]
    all_cdf_std = [cdf_std_1_sgd, cdf_std_1_sam, cdf_std_1_ekfac]
    labels = ["SGD", "ASAM", "EKFAC"]

    for i in range(len(all_cdf_mean)):
        mean = all_cdf_mean[i]
        std = all_cdf_std[i]
        label = labels[i]
        bin_count = cfd_bins_1_sgd[1:]
        axs.plot(bin_count, mean, label=labels[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")

    plt.yscale("log")
    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("$|w|$")
    plt.ylabel("CDF")
    plt.xlim(0, 0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_cdf_resnet_50_cifar10_level1.pdf")
    del all_cdf_mean
    del all_cdf_std
    fig.clf()
    plt.close()
    gc.collect()

    # del all_cdf_mean
    # del all_cdf_std
    # del fig

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')
    import gc

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_cdf_mean = [cdf_mean_2_sgd, cdf_mean_2_sam, cdf_mean_2_ekfac]
    all_cdf_std = [cdf_std_2_sgd, cdf_std_2_sam, cdf_std_2_ekfac]
    labels = ["SGD", "ASAM", "EKFAC"]

    for i in range(len(all_cdf_mean)):
        mean = all_cdf_mean[i]
        std = all_cdf_std[i]
        label = labels[i]
        bin_count = cfd_bins_1_sgd[1:]
        axs.plot(bin_count, mean, label=labels[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")
    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("Weight")
    plt.xlabel("$|w|$")
    plt.ylabel("CDF")
    plt.xlim(0, 0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_cdf_resnet_50_cifar10_level2.pdf")
    del all_cdf_mean
    del all_cdf_std
    fig.clf()
    plt.close()
    gc.collect()

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_cdf_mean = [cdf_mean_3_sgd, cdf_mean_3_sam, cdf_mean_3_ekfac]
    all_cdf_std = [cdf_std_3_sgd, cdf_std_3_sam, cdf_std_3_ekfac]
    labels = ["SGD", "ASAM", "EKFAC"]

    for i in range(len(all_cdf_mean)):
        mean = all_cdf_mean[i]
        std = all_cdf_std[i]
        label = labels[i]
        bin_count = cfd_bins_1_sgd[1:]
        axs.plot(bin_count, mean, label=labels[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")

    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("Weight")
    plt.xlabel("$|w|$")
    plt.ylabel("CDF")
    plt.xlim(0, 0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_cdf_resnet_50_cifar10_level3.pdf")
    plt.close()

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_cdf_mean = [cdf_mean_4_sgd, cdf_mean_4_sam, cdf_mean_4_ekfac]
    all_cdf_std = [cdf_std_4_sgd, cdf_std_4_sam, cdf_std_4_ekfac]
    labels = ["SGD", "ASAM", "EKFAC"]

    for i in range(len(all_cdf_mean)):
        mean = all_cdf_mean[i]
        std = all_cdf_std[i]
        label = labels[i]
        bin_count = cfd_bins_1_sgd[1:]
        axs.plot(bin_count, mean, label=labels[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")

    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("Weight")
    plt.xlabel("$|w|$")
    plt.ylabel("CDF")
    plt.xlim(0, 0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_cdf_resnet_50_cifar10_level4.pdf")
    plt.close()

    """## histograms"""

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_histogram_mean = [histogram_mean_1_sgd, histogram_mean_1_sam, histogram_mean_1_ekfac]
    all_histogram_std = [histogram_std_1_sgd, histogram_std_1_sam, histogram_std_1_ekfac]
    labels = ["SGD", "ASAM", "EKFAC"]
    alphas = [0.6, 0.5, 0.4]
    for i in range(len(all_histogram_mean)):
        mean = all_histogram_mean[i]
        std = all_histogram_std[i]
        label = labels[i]
        bin_count = histogram_bins_1_sgd[1:]
        # plt.hist(mean,bins=bin_count,label=labels[i])
        axs.bar(x=bin_count, height=mean, width=0.0002, align='edge', label=labels[i], alpha=alphas[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")

    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("Weight")
    plt.ylabel("Count")
    # plt.xlim(0,0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_histogram_resnet_50_cifar10_level1.pdf")
    plt.close()

    np.diff(bin_count)

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_histogram_mean = [histogram_mean_2_sgd, histogram_mean_2_sam, histogram_mean_2_ekfac]
    all_histogram_std = [histogram_std_2_sgd, histogram_std_2_sam, histogram_std_2_ekfac]
    labels = ["SGD", "ASAM", "EKFAC"]

    for i in range(len(all_histogram_mean)):
        mean = all_histogram_mean[i]
        std = all_histogram_std[i]
        label = labels[i]
        bin_count = histogram_bins_1_sgd[1:]
        # plt.hist(mean,bins=bin_count,label=labels[i])
        axs.bar(x=bin_count, height=mean, width=0.0002, align='edge', label=labels[i], alpha=alphas[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")

    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("Weight")
    plt.ylabel("Count")
    # plt.xlim(0,0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_histogram_resnet_50_cifar10_level2.pdf")
    plt.close()

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_histogram_mean = [histogram_mean_3_sgd, histogram_mean_3_sam, histogram_mean_3_ekfac]
    all_histogram_std = [histogram_std_3_sgd, histogram_std_3_sam, histogram_std_3_ekfac]
    labels = ["SGD", "ASAM", "EKFAC"]

    for i in range(len(all_histogram_mean)):
        mean = all_histogram_mean[i]
        std = all_histogram_std[i]
        label = labels[i]
        bin_count = histogram_bins_1_sgd[1:]
        # plt.hist(mean,bins=bin_count,label=labels[i])
        axs.bar(x=bin_count, height=mean, width=0.0002, align='edge', label=labels[i], alpha=alphas[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")

    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("Weight")
    plt.ylabel("Count")
    # plt.xlim(0,0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_histogram_resnet_50_cifar10_level3.pdf")
    plt.close()

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_histogram_mean = [histogram_mean_4_sgd, histogram_mean_4_sam, histogram_mean_4_ekfac]
    all_histogram_std = [histogram_std_4_sgd, histogram_std_4_sam, histogram_std_4_ekfac]
    labels = ["SGD", "ASAM", "EKFAC"]

    for i in range(len(all_histogram_mean)):
        mean = all_histogram_mean[i]
        std = all_histogram_std[i]
        label = labels[i]
        bin_count = histogram_bins_1_sgd[1:]
        # plt.hist(mean,bins=bin_count,label=labels[i])
        axs.bar(x=bin_count, height=mean, width=0.0002, align='edge', label=labels[i], alpha=alphas[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")

    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("Weight")
    plt.ylabel("Count")
    # plt.xlim(0,0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_histogram_resnet_50_cifar10_level4.pdf")
    plt.close()

    """## histograms abs"""

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_histogram_abs_mean = [histogram_abs_mean_1_sgd, histogram_abs_mean_1_sam, histogram_abs_mean_1_ekfac]
    all_histogram_abs_std = [histogram_abs_std_1_sgd, histogram_abs_std_1_sam, histogram_abs_std_1_ekfac]
    labels = ["SGD", "ASAM", "EKFAC"]

    for i in range(len(all_histogram_abs_mean)):
        mean = all_histogram_abs_mean[i]
        std = all_histogram_abs_std[i]
        label = labels[i]
        bin_count = histogram_abs_bins_1_sgd[1:]
        # plt.hist(mean,bins=bin_count,label=labels[i])
        axs.bar(x=bin_count, height=mean, width=0.0002, align='edge', label=labels[i], alpha=alphas[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")

    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("Weight Magnitude")
    plt.ylabel("Count")
    # plt.xlim(0,0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_histogram_abs_resnet_50_cifar10_level1.pdf")
    plt.close()

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_histogram_abs_mean = [histogram_abs_mean_2_sgd, histogram_abs_mean_2_sam, histogram_abs_mean_2_ekfac]
    all_histogram_abs_std = [histogram_abs_std_2_sgd, histogram_abs_std_2_sam, histogram_abs_std_2_ekfac]
    labels = ["SGD", "ASAM", "EKFAC"]

    for i in range(len(all_histogram_abs_mean)):
        mean = all_histogram_abs_mean[i]
        std = all_histogram_abs_std[i]
        label = labels[i]
        bin_count = histogram_abs_bins_1_sgd[1:]
        # axs.plot(bin_count, mean,label=labels[i])
        axs.bar(x=bin_count, height=mean, width=0.0002, align='edge', label=labels[i], alpha=alphas[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")

    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("Weight")
    plt.ylabel("Count")
    # plt.xlim(0,0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_histogram_abs_resnet_50_cifar10_level2.pdf")
    plt.close()

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_histogram_abs_mean = [histogram_abs_mean_3_sgd, histogram_abs_mean_3_sam, histogram_abs_mean_3_ekfac]
    all_histogram_abs_std = [histogram_abs_std_3_sgd, histogram_abs_std_3_sam, histogram_abs_std_3_ekfac]
    labels = ["SGD", "ASAM", "EKFAC"]

    for i in range(len(all_histogram_abs_mean)):
        mean = all_histogram_abs_mean[i]
        std = all_histogram_abs_std[i]
        label = labels[i]
        bin_count = histogram_abs_bins_1_sgd[1:]
        # axs.plot(bin_count, mean,label=labels[i])
        axs.bar(x=bin_count, height=mean, width=0.0002, align='edge', label=labels[i], alpha=alphas[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")

    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("Weight")
    plt.ylabel("Count")
    # plt.xlim(0,0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_histogram_abs_resnet_50_cifar10_level3.pdf")
    plt.close()

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_histogram_abs_mean = [histogram_abs_mean_4_sgd, histogram_abs_mean_4_sam, histogram_abs_mean_4_ekfac]
    all_histogram_abs_std = [histogram_abs_std_4_sgd, histogram_abs_std_4_sam, histogram_abs_std_4_ekfac]
    labels = ["SGD", "ASAM", "EKFAC"]

    for i in range(len(all_histogram_abs_mean)):
        mean = all_histogram_abs_mean[i]
        std = all_histogram_abs_std[i]
        label = labels[i]
        bin_count = histogram_abs_bins_1_sgd[1:]
        # axs.plot(bin_count, mean,label=labels[i])
        axs.bar(x=bin_count, height=mean, width=0.0002, align='edge', label=labels[i], alpha=alphas[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")

    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("Weight")
    plt.ylabel("Count")
    # plt.xlim(0,0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_histogram_abs_resnet_50_cifar10_level4.pdf")
    plt.close()


def weight_inspection_resnet50_cifar10_lr_truncated_50_and_all_sat_and_pruning_plots():
    """# TODO: ResNet50 with truncated lr
    Here the following is true

    * EKFAC: 0.1
    * ASAM: 0.01
    * SGD: 0.01
    """

    from matplotlib import pyplot as plt
    import seaborn as sns
    import pickle
    def read_string(name):
        with open(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/{name}.pkl", "rb") as f:
            return pickle.load(f)

    # CDFs

    ## Means

    ###Level1

    cdf_mean_1_sgd = read_string("resnet50_cifar10_1_sgd_200_res_32_lr_0.01_whole_model_cdf_mean")
    cdf_mean_1_sam = read_string("resnet50_cifar10_1_lr_changed_sam_200_res_32_gc_0_whole_model_cdf_mean")
    cdf_mean_1_ekfac = read_string("resnet50_cifar10_1_lr_changed_ekfac_200_res_32_gc_0_whole_model_cdf_mean")

    ###Level2

    cdf_mean_2_sgd = read_string("resnet50_cifar10_2_sgd_200_res_32_lr_0.01_whole_model_cdf_mean")
    cdf_mean_2_sam = read_string("resnet50_cifar10_2_lr_changed_sam_200_res_32_gc_0_whole_model_cdf_mean")
    cdf_mean_2_ekfac = read_string("resnet50_cifar10_2_lr_changed_ekfac_200_res_32_gc_0_whole_model_cdf_mean")

    ###Level3

    cdf_mean_3_sgd = read_string("resnet50_cifar10_3_sgd_200_res_32_lr_0.01_whole_model_cdf_mean")
    cdf_mean_3_sam = read_string("resnet50_cifar10_3_lr_changed_sam_200_res_32_gc_0_whole_model_cdf_mean")
    cdf_mean_3_ekfac = read_string("resnet50_cifar10_3_lr_changed_ekfac_200_res_32_gc_0_whole_model_cdf_mean")

    ###Level4

    cdf_mean_4_sgd = read_string("resnet50_cifar10_4_sgd_200_res_32_lr_0.01_whole_model_cdf_mean")
    cdf_mean_4_sam = read_string("resnet50_cifar10_4_lr_changed_sam_200_res_32_gc_0_whole_model_cdf_mean")
    cdf_mean_4_ekfac = read_string("resnet50_cifar10_4_lr_changed_ekfac_200_res_32_gc_0_whole_model_cdf_mean")

    ## STD
    ###Level1

    cdf_std_1_sgd = read_string("resnet50_cifar10_1_sgd_200_res_32_lr_0.01_whole_model_cdf_std")
    cdf_std_1_sam = read_string("resnet50_cifar10_1_lr_changed_sam_200_res_32_gc_0_whole_model_cdf_std")
    cdf_std_1_ekfac = read_string("resnet50_cifar10_1_lr_changed_ekfac_200_res_32_gc_0_whole_model_cdf_std")

    ###Level2

    cdf_std_2_sgd = read_string("resnet50_cifar10_2_sgd_200_res_32_lr_0.01_whole_model_cdf_std")
    cdf_std_2_sam = read_string("resnet50_cifar10_2_lr_changed_sam_200_res_32_gc_0_whole_model_cdf_std")
    cdf_std_2_ekfac = read_string("resnet50_cifar10_2_lr_changed_ekfac_200_res_32_gc_0_whole_model_cdf_std")
    ###Level3

    cdf_std_3_sgd = read_string("resnet50_cifar10_3_sgd_200_res_32_lr_0.01_whole_model_cdf_std")
    cdf_std_3_sam = read_string("resnet50_cifar10_3_lr_changed_sam_200_res_32_gc_0_whole_model_cdf_std")
    cdf_std_3_ekfac = read_string("resnet50_cifar10_3_lr_changed_ekfac_200_res_32_gc_0_whole_model_cdf_std")

    ###Level4

    cdf_std_4_sgd = read_string("resnet50_cifar10_4_sgd_200_res_32_lr_0.01_whole_model_cdf_std")
    cdf_std_4_sam = read_string("resnet50_cifar10_4_lr_changed_sam_200_res_32_gc_0_whole_model_cdf_std")
    cdf_std_4_ekfac = read_string("resnet50_cifar10_4_lr_changed_ekfac_200_res_32_gc_0_whole_model_cdf_std")

    ## Bins
    cfd_bins_1_sgd = read_string("resnet50_cifar10_1_sgd_200_res_32_lr_0.01_whole_model_cdf_bin")

    # histograms  abs range(0,0.1)

    ## Means

    ###Level1
    histogram_abs_mean_1_sgd = read_string("resnet50_cifar10_1_sgd_200_res_32_lr_0.01_whole_model_histogram_abs_mean")
    histogram_abs_mean_1_sam = read_string(
        "resnet50_cifar10_1_lr_changed_sam_200_res_32_gc_0_whole_model_histogram_abs_mean")
    histogram_abs_mean_1_ekfac = read_string(
        "resnet50_cifar10_1_lr_changed_ekfac_200_res_32_gc_0_whole_model_histogram_abs_mean")

    ###Level2
    histogram_abs_mean_2_sgd = read_string("resnet50_cifar10_2_sgd_200_res_32_lr_0.01_whole_model_histogram_abs_mean")
    histogram_abs_mean_2_sam = read_string(
        "resnet50_cifar10_2_lr_changed_sam_200_res_32_gc_0_whole_model_histogram_abs_mean")
    histogram_abs_mean_2_ekfac = read_string(
        "resnet50_cifar10_2_lr_changed_ekfac_200_res_32_gc_0_whole_model_histogram_abs_mean")
    ###Level3
    histogram_abs_mean_3_sgd = read_string("resnet50_cifar10_3_sgd_200_res_32_lr_0.01_whole_model_histogram_abs_mean")
    histogram_abs_mean_3_sam = read_string(
        "resnet50_cifar10_3_lr_changed_sam_200_res_32_gc_0_whole_model_histogram_abs_mean")
    histogram_abs_mean_3_ekfac = read_string(
        "resnet50_cifar10_3_lr_changed_ekfac_200_res_32_gc_0_whole_model_histogram_abs_mean")
    ###Level4
    histogram_abs_mean_4_sgd = read_string("resnet50_cifar10_4_sgd_200_res_32_lr_0.01_whole_model_histogram_abs_mean")
    histogram_abs_mean_4_sam = read_string(
        "resnet50_cifar10_4_lr_changed_sam_200_res_32_gc_0_whole_model_histogram_abs_mean")
    histogram_abs_mean_4_ekfac = read_string(
        "resnet50_cifar10_4_lr_changed_ekfac_200_res_32_gc_0_whole_model_histogram_abs_mean")
    ## STD
    ###Level1
    histogram_abs_std_1_sgd = read_string("resnet50_cifar10_1_sgd_200_res_32_lr_0.01_whole_model_histogram_abs_std")
    histogram_abs_std_1_sam = read_string(
        "resnet50_cifar10_1_lr_changed_sam_200_res_32_gc_0_whole_model_histogram_abs_std")
    histogram_abs_std_1_ekfac = read_string(
        "resnet50_cifar10_1_lr_changed_ekfac_200_res_32_gc_0_whole_model_histogram_abs_std")
    ###Level2
    histogram_abs_std_2_sgd = read_string("resnet50_cifar10_2_sgd_200_res_32_lr_0.01_whole_model_histogram_abs_std")
    histogram_abs_std_2_sam = read_string(
        "resnet50_cifar10_2_lr_changed_sam_200_res_32_gc_0_whole_model_histogram_abs_std")
    histogram_abs_std_2_ekfac = read_string(
        "resnet50_cifar10_2_lr_changed_ekfac_200_res_32_gc_0_whole_model_histogram_abs_std")
    ###Level3
    histogram_abs_std_3_sgd = read_string("resnet50_cifar10_3_sgd_200_res_32_lr_0.01_whole_model_histogram_abs_std")
    histogram_abs_std_3_sam = read_string(
        "resnet50_cifar10_3_lr_changed_sam_200_res_32_gc_0_whole_model_histogram_abs_std")
    histogram_abs_std_3_ekfac = read_string(
        "resnet50_cifar10_3_lr_changed_ekfac_200_res_32_gc_0_whole_model_histogram_abs_std")

    ###Level4
    histogram_abs_std_4_sgd = read_string("resnet50_cifar10_4_sgd_200_res_32_lr_0.01_whole_model_histogram_abs_std")
    histogram_abs_std_4_sam = read_string(
        "resnet50_cifar10_4_lr_changed_sam_200_res_32_gc_0_whole_model_histogram_abs_std")
    histogram_abs_std_4_ekfac = read_string(
        "resnet50_cifar10_4_lr_changed_ekfac_200_res_32_gc_0_whole_model_histogram_abs_std")

    ## Bin

    histogram_abs_bins_1_sgd = read_string("resnet50_cifar10_1_sgd_200_res_32_lr_0.01_whole_model_histogram_abs_bin")

    # histograms  range (-0.1.0.1)

    ## Means
    ###Level1
    histogram_mean_1_sgd = read_string("resnet50_cifar10_1_sgd_200_res_32_lr_0.01_whole_model_histogram_mean")
    histogram_mean_1_sam = read_string("resnet50_cifar10_1_lr_changed_sam_200_res_32_gc_0_whole_model_histogram_mean")
    histogram_mean_1_ekfac = read_string(
        "resnet50_cifar10_1_lr_changed_ekfac_200_res_32_gc_0_whole_model_histogram_mean")

    ###Level2
    histogram_mean_2_sgd = read_string("resnet50_cifar10_2_sgd_200_res_32_lr_0.01_whole_model_histogram_mean")
    histogram_mean_2_sam = read_string("resnet50_cifar10_2_lr_changed_sam_200_res_32_gc_0_whole_model_histogram_mean")
    histogram_mean_2_ekfac = read_string(
        "resnet50_cifar10_2_lr_changed_ekfac_200_res_32_gc_0_whole_model_histogram_mean")

    ###Level3
    histogram_mean_3_sgd = read_string("resnet50_cifar10_3_sgd_200_res_32_lr_0.01_whole_model_histogram_mean")
    histogram_mean_3_sam = read_string("resnet50_cifar10_3_lr_changed_sam_200_res_32_gc_0_whole_model_histogram_mean")
    histogram_mean_3_ekfac = read_string(
        "resnet50_cifar10_3_lr_changed_ekfac_200_res_32_gc_0_whole_model_histogram_mean")
    ###Level4
    histogram_mean_4_sgd = read_string("resnet50_cifar10_4_sgd_200_res_32_lr_0.01_whole_model_histogram_mean")
    histogram_mean_4_sam = read_string("resnet50_cifar10_4_lr_changed_sam_200_res_32_gc_0_whole_model_histogram_mean")
    histogram_mean_4_ekfac = read_string(
        "resnet50_cifar10_4_lr_changed_ekfac_200_res_32_gc_0_whole_model_histogram_mean")
    ## STD
    ###Level1
    histogram_std_1_sgd = read_string("resnet50_cifar10_1_sgd_200_res_32_lr_0.01_whole_model_histogram_std")
    histogram_std_1_sam = read_string("resnet50_cifar10_1_lr_changed_sam_200_res_32_gc_0_whole_model_histogram_std")
    histogram_std_1_ekfac = read_string("resnet50_cifar10_1_lr_changed_ekfac_200_res_32_gc_0_whole_model_histogram_std")
    ###Level2
    histogram_std_2_sgd = read_string("resnet50_cifar10_2_sgd_200_res_32_lr_0.01_whole_model_histogram_std")
    histogram_std_2_sam = read_string("resnet50_cifar10_2_lr_changed_sam_200_res_32_gc_0_whole_model_histogram_std")
    histogram_std_2_ekfac = read_string("resnet50_cifar10_2_lr_changed_ekfac_200_res_32_gc_0_whole_model_histogram_std")
    ###Level3
    histogram_std_3_sgd = read_string("resnet50_cifar10_3_sgd_200_res_32_lr_0.01_whole_model_histogram_std")
    histogram_std_3_sam = read_string("resnet50_cifar10_3_lr_changed_sam_200_res_32_gc_0_whole_model_histogram_std")
    histogram_std_3_ekfac = read_string("resnet50_cifar10_3_lr_changed_ekfac_200_res_32_gc_0_whole_model_histogram_std")
    ###Level4
    histogram_std_4_sgd = read_string("resnet50_cifar10_4_sgd_200_res_32_lr_0.01_whole_model_histogram_std")
    histogram_std_4_sam = read_string("resnet50_cifar10_4_lr_changed_sam_200_res_32_gc_0_whole_model_histogram_std")
    histogram_std_4_ekfac = read_string("resnet50_cifar10_4_lr_changed_ekfac_200_res_32_gc_0_whole_model_histogram_std")

    ## Bin
    histogram_bins_1_sgd = read_string("resnet50_cifar10_1_sgd_200_res_32_lr_0.01_whole_model_histogram_bin")

    """# TODO: DF with percentiles"""

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    def get_percentile_value(mean, bin, percentile):
        percentile_index = find_nearest(mean, percentile)
        value = bin[percentile_index]
        return value

    resnets_rfs = [108, 110, 213, 318, 423, 1415, 1920, 3100]

    percentile_95 = []
    optim = []
    learning_rate = []
    rf = []

    percentile_95_mean_1_sgd = get_percentile_value(cdf_mean_1_sgd, cfd_bins_1_sgd, 0.95)
    percentile_95.append(percentile_95_mean_1_sgd)
    optim.append("SGD")
    learning_rate.append(0.01)
    rf.append(resnets_rfs[1])
    percentile_95_mean_1_sam = get_percentile_value(cdf_mean_1_sam, cfd_bins_1_sgd, 0.95)
    percentile_95.append(percentile_95_mean_1_sam)
    optim.append("SAM")
    learning_rate.append(0.01)
    rf.append(resnets_rfs[1])
    percentile_95_mean_1_ekfac = get_percentile_value(cdf_mean_1_ekfac, cfd_bins_1_sgd, 0.95)

    percentile_95.append(percentile_95_mean_1_ekfac)
    optim.append("EKFAC")
    learning_rate.append(0.1)

    rf.append(resnets_rfs[1])

    percentile_95_mean_2_sgd = get_percentile_value(cdf_mean_2_sgd, cfd_bins_1_sgd, 0.95)
    percentile_95.append(percentile_95_mean_2_sgd)
    optim.append("SGD")
    learning_rate.append(0.01)

    rf.append(resnets_rfs[2])

    percentile_95_mean_2_sam = get_percentile_value(cdf_mean_2_sam, cfd_bins_1_sgd, 0.95)

    percentile_95.append(percentile_95_mean_2_sam)
    optim.append("SAM")
    learning_rate.append(0.01)

    rf.append(resnets_rfs[2])

    percentile_95_mean_2_ekfac = get_percentile_value(cdf_mean_2_ekfac, cfd_bins_1_sgd, 0.95)

    percentile_95.append(percentile_95_mean_2_ekfac)
    optim.append("EKFAC")
    learning_rate.append(0.1)

    rf.append(resnets_rfs[2])

    percentile_95_mean_3_sgd = get_percentile_value(cdf_mean_3_sgd, cfd_bins_1_sgd, 0.95)

    percentile_95.append(percentile_95_mean_3_sgd)
    optim.append("SGD")
    learning_rate.append(0.01)

    rf.append(resnets_rfs[3])

    percentile_95_mean_3_sam = get_percentile_value(cdf_mean_3_sam, cfd_bins_1_sgd, 0.95)
    percentile_95.append(percentile_95_mean_3_sam)
    optim.append("SAM")
    learning_rate.append(0.01)

    rf.append(resnets_rfs[3])

    percentile_95_mean_3_ekfac = get_percentile_value(cdf_mean_3_ekfac, cfd_bins_1_sgd, 0.95)

    percentile_95.append(percentile_95_mean_3_ekfac)
    optim.append("EKFAC")
    learning_rate.append(0.1)

    rf.append(resnets_rfs[3])

    percentile_95_mean_4_sgd = get_percentile_value(cdf_mean_4_sgd, cfd_bins_1_sgd, 0.95)

    percentile_95.append(percentile_95_mean_4_sgd)
    optim.append("SGD")
    learning_rate.append(0.01)

    rf.append(resnets_rfs[4])

    percentile_95_mean_4_sam = get_percentile_value(cdf_mean_4_sam, cfd_bins_1_sgd, 0.95)

    percentile_95.append(percentile_95_mean_4_sam)
    optim.append("SAM")
    learning_rate.append(0.01)

    rf.append(resnets_rfs[4])

    percentile_95_mean_4_ekfac = get_percentile_value(cdf_mean_4_ekfac, cfd_bins_1_sgd, 0.95)

    percentile_95.append(percentile_95_mean_4_ekfac)
    optim.append("EKFAC")
    learning_rate.append(0.1)

    rf.append(resnets_rfs[4])

    percentile_95.reverse()
    optim.reverse()
    learning_rate.reverse()
    rf.reverse()

    df = pd.DataFrame(
        {"95 Percentile": percentile_95, "Optimiser": optim, "Learning Rate": learning_rate, "Receptive Field": rf})

    import seaborn as sns
    import matplotlib.pyplot as plt

    all_lr_results = pd.read_csv("lr_resnet50_cifar10_optimisers.csv", delimiter=",")
    # all_lr_results.iloc[::-1]
    all_lr_results.sort_values("Optimiser", ascending=True)
    lr_01_results = all_lr_results[all_lr_results["Learning Rate"] == 0.1]

    lr_01_results = lr_01_results.sort_values("Optimiser", ascending=True)
    lr_001_results = all_lr_results[all_lr_results["Learning Rate"] == 0.01]
    lr_001_results = lr_001_results.sort_values("Optimiser", ascending=True)
    # all_lr_results[]

    # sns.set(style="ticks")
    # sns.set_style("ticks",{'axes.grid' : True})

    fig, axs = plt.subplots(1, 2, figsize=(15, 10), layout="compressed", sharey=True)

    sns.barplot(data=lr_001_results, x="Receptive Field", y="95 Percentile", hue="Optimiser", ax=axs[0], legend=False)
    sns.barplot(data=lr_01_results, x="Receptive Field", y="95 Percentile", hue="Optimiser", ax=axs[1])

    # plt.grid(ls="--")

    # for ax in fig.axes.flat:
    axs[0].set_ylabel("95 Percentile of $|W|$")
    # axs[0].tick_params(axis="both",labelsize=fs*ticks_multiplier)
    # axs[1].tick_params(axis="both",labelsize=fs*ticks_multiplier)
    axs[0].set_title("Learning Rate=0.01", size=25)
    axs[1].set_title("Learning Rate=0.1", size=25)
    axs[0].set_xlabel("")
    axs[1].set_xlabel("")
    # ax[0].set_xlabel("Receptive "\textbf{This could be a table})
    # ax[1].set_xlabel("")
    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.grid(ls="--")
    axs[1].legend(prop={"size": fs * 1.7}, loc="upper left")
    fig_multiplier = 1.7
    fig.text(0.55, -0.019, 'Receptive Field', ha='center', size=fs * fig_multiplier)
    plt.savefig(
        "/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/learning_rates_95_percentile_optimisers_cifar10_ResNet50.pdf")
    plt.close()

    lr_01_results.sort_values("Optimiser", ascending=True)
    lr_01_results

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt

    all_lr_results = pd.read_csv("lr_resnet50_cifar10_optimisers.csv", delimiter=",")

    sgd_results = all_lr_results[all_lr_results["Optimiser"] == "SGD"]

    fig = sns.catplot(data=sgd_results, kind="bar", x="Receptive Field", y="95 Percentile", hue="Optimiser",
                      col="Learning Rate")

    for ax in fig.axes.flat:
        ax.set_ylabel("95 Percentile of $|W|$")
        ax.grid(ls="--")

    # plt.grid(ls="--")
    plt.close()

    """## CDFs"""

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')
    import gc

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_cdf_mean = [cdf_mean_1_ekfac, cdf_mean_1_sam, cdf_mean_1_sgd]
    all_cdf_std = [cdf_std_1_ekfac, cdf_std_1_sam, cdf_std_1_sgd]
    labels = ["EKFAC:lr=0.1", "ASAM:lr=0.01", "SGD:lr=0.01"]

    for i in range(len(all_cdf_mean)):
        mean = all_cdf_mean[i]
        std = all_cdf_std[i]
        label = labels[i]
        bin_count = cfd_bins_1_sgd[1:]
        axs.plot(bin_count, mean, label=labels[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")

    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("$|w|$")
    plt.ylabel("CDF")
    plt.xlim(0, 0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_cdf_resnet_50_lr_changed_cifar10_level1.pdf")
    del all_cdf_mean
    del all_cdf_std
    fig.clf()
    plt.close()
    gc.collect()

    # del all_cdf_mean
    # del all_cdf_std
    # del fig

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')
    import gc

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_cdf_mean = [cdf_mean_2_sgd, cdf_mean_2_sam, cdf_mean_2_ekfac]
    all_cdf_std = [cdf_std_2_sgd, cdf_std_2_sam, cdf_std_2_ekfac]
    labels = ["SGD:lr=0.01", "ASAM:lr=0.01", "EKFAC:lr=0.1"]

    for i in range(len(all_cdf_mean)):
        mean = all_cdf_mean[i]
        std = all_cdf_std[i]
        label = labels[i]
        bin_count = cfd_bins_1_sgd[1:]
        axs.plot(bin_count, mean, label=labels[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")
    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("Weight")
    plt.xlabel("$|w|$")
    plt.ylabel("CDF")
    plt.xlim(0, 0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_cdf_resnet_50_lr_changed_cifar10_level2.pdf")
    del all_cdf_mean
    del all_cdf_std
    fig.clf()
    plt.close()
    gc.collect()

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_cdf_mean = [cdf_mean_3_sgd, cdf_mean_3_sam, cdf_mean_3_ekfac]
    all_cdf_std = [cdf_std_3_sgd, cdf_std_3_sam, cdf_std_3_ekfac]
    labels = ["SGD:lr=0.01", "ASAM:lr=0.01", "EKFAC:lr=0.1"]

    for i in range(len(all_cdf_mean)):
        mean = all_cdf_mean[i]
        std = all_cdf_std[i]
        label = labels[i]
        bin_count = cfd_bins_1_sgd[1:]
        axs.plot(bin_count, mean, label=labels[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")

    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("Weight")
    plt.xlabel("$|w|$")
    plt.ylabel("CDF")
    plt.xlim(0, 0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_cdf_resnet_50_lr_changed_cifar10_level3.pdf")
    del all_cdf_mean
    del all_cdf_std
    fig.clf()
    plt.close()
    gc.collect()

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_cdf_mean = [cdf_mean_4_ekfac, cdf_mean_4_sam, cdf_mean_4_sgd]
    all_cdf_std = [cdf_std_4_ekfac, cdf_std_4_sam, cdf_std_4_sgd]
    labels = ["EKFAC:lr=0.1", "ASAM:lr=0.01", "SGD:lr=0.01"]

    for i in range(len(all_cdf_mean)):
        mean = all_cdf_mean[i]
        std = all_cdf_std[i]
        label = labels[i]
        bin_count = cfd_bins_1_sgd[1:]
        # plt.hist(mean,bins=bin_count,label=labels[i])
        axs.plot(bin_count, mean, label=labels[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")

    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("Weight")
    plt.xlabel("$|w|$")
    plt.ylabel("CDF")
    plt.xlim(0, 0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_cdf_resnet_50_lr_changed_cifar10_level4.pdf")

    del all_cdf_mean
    del all_cdf_std
    fig.clf()
    plt.close()
    gc.collect()

    """## Pr= 0.9"""

    from matplotlib import pyplot as plt
    import seaborn as sns
    # import matplotlib
    # matplotlib.use('tkAgg')

    # level 1 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_1_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_1_cifar10_0.9_lr_changed_sam_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_1_cifar10_0.9_sgd_200_res_32_lr_0.01_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 2 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_2_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_2_cifar10_0.9_lr_changed_sam_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_2_cifar10_0.9_sgd_200_res_32_lr_0.01_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 3 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_3_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_3_cifar10_0.9_lr_changed_sam_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_3_cifar10_0.9_sgd_200_res_32_lr_0.01_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 4 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_4_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_4_cifar10_0.9_lr_changed_sam_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_4_cifar10_0.9_sgd_200_res_32_lr_0.01_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 5 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_5_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################ ############################

    df_level6_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_6_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level6_ekfac))
    df_level6_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level6_ekfac))
    df_level6_ekfac["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level7_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_7_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level7_ekfac))
    df_level7_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level7_ekfac))
    df_level7_ekfac["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4],ignore_index=True)
    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level7_ekfac,df_level6_ekfac,df_level5_ekfac])
    all_df = pd.concat([df_level1, df_level2, df_level4, df_level7_ekfac, df_level6_ekfac, df_level5_ekfac])

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser", alpha=0.5)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False, alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Scaled Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)
    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    # sns.barplot(data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",errorbar="ci")

    axs[0].legend(prop={"size": fs * 1.2}, loc="upper left")

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))
    secay.set_ylabel('Absolute Pruned Accuracy')

    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)
        plt.close()
    # plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet_50_lr_changed_cifar10_pruning_performance.pdf")

    plt.close()

    df_level6_ekfac

    from matplotlib import pyplot as plt
    import seaborn as sns

    from matplotlib.patches import Patch
    # fs=20

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)
    sgd_new = all_df
    # sgd_new = all_df[all_df["optimiser"]=="SGD"]
    # sgd_originals =all_df_original_lrs[all_df_original_lrs["optimiser"]=="SGD"]
    sgd_originals = all_df_original_lrs[all_df_original_lrs["RF"] != 318]
    sgd_originals = sgd_originals[sgd_originals["RF"] < 538]

    sgd_originals["Learning rate"] = [0.1] * len(sgd_originals)
    sgd_new["Learning rate"] = [0.01] * len(sgd_new)
    sgd_new["RF"] = list(map(int, sgd_new["RF"]))

    # sns.barplot(ax=axs[1],data=sgd_originals,x="RF",y="Dense Accuracy",color="red",legend=False,alpha=0.3)
    sns.barplot(ax=axs[1], data=sgd_originals, x="RF", y="Pruned Accuracy", hue="optimiser", alpha=0.5, legend=False)

    # sns.barplot(ax=axs[0],data=sgd_new,x="RF",y="Dense Accuracy",color="red",legend=False,alpha=0.3)
    sns.barplot(ax=axs[0], data=sgd_new, x="RF", y="Pruned Accuracy", hue="optimiser", alpha=0.5)

    # sns.stripplot(
    #     x="RF",
    #     y="Dense Accuracy",
    #     # hue="optimiser",
    #     color="red",
    #     data=sgd_originals, dodge=True, alpha=0.4, ax=axs[1],legend=False)
    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        hue="optimiser",
        data=sgd_originals, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    # sns.stripplot(
    #     x="RF",
    #     y="Dense Accuracy",
    #     # hue="optimiser",
    #     color="red",
    #     data=sgd_new, dodge=True, alpha=0.4, ax=axs[0],legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        hue="optimiser",
        data=sgd_new, dodge=True, alpha=0.6, ax=axs[0], legend=False)

    axs[1].set_title("Lr = 0.1")
    axs[0].set_title("Lr = 0.01")

    # species=["Pruned SGD","Dense SGD"]
    # colors=["cornflowerblue","red"]

    # handles = [
    #     Patch(facecolor=color, label=label)
    #     for label, color in zip(species,colors)
    # ]

    # axs[1].legend(handles=handles,prop={"size": fs*1.7}, loc="upper left",bbox_to_anchor=(1.01, 1))

    bbox_to_anchor = (1, 1),

    axs[0].grid(ls="--")
    axs[1].grid(ls="--")

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Pruned Accuracy')
    axs[0].set_ylabel('Pruned Accuracy', fontsize=20)
    # axs[1].set_ylabel('Accuracy')
    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major')
        ax.set_xlabel("")

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    fig_multiplier = 1.7

    # fig.text(0.5, -0.019, 'Receptive Field', ha='center', size=fs * fig_multiplier)

    # fig.suptitle('ResNet50 x CIFAR10 @ 32 PR 0.9')
    fig.text(0.55, -0.019, 'Receptive Field', ha='center', size=fs * fig_multiplier)
    # plt.tight_layout()
    plt.savefig(
        "/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet_50_lr_pruned_accuracy_cifar10_pruning_performance_all_optimisers.pdf")
    plt.close()

    """\"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    from matplotlib.patches import Patch
    # fs=20

    fig, axs = plt.subplots(1,2,figsize=(10,10),layout="compressed",sharey=True)
    # sgd_new=all_df
    sgd_new = all_df[all_df["optimiser"]=="SGD"]
    sgd_originals =all_df_original_lrs[all_df_original_lrs["optimiser"]=="SGD"]


    sgd_originals["Learning rate"]=[0.1]*len(sgd_originals)
    sgd_new["Learning rate"]=[0.01]*len(sgd_new)
    sgd_new["RF"]=list(map(int,sgd_new["RF"]))

    sns.barplot(ax=axs[1],data=sgd_originals,x="RF",y="Dense Accuracy",color="red",legend=False,alpha=0.3)
    sns.barplot(ax=axs[1],data=sgd_originals,x="RF",y="Pruned Accuracy",hue="optimiser",alpha=0.5,legend=False)

    sns.barplot(ax=axs[0],data=sgd_new,x="RF",y="Dense Accuracy",color="red",legend=False,alpha=0.3)
    sns.barplot(ax=axs[0],data=sgd_new,x="RF",y="Pruned Accuracy",hue="optimiser",alpha=0.5,legend=False)



    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        # hue="optimiser",
        color="red",
        data=sgd_originals, dodge=True, alpha=0.4, ax=axs[1],legend=False)
    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        hue="optimiser",
        data=sgd_originals, dodge=True, alpha=0.6, ax=axs[1],legend=False)


    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        # hue="optimiser",
        color="red",
        data=sgd_new, dodge=True, alpha=0.4, ax=axs[0],legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        hue="optimiser",
        data=sgd_new, dodge=True, alpha=0.6, ax=axs[0],legend=False)



    axs[1].set_title("Lr = 0.1")
    axs[0].set_title("Lr = 0.01")



    species=["Pruned SGD","Dense SGD"]
    colors=["cornflowerblue","red"]

    handles = [
        Patch(facecolor=color, label=label)
        for label, color in zip(species,colors)
    ]

    axs[1].legend(handles=handles,prop={"size": fs*1.7}, loc="upper left",bbox_to_anchor=(1.01, 1))

    bbox_to_anchor=(1, 1),

    axs[0].grid(ls="--")
    axs[1].grid(ls="--")

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Pruned Accuracy')
    axs[0].set_ylabel('Accuracy',fontsize=20)
    # axs[1].set_ylabel('Accuracy')
    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)


    for ax in axs.flat:
      ax.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
      ax.tick_params(axis='x', which='major')
      ax.set_xlabel("")


    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    fig_multiplier=1.5

    # fig.text(0.5, -0.019, 'Receptive Field', ha='center', size=fs * fig_multiplier)

    # fig.suptitle('ResNet50 x CIFAR10 @ 32 PR 0.9')
    fig.text(0.4, -0.005, 'Receptive Field', ha='center', size=fs * fig_multiplier)
    # plt.tight_layout()
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet_50_lr_dense_pruned_accuracy_cifar10_pruning_performance.pdf")
    plt.close()

    all_df

    all_df_orignal_lrs

    from matplotlib import pyplot as plt
    import seaborn as sns
    # import matplotlib
    # matplotlib.use('tkAgg')



    #level 1 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet50_1_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    RF=[]
    RF.extend([resnets_rfs[1]]*len(df_level1_ekfac))
    df_level1_ekfac["RF"]=RF
    optim=[]
    optim.extend(["EKFAC"]*len(df_level1_ekfac))
    df_level1_ekfac["optimiser"]=optim



    df_level1_asam = pd.read_csv("large_input_pruning_results/RF_resnet50_1_cifar10_0.9_lr_changed_sam_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    RF=[]
    RF.extend([resnets_rfs[1]]*len(df_level1_asam))
    df_level1_asam["RF"]=RF
    optim=[]
    optim.extend(["ASAM"]*len(df_level1_asam))
    df_level1_asam["optimiser"]=optim



    df_level1_sgd = pd.read_csv("large_input_pruning_results/RF_resnet50_1_cifar10_0.9_sgd_200_res_32_lr_0.01_global_one_shot_summary.csv",delimiter=",")
    RF=[]
    RF.extend([resnets_rfs[1]]*len(df_level1_sgd))
    df_level1_sgd["RF"]=RF
    optim=[]
    optim.extend(["SGD"]*len(df_level1_sgd))
    df_level1_sgd["optimiser"]=optim


    #level 2 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet50_2_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    RF=[]
    RF.extend([resnets_rfs[2]]*len(df_level2_ekfac))
    df_level2_ekfac["RF"]=RF
    optim=[]
    optim.extend(["EKFAC"]*len(df_level2_ekfac))
    df_level2_ekfac["optimiser"]=optim



    df_level2_asam = pd.read_csv("large_input_pruning_results/RF_resnet50_2_cifar10_0.9_lr_changed_sam_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    RF=[]
    RF.extend([resnets_rfs[2]]*len(df_level2_asam))
    df_level2_asam["RF"]=RF
    optim=[]
    optim.extend(["ASAM"]*len(df_level2_asam))
    df_level2_asam["optimiser"]=optim



    df_level2_sgd = pd.read_csv("large_input_pruning_results/RF_resnet50_2_cifar10_0.9_sgd_200_res_32_lr_0.01_global_one_shot_summary.csv",delimiter=",")
    RF=[]
    RF.extend([resnets_rfs[2]]*len(df_level2_sgd))
    df_level2_sgd["RF"]=RF
    optim=[]
    optim.extend(["SGD"]*len(df_level2_sgd))
    df_level2_sgd["optimiser"]=optim


    #level 3 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet50_3_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    RF=[]
    RF.extend([resnets_rfs[3]]*len(df_level3_ekfac))
    df_level3_ekfac["RF"]=RF
    optim=[]
    optim.extend(["EKFAC"]*len(df_level3_ekfac))
    df_level3_ekfac["optimiser"]=optim



    df_level3_asam = pd.read_csv("large_input_pruning_results/RF_resnet50_3_cifar10_0.9_lr_changed_sam_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    RF=[]
    RF.extend([resnets_rfs[3]]*len(df_level3_asam))
    df_level3_asam["RF"]=RF
    optim=[]
    optim.extend(["ASAM"]*len(df_level3_asam))
    df_level3_asam["optimiser"]=optim



    df_level3_sgd = pd.read_csv("large_input_pruning_results/RF_resnet50_3_cifar10_0.9_sgd_200_res_32_lr_0.01_global_one_shot_summary.csv",delimiter=",")
    RF=[]
    RF.extend([resnets_rfs[3]]*len(df_level3_sgd))
    df_level3_sgd["RF"]=RF
    optim=[]
    optim.extend(["SGD"]*len(df_level3_sgd))
    df_level3_sgd["optimiser"]=optim

    #level 4 ############################ ############################ ############################ ############################ ############################ ############################


    df_level4_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet50_4_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    RF=[]
    RF.extend([resnets_rfs[4]]*len(df_level4_ekfac))
    df_level4_ekfac["RF"]=RF
    optim=[]
    optim.extend(["EKFAC"]*len(df_level4_ekfac))
    df_level4_ekfac["optimiser"]=optim



    df_level4_asam = pd.read_csv("large_input_pruning_results/RF_resnet50_4_cifar10_0.9_lr_changed_sam_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    RF=[]
    RF.extend([resnets_rfs[4]]*len(df_level4_asam))
    df_level4_asam["RF"]=RF
    optim=[]
    optim.extend(["ASAM"]*len(df_level4_asam))
    df_level4_asam["optimiser"]=optim



    df_level4_sgd = pd.read_csv("large_input_pruning_results/RF_resnet50_4_cifar10_0.9_sgd_200_res_32_lr_0.01_global_one_shot_summary.csv",delimiter=",")
    RF=[]
    RF.extend([resnets_rfs[4]]*len(df_level4_sgd))
    df_level4_sgd["RF"]=RF
    optim=[]
    optim.extend(["SGD"]*len(df_level4_sgd))
    df_level4_sgd["optimiser"]=optim




    # level 5 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet50_5_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    RF=[]
    RF.extend([resnets_rfs[5]]*len(df_level5_ekfac))
    df_level5_ekfac["RF"]=RF
    optim=[]
    optim.extend(["EKFAC"]*len(df_level5_ekfac))
    df_level5_ekfac["optimiser"]=optim

    #level 6 ############################ ############################ ############################ ############################ ############################ ############################

    df_level6_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet50_6_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    RF=[]
    RF.extend([resnets_rfs[6]]*len(df_level6_ekfac))
    df_level6_ekfac["RF"]=RF
    optim=[]
    optim.extend(["EKFAC"]*len(df_level6_ekfac))
    df_level6_ekfac["optimiser"]=optim

    #level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level7_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet50_7_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    RF=[]
    RF.extend([resnets_rfs[7]]*len(df_level7_ekfac))
    df_level7_ekfac["RF"]=RF
    optim=[]
    optim.extend(["EKFAC"]*len(df_level7_ekfac))
    df_level7_ekfac["optimiser"]=optim








    df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4],ignore_index=True)
    all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level7_ekfac,df_level6_ekfac,df_level5_ekfac])

    all_df["Scaled Pruned Accuracy"]=(all_df["Pruned Accuracy"]/all_df["Dense Accuracy"])*100

    fig, axs = plt.subplots(1,1,figsize=(10,10), layout="compressed",sharey=True)

    # sns.barplot(ax=axs,data=all_df,x="RF",y="Scaled Pruned Accuracy",hue="optimiser",alpha=0.5)
    sns.barplot(ax=axs,data=all_df,x="RF",y="Dense Accuracy",hue="optimiser",alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs,legend=False)
    # sns.stripplot(
    #     x="RF",
    #     y=" Dense Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[1],legend=False)

    # sns.barplot(data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",errorbar="ci")


    axs.legend(prop={"size": fs*1.2}, loc="upper left")



    def f(x):
      return x

    def invf(x):
      return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))
    # secay.set_ylabel('Absolute Pruned Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)



    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelrotation=90)
    axs.set_xlabel("")
        plt.close()
    plt.grid(ls="--")
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet_50_lr_changed_cifar10_dense_performance.pdf")
    plt.close()
    # del all_cdf_mean
    # del all_cdf_std
    fig.clf()
        plt.close()
    gc.collect()

    """
    ## Pr= 0.9 with batch norm adjustment"""

    from matplotlib import pyplot as plt
    import seaborn as sns
    # import matplotlib
    # matplotlib.use('tkAgg')

    # level 1 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_1_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_1_cifar10_0.9_lr_changed_sam_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_1_cifar10_0.9_sgd_200_res_32_lr_0.01_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 2 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_2_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_2_cifar10_0.9_lr_changed_sam_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_2_cifar10_0.9_sgd_200_res_32_lr_0.01_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 3 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_3_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_3_cifar10_0.9_lr_changed_sam_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_3_cifar10_0.9_sgd_200_res_32_lr_0.01_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 4 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_4_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_4_cifar10_0.9_lr_changed_sam_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_4_cifar10_0.9_sgd_200_res_32_lr_0.01_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 5 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_5_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################ ############################

    df_level6_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_6_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level6_ekfac))
    df_level6_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level6_ekfac))
    df_level6_ekfac["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level7_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_7_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level7_ekfac))
    df_level7_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level7_ekfac))
    df_level7_ekfac["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4],ignore_index=True)
    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4, df_level7_ekfac, df_level6_ekfac, df_level5_ekfac])

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser", alpha=0.5)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False, alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Scaled Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)
    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    # sns.barplot(data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",errorbar="ci")

    axs[0].legend(prop={"size": fs * 1.2}, loc="upper left")

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))
    secay.set_ylabel('Absolute Pruned Accuracy')

    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)
    # plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet_50_lr_changed_cifar10_pruning_performance.pdf")

    plt.close()

    from matplotlib import pyplot as plt
    import seaborn as sns

    from matplotlib.patches import Patch
    # fs=20

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)
    sgd_new = all_df[all_df["optimiser"] == "SGD"]
    all_df_original_lrs
    sgd_originals = all_df_original_lrs[all_df_original_lrs["optimiser"] == "SGD"]

    sgd_originals["Learning rate"] = [0.1] * len(sgd_originals)
    sgd_new["Learning rate"] = [0.01] * len(sgd_new)

    sns.barplot(ax=axs[1], data=sgd_originals, x="RF", y="Dense Accuracy", color="red", legend=False, alpha=0.3)
    sns.barplot(ax=axs[1], data=sgd_originals, x="RF", y="Pruned Accuracy", hue="optimiser", alpha=0.5, legend=False)

    sns.barplot(ax=axs[0], data=sgd_new, x="RF", y="Dense Accuracy", color="red", legend=False, alpha=0.3)
    sns.barplot(ax=axs[0], data=sgd_new, x="RF", y="Pruned Accuracy", hue="optimiser", alpha=0.5, legend=False)

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        # hue="optimiser",
        color="red",
        data=sgd_originals, dodge=True, alpha=0.4, ax=axs[1], legend=False)
    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        hue="optimiser",
        data=sgd_originals, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        # hue="optimiser",
        color="red",
        data=sgd_new, dodge=True, alpha=0.4, ax=axs[0], legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        hue="optimiser",
        data=sgd_new, dodge=True, alpha=0.6, ax=axs[0], legend=False)

    axs[1].set_title("Lr= 0.1")
    axs[0].set_title("Lr= 0.01")

    species = ["Pruned SGD", "Dense SGD"]
    colors = ["cornflowerblue", "red"]

    handles = [
        Patch(facecolor=color, label=label)
        for label, color in zip(species, colors)
    ]

    axs[1].legend(handles=handles, prop={"size": fs * 1.7}, loc="upper left", bbox_to_anchor=(1.01, 1),
                  borderaxespad=0.1)

    bbox_to_anchor = (1, 1),

    axs[0].grid(ls="--")
    axs[1].grid(ls="--")

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Pruned Accuracy')
    axs[0].set_ylabel('Accuracy')
    # axs[1].set_ylabel('Accuracy')
    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)

    fig.suptitle('ResNet50 x CIFAR10 @ 32')
    plt.close()

    all_df_orignal_lrs

    from matplotlib import pyplot as plt
    import seaborn as sns
    # import matplotlib
    # matplotlib.use('tkAgg')

    # level 1 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_1_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_1_cifar10_0.9_lr_changed_sam_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_1_cifar10_0.9_sgd_200_res_32_lr_0.01_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[1]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 2 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_2_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_2_cifar10_0.9_lr_changed_sam_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_2_cifar10_0.9_sgd_200_res_32_lr_0.01_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[2]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 3 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_3_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_3_cifar10_0.9_lr_changed_sam_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_3_cifar10_0.9_sgd_200_res_32_lr_0.01_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[3]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 4 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_4_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_4_cifar10_0.9_lr_changed_sam_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_4_cifar10_0.9_sgd_200_res_32_lr_0.01_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[4]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 5 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_5_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################ ############################

    df_level6_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_6_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level6_ekfac))
    df_level6_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level6_ekfac))
    df_level6_ekfac["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level7_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet50_7_cifar10_0.9_lr_changed_ekfac_200_res_32_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level7_ekfac))
    df_level7_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level7_ekfac))
    df_level7_ekfac["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4],ignore_index=True)
    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4, df_level7_ekfac, df_level6_ekfac, df_level5_ekfac])

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    # sns.barplot(ax=axs,data=all_df,x="RF",y="Scaled Pruned Accuracy",hue="optimiser",alpha=0.5)
    sns.barplot(ax=axs, data=all_df, x="RF", y="Dense Accuracy", hue="optimiser", alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs, legend=False)
    # sns.stripplot(
    #     x="RF",
    #     y=" Dense Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[1],legend=False)

    # sns.barplot(data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",errorbar="ci")

    axs.legend(prop={"size": fs * 1.2}, loc="upper left")

    def f(x):
        return x

    def invf(x):
        return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))
    # secay.set_ylabel('Absolute Pruned Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelrotation=90)
    plt.grid(ls="--")
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet_50_lr_changed_cifar10_dense_performance.pdf")
    # del all_cdf_mean
    # del all_cdf_std
    fig.clf()
    plt.close()
    gc.collect()

    """# TODO: Vgg19"""

    from matplotlib import pyplot as plt
    import seaborn as sns
    import pickle
    def read_string(name):
        with open(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/{name}.pkl", "rb") as f:
            return pickle.load(f)

    # CDFs

    ## Means

    ###Level1

    cdf_mean_1_sgd = read_string("vgg19_cifar10_1_recording_200_whole_model_cdf_mean")
    cdf_mean_1_sam = read_string("vgg19_cifar10_1_sam_optim_saturation_200_gc_0_whole_model_cdf_mean")
    cdf_mean_1_ekfac = read_string("vgg19_cifar10_1_ekfac_optim_hyper_saturation_200_gc_0_whole_model_cdf_mean")

    ###Level2

    cdf_mean_2_sgd = read_string("vgg19_cifar10_2_recording_200_whole_model_cdf_mean")
    cdf_mean_2_sam = read_string("vgg19_cifar10_2_sam_optim_saturation_200_gc_0_whole_model_cdf_mean")
    cdf_mean_2_ekfac = read_string("vgg19_cifar10_2_ekfac_optim_hyper_saturation_200_gc_0_whole_model_cdf_mean")

    ###Level3

    cdf_mean_3_sgd = read_string("vgg19_cifar10_3_recording_200_whole_model_cdf_mean")
    cdf_mean_3_sam = read_string("vgg19_cifar10_3_sam_optim_saturation_200_gc_0_whole_model_cdf_mean")
    cdf_mean_3_ekfac = read_string("vgg19_cifar10_3_ekfac_optim_hyper_saturation_200_gc_0_whole_model_cdf_mean")

    ###Level4

    cdf_mean_4_sgd = read_string("vgg19_cifar10_4_recording_200_whole_model_cdf_mean")
    cdf_mean_4_sam = read_string("vgg19_cifar10_4_sam_optim_saturation_200_gc_0_whole_model_cdf_mean")
    cdf_mean_4_ekfac = read_string("vgg19_cifar10_4_ekfac_optim_hyper_saturation_200_gc_0_whole_model_cdf_mean")

    ## STD
    ###Level1

    cdf_std_1_sgd = read_string("vgg19_cifar10_1_recording_200_whole_model_cdf_std")
    cdf_std_1_sam = read_string("vgg19_cifar10_1_sam_optim_saturation_200_gc_0_whole_model_cdf_std")
    cdf_std_1_ekfac = read_string("vgg19_cifar10_1_ekfac_optim_hyper_saturation_200_gc_0_whole_model_cdf_std")

    ###Level2

    cdf_std_2_sgd = read_string("vgg19_cifar10_2_recording_200_whole_model_cdf_std")
    cdf_std_2_sam = read_string("vgg19_cifar10_2_sam_optim_saturation_200_gc_0_whole_model_cdf_std")
    cdf_std_2_ekfac = read_string("vgg19_cifar10_2_ekfac_optim_hyper_saturation_200_gc_0_whole_model_cdf_std")
    ###Level3

    cdf_std_3_sgd = read_string("vgg19_cifar10_3_recording_200_whole_model_cdf_std")
    cdf_std_3_sam = read_string("vgg19_cifar10_3_sam_optim_saturation_200_gc_0_whole_model_cdf_std")
    cdf_std_3_ekfac = read_string("vgg19_cifar10_3_ekfac_optim_hyper_saturation_200_gc_0_whole_model_cdf_std")

    ###Level4

    cdf_std_4_sgd = read_string("vgg19_cifar10_4_recording_200_whole_model_cdf_std")
    cdf_std_4_sam = read_string("vgg19_cifar10_4_sam_optim_saturation_200_gc_0_whole_model_cdf_std")
    cdf_std_4_ekfac = read_string("vgg19_cifar10_4_ekfac_optim_hyper_saturation_200_gc_0_whole_model_cdf_std")

    ## Bins
    cfd_bins_1_sgd = read_string("vgg19_cifar10_1_recording_200_whole_model_cdf_bin")

    # histograms  abs range(0,0.1)

    ## Means

    ###Level1
    histogram_abs_mean_1_sgd = read_string("vgg19_cifar10_1_recording_200_whole_model_histogram_abs_mean")
    histogram_abs_mean_1_sam = read_string(
        "vgg19_cifar10_1_sam_optim_saturation_200_gc_0_whole_model_histogram_abs_mean")
    histogram_abs_mean_1_ekfac = read_string(
        "vgg19_cifar10_1_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_abs_mean")

    ###Level2
    histogram_abs_mean_2_sgd = read_string("vgg19_cifar10_2_recording_200_whole_model_histogram_abs_mean")
    histogram_abs_mean_2_sam = read_string(
        "vgg19_cifar10_2_sam_optim_saturation_200_gc_0_whole_model_histogram_abs_mean")
    histogram_abs_mean_2_ekfac = read_string(
        "vgg19_cifar10_2_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_abs_mean")
    ###Level3
    histogram_abs_mean_3_sgd = read_string("vgg19_cifar10_3_recording_200_whole_model_histogram_abs_mean")
    histogram_abs_mean_3_sam = read_string(
        "vgg19_cifar10_3_sam_optim_saturation_200_gc_0_whole_model_histogram_abs_mean")
    histogram_abs_mean_3_ekfac = read_string(
        "vgg19_cifar10_3_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_abs_mean")
    ###Level4
    histogram_abs_mean_4_sgd = read_string("vgg19_cifar10_4_recording_200_whole_model_histogram_abs_mean")
    histogram_abs_mean_4_sam = read_string(
        "vgg19_cifar10_4_sam_optim_saturation_200_gc_0_whole_model_histogram_abs_mean")
    histogram_abs_mean_4_ekfac = read_string(
        "vgg19_cifar10_4_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_abs_mean")
    ## STD
    ###Level1
    histogram_abs_std_1_sgd = read_string("vgg19_cifar10_1_recording_200_whole_model_histogram_abs_std")
    histogram_abs_std_1_sam = read_string("vgg19_cifar10_1_sam_optim_saturation_200_gc_0_whole_model_histogram_abs_std")
    histogram_abs_std_1_ekfac = read_string(
        "vgg19_cifar10_1_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_abs_std")
    ###Level2
    histogram_abs_std_2_sgd = read_string("vgg19_cifar10_2_recording_200_whole_model_histogram_abs_std")
    histogram_abs_std_2_sam = read_string("vgg19_cifar10_2_sam_optim_saturation_200_gc_0_whole_model_histogram_abs_std")
    histogram_abs_std_2_ekfac = read_string(
        "vgg19_cifar10_2_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_abs_std")
    ###Level3
    histogram_abs_std_3_sgd = read_string("vgg19_cifar10_3_recording_200_whole_model_histogram_abs_std")
    histogram_abs_std_3_sam = read_string("vgg19_cifar10_3_sam_optim_saturation_200_gc_0_whole_model_histogram_abs_std")
    histogram_abs_std_3_ekfac = read_string(
        "vgg19_cifar10_3_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_abs_std")

    ###Level4
    histogram_abs_std_4_sgd = read_string("vgg19_cifar10_4_recording_200_whole_model_histogram_abs_std")
    histogram_abs_std_4_sam = read_string("vgg19_cifar10_4_sam_optim_saturation_200_gc_0_whole_model_histogram_abs_std")
    histogram_abs_std_4_ekfac = read_string(
        "vgg19_cifar10_4_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_abs_std")

    ## Bin

    histogram_abs_bins_1_sgd = read_string("vgg19_cifar10_1_recording_200_whole_model_histogram_abs_bin")

    # histograms  range (-0.1.0.1)

    ## Means
    ###Level1
    histogram_mean_1_sgd = read_string("vgg19_cifar10_1_recording_200_whole_model_histogram_mean")
    histogram_mean_1_sam = read_string("vgg19_cifar10_1_sam_optim_saturation_200_gc_0_whole_model_histogram_mean")
    histogram_mean_1_ekfac = read_string(
        "vgg19_cifar10_1_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_mean")

    ###Level2
    histogram_mean_2_sgd = read_string("vgg19_cifar10_2_recording_200_whole_model_histogram_mean")
    histogram_mean_2_sam = read_string("vgg19_cifar10_2_sam_optim_saturation_200_gc_0_whole_model_histogram_mean")
    histogram_mean_2_ekfac = read_string(
        "vgg19_cifar10_2_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_mean")

    ###Level3
    histogram_mean_3_sgd = read_string("vgg19_cifar10_3_recording_200_whole_model_histogram_mean")
    histogram_mean_3_sam = read_string("vgg19_cifar10_3_sam_optim_saturation_200_gc_0_whole_model_histogram_mean")
    histogram_mean_3_ekfac = read_string(
        "vgg19_cifar10_3_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_mean")
    ###Level4
    histogram_mean_4_sgd = read_string("vgg19_cifar10_4_recording_200_whole_model_histogram_mean")
    histogram_mean_4_sam = read_string("vgg19_cifar10_4_sam_optim_saturation_200_gc_0_whole_model_histogram_mean")
    histogram_mean_4_ekfac = read_string(
        "vgg19_cifar10_4_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_mean")
    ## STD
    ###Level1
    histogram_std_1_sgd = read_string("vgg19_cifar10_1_recording_200_whole_model_histogram_std")
    histogram_std_1_sam = read_string("vgg19_cifar10_1_sam_optim_saturation_200_gc_0_whole_model_histogram_std")
    histogram_std_1_ekfac = read_string(
        "vgg19_cifar10_1_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_std")
    ###Level2
    histogram_std_2_sgd = read_string("vgg19_cifar10_2_recording_200_whole_model_histogram_std")
    histogram_std_2_sam = read_string("vgg19_cifar10_2_sam_optim_saturation_200_gc_0_whole_model_histogram_std")
    histogram_std_2_ekfac = read_string(
        "vgg19_cifar10_2_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_std")
    ###Level3
    histogram_std_3_sgd = read_string("vgg19_cifar10_3_recording_200_whole_model_histogram_std")
    histogram_std_3_sam = read_string("vgg19_cifar10_3_sam_optim_saturation_200_gc_0_whole_model_histogram_std")
    histogram_std_3_ekfac = read_string(
        "vgg19_cifar10_3_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_std")
    ###Level4
    histogram_std_4_sgd = read_string("vgg19_cifar10_4_recording_200_whole_model_histogram_std")
    histogram_std_4_sam = read_string("vgg19_cifar10_4_sam_optim_saturation_200_gc_0_whole_model_histogram_std")
    histogram_std_4_ekfac = read_string(
        "vgg19_cifar10_4_ekfac_optim_hyper_saturation_200_gc_0_whole_model_histogram_std")

    ## Bin
    histogram_bins_1_sgd = read_string("vgg19_cifar10_1_recording_200_whole_model_histogram_bin")

    histogram_mean_4_sam

    """## CDFs"""

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')
    import gc

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_cdf_mean = [cdf_mean_1_sgd, cdf_mean_1_sam, cdf_mean_1_ekfac]
    all_cdf_std = [cdf_std_1_sgd, cdf_std_1_sam, cdf_std_1_ekfac]
    labels = ["SGD", "ASAM", "EKFAC"]

    for i in range(len(all_cdf_mean)):
        mean = all_cdf_mean[i]
        std = all_cdf_std[i]
        label = labels[i]
        bin_count = cfd_bins_1_sgd[1:]
        axs.plot(bin_count, mean, label=labels[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")

    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("$|w|$")
    plt.ylabel("CDF")
    plt.xlim(0, 0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_cdf_vgg19_cifar10_level1.pdf")
    del all_cdf_mean
    del all_cdf_std
    fig.clf()
    plt.close()
    gc.collect()

    # del all_cdf_mean
    # del all_cdf_std
    # del fig

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')
    import gc

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_cdf_mean = [cdf_mean_2_sgd, cdf_mean_2_sam, cdf_mean_2_ekfac]
    all_cdf_std = [cdf_std_2_sgd, cdf_std_2_sam, cdf_std_2_ekfac]
    labels = ["SGD", "ASAM", "EKFAC"]

    for i in range(len(all_cdf_mean)):
        mean = all_cdf_mean[i]
        std = all_cdf_std[i]
        label = labels[i]
        bin_count = cfd_bins_1_sgd[1:]
        axs.plot(bin_count, mean, label=labels[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")
    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("Weight")
    plt.xlabel("$|w|$")
    plt.ylabel("CDF")
    plt.xlim(0, 0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_cdf_vgg19_cifar10_level2.pdf")
    del all_cdf_mean
    del all_cdf_std
    fig.clf()
    plt.close()
    gc.collect()

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_cdf_mean = [cdf_mean_3_sgd, cdf_mean_3_sam, cdf_mean_3_ekfac]
    all_cdf_std = [cdf_std_3_sgd, cdf_std_3_sam, cdf_std_3_ekfac]
    labels = ["SGD", "ASAM", "EKFAC"]

    for i in range(len(all_cdf_mean)):
        mean = all_cdf_mean[i]
        std = all_cdf_std[i]
        label = labels[i]
        bin_count = cfd_bins_1_sgd[1:]
        axs.plot(bin_count, mean, label=labels[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")

    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("Weight")
    plt.xlabel("$|w|$")
    plt.ylabel("CDF")
    plt.xlim(0, 0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_cdf_vgg19_cifar10_level3.pdf")
    del all_cdf_mean
    del all_cdf_std
    fig.clf()
    plt.close()
    gc.collect()

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')
    import gc

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_cdf_mean = [cdf_mean_4_sgd, cdf_mean_4_sam, cdf_mean_4_ekfac]
    all_cdf_std = [cdf_std_4_sgd, cdf_std_4_sam, cdf_std_4_ekfac]
    labels = ["SGD", "ASAM", "EKFAC"]

    for i in range(len(all_cdf_mean)):
        mean = all_cdf_mean[i]
        std = all_cdf_std[i]
        label = labels[i]
        bin_count = cfd_bins_1_sgd[1:]
        axs.plot(bin_count, mean, label=labels[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")

    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("Weight")
    plt.xlabel("$|w|$")
    plt.ylabel("CDF")
    plt.xlim(0, 0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_cdf_vgg19_cifar10_level4.pdf")
    del all_cdf_mean
    del all_cdf_std
    fig.clf()
    plt.close()
    gc.collect()

    """## histograms"""

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_histogram_mean = [histogram_mean_1_sgd, histogram_mean_1_sam, histogram_mean_1_ekfac]
    all_histogram_std = [histogram_std_1_sgd, histogram_std_1_sam, histogram_std_1_ekfac]
    labels = ["SGD", "ASAM", "EKFAC"]
    alphas = [0.6, 0.5, 0.4]
    for i in range(len(all_histogram_mean)):
        mean = all_histogram_mean[i]
        std = all_histogram_std[i]
        label = labels[i]
        bin_count = histogram_bins_1_sgd[1:]
        # plt.hist(mean,bins=bin_count,label=labels[i])
        axs.bar(x=bin_count, height=mean, width=0.0002, align='edge', label=labels[i], alpha=alphas[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")

    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("Weight")
    plt.ylabel("Count")
    # plt.xlim(0,0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_histogram_vgg19_cifar10_level1.pdf")
    plt.close()

    np.diff(bin_count)

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_histogram_mean = [histogram_mean_2_sgd, histogram_mean_2_sam, histogram_mean_2_ekfac]
    all_histogram_std = [histogram_std_2_sgd, histogram_std_2_sam, histogram_std_2_ekfac]
    labels = ["SGD", "ASAM", "EKFAC"]

    for i in range(len(all_histogram_mean)):
        mean = all_histogram_mean[i]
        std = all_histogram_std[i]
        label = labels[i]
        bin_count = histogram_bins_1_sgd[1:]
        # plt.hist(mean,bins=bin_count,label=labels[i])
        axs.bar(x=bin_count, height=mean, width=0.0002, align='edge', label=labels[i], alpha=alphas[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")

    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("Weight")
    plt.ylabel("Count")
    # plt.xlim(0,0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_histogram_resnet_50_cifar10_level2.pdf")
    plt.close()

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_histogram_mean = [histogram_mean_3_sgd, histogram_mean_3_sam, histogram_mean_3_ekfac]
    all_histogram_std = [histogram_std_3_sgd, histogram_std_3_sam, histogram_std_3_ekfac]
    labels = ["SGD", "ASAM", "EKFAC"]

    for i in range(len(all_histogram_mean)):
        mean = all_histogram_mean[i]
        std = all_histogram_std[i]
        label = labels[i]
        bin_count = histogram_bins_1_sgd[1:]
        # plt.hist(mean,bins=bin_count,label=labels[i])
        axs.bar(x=bin_count, height=mean, width=0.0002, align='edge', label=labels[i], alpha=alphas[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")

    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("Weight")
    plt.ylabel("Count")
    # plt.xlim(0,0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_histogram_resnet_50_cifar10_level3.pdf")
    plt.close()

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    colors = ["m", "g", "r", "c"]
    import matplotlib
    matplotlib.use('agg')

    def find_nearest(array, value):
        array = np.array(array)
        idx = (np.abs(array - value)).argmin()
        return idx

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    all_histogram_mean = [histogram_mean_4_sgd, histogram_mean_4_sam, histogram_mean_4_ekfac]

    all_histogram_std = [histogram_std_4_sgd, histogram_std_4_sam, histogram_std_4_ekfac]

    labels = ["SGD", "ASAM", "EKFAC"]

    for i in range(len(all_histogram_mean)):
        mean = all_histogram_mean[i]
        std = all_histogram_std[i]
        label = labels[i]
        bin_count = histogram_bins_1_sgd[1:]
        # plt.hist(mean,bins=bin_count,label=labels[i])
        axs.bar(x=bin_count, height=mean, width=0.0002, align='edge', label=labels[i], alpha=alphas[i])
        # axs.fill_between(bin_count, mean - std, mean + std)

    # threshold_09 = find_nearest(mean, 0.9)
    # threshold_08 = find_nearest(mean, 0.8)
    # threshold_07 = find_nearest(mean, 0.7)
    # thresholds = [bin_count[threshold_07], bin_count[threshold_08], bin_count[threshold_09]]
    # pruning_rates = [0.7, 0.8, 0.9]

    # for i, threshold in enumerate(thresholds):
    #     pr = pruning_rates[i]
    #     plt.axvline(threshold, linewidth=1, color=colors[i], linestyle="dotted",
    #                 label=f"threshold @ pr {pr}")

    plt.grid(ls="--")
    plt.legend()
    plt.xlabel("Weight")
    plt.ylabel("Count")
    # plt.xlim(0,0.05)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_histogram_vgg19_cifar10_level4.pdf")
    plt.close()


def saturation_accuracy_plots():
    """# TODO: Pruning different intermediate layers results With GMP and Random pruning (with same pruning rates as GMP per layer)
     Here the general pruning rate is fixed to 0.9

    # vgg19
    """

    ekfac_lvl1 = "RF_vgg19_1_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_inter_layers_summary.csv"
    sgd_lvl1 = "RF_vgg19_1_cifar10_0.9_recording_200_no_ffcv_one_shot_inter_layers_summary.csv"
    sam_lvl1 = "RF_vgg19_1_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_inter_layers_summary.csv"

    ekfac_lvl2 = "RF_vgg19_2_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_inter_layers_summary.csv"
    sgd_lvl2 = "RF_vgg19_2_cifar10_0.9_recording_200_no_ffcv_one_shot_inter_layers_summary.csv"
    sam_lvl2 = "RF_vgg19_2_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_inter_layers_summary.csv"

    ekfac_lvl3 = "RF_vgg19_3_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_inter_layers_summary.csv"
    sgd_lvl3 = "RF_vgg19_3_cifar10_0.9_recording_200_no_ffcv_one_shot_inter_layers_summary.csv"
    sam_lvl3 = "RF_vgg19_3_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_inter_layers_summary.csv"

    ekfac_lvl4 = "RF_vgg19_4_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_inter_layers_summary.csv"
    sgd_lvl4 = "RF_vgg19_4_cifar10_0.9_recording_200_no_ffcv_one_shot_inter_layers_summary.csv"
    sam_lvl4 = "RF_vgg19_4_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_inter_layers_summary.csv"

    preamble = "inter_layer_pruning_results/"

    df_level1_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl1}", delimiter=",")
    df_level1_ekfac["RF"] = [vgg_rfs[1]] * len(df_level1_ekfac)
    df_level2_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl2}", delimiter=",")
    df_level2_ekfac["RF"] = [vgg_rfs[2]] * len(df_level2_ekfac)
    df_level3_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl3}", delimiter=",")
    df_level3_ekfac["RF"] = [vgg_rfs[3]] * len(df_level3_ekfac)
    df_level4_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl4}", delimiter=",")
    df_level4_ekfac["RF"] = [vgg_rfs[4]] * len(df_level4_ekfac)

    all_ekfac = pd.concat([df_level1_ekfac, df_level2_ekfac, df_level3_ekfac, df_level4_ekfac])

    df_level1_sam = pd.read_csv(f"{preamble}{sam_lvl1}", delimiter=",")
    df_level1_sam["RF"] = [vgg_rfs[1]] * len(df_level1_sam)
    df_level2_sam = pd.read_csv(f"{preamble}{sam_lvl2}", delimiter=",")

    df_level2_sam["RF"] = [vgg_rfs[2]] * len(df_level2_sam)
    df_level3_sam = pd.read_csv(f"{preamble}{sam_lvl3}", delimiter=",")
    df_level3_sam["RF"] = [vgg_rfs[3]] * len(df_level3_sam)
    df_level4_sam = pd.read_csv(f"{preamble}{sam_lvl4}", delimiter=",")
    df_level4_sam["RF"] = [vgg_rfs[4]] * len(df_level4_sam)

    all_sam = pd.concat([df_level1_sam, df_level2_sam, df_level3_sam, df_level4_sam])

    df_level1_sgd = pd.read_csv(f"{preamble}{sgd_lvl1}", delimiter=",")
    df_level1_sgd["RF"] = [vgg_rfs[1]] * len(df_level1_sgd)
    df_level2_sgd = pd.read_csv(f"{preamble}{sgd_lvl2}", delimiter=",")
    df_level2_sgd["RF"] = [vgg_rfs[2]] * len(df_level2_sgd)
    df_level3_sgd = pd.read_csv(f"{preamble}{sgd_lvl3}", delimiter=",")
    df_level3_sgd["RF"] = [vgg_rfs[3]] * len(df_level3_sgd)
    df_level4_sgd = pd.read_csv(f"{preamble}{sgd_lvl4}", delimiter=",")
    df_level4_sgd["RF"] = [vgg_rfs[4]] * len(df_level4_sgd)

    all_sgd = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd])
    all_sgd["optimiser"] = ["SGD"] * len(all_sgd)
    all_sam["optimiser"] = ["ASAM"] * len(all_sam)
    all_ekfac["optimiser"] = ["EKFAC"] * len(all_ekfac)

    all_df1 = pd.concat([all_ekfac, all_sam, all_sgd])

    """# TODO: SGD"""

    import seaborn as sns
    import matplotlib.pyplot as plt

    all_df = all_df1[all_df1["optimiser"] == "SGD"]

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            list_of_string = string.slit("_")
            layer_name = list_of_string[4]
            # o=string.replace("gmp_Accuracy_pruning_from_","")
            # o=o.replace("-","")
            # o=o.replace("-",".")
            return layer_name

    """## RF 131

    ### GMP
    """

    from delve.writers import plot_stat_level_from_results, plot_stat
    mean_df = all_df[all_df["RF"] == vgg_rfs[1]].filter(regex="gmp")

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:

        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")
    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    # ax.set_xticklabels([])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')
    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)

    plt.grid(ls="--", alpha=0.5)
    # plt.title("RF={}".format(vgg_rfs[1]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_1_sgd_gmp.pdf")
    plt.close()

    """### Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    mean_df = all_df[all_df["RF"] == vgg_rfs[1]].filter(regex="random")

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * labels_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()

    # plt.title("{}".format(vgg_rfs[1]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_1_sgd_random.pdf")
    plt.close()

    """## RF 315
        
        ### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 2
    method = "gmp"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726773380.2706754_rf_level_2_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")
    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    # ax.set_xticklabels([])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid(ls="--", alpha=0.5)
    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_2_sgd_gmp.pdf")
    plt.close()

    """### Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 2
    method = "random"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726773380.2706754_rf_level_2_recording_200_no_ffcv.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # #plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)
    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid(ls="--", alpha=0.5)

    # plt.title("RF={}".format(vgg_rfs[level]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_2_sgd_random.pdf")
    plt.close()

    from delve.writers import plot_stat_level_from_results

    plot_stat_level_from_results(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1725640015.7435527_rf_level_4_recording_200_no_ffcv.csv",
        199, "lsat", stat_mode="train")
    plt.close()

    """## RF 537
        
        ### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 3
    method = "gmp"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1725639932.8630962_rf_level_3_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")
    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    # ax.set_xticklabels([])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid(ls="--", alpha=0.5)
    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)

    # plt.title("RF={}".format(vgg_rfs[level]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_3_sgd_gmp.pdf")

    plt.close()

    """### Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 3
    method = "random"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1725640015.7435527_rf_level_4_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)
    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid(ls="--", alpha=0.5)

    # plt.title("RF={}".format(vgg_rfs[level]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_3_sgd_random.pdf")

    plt.close()

    """## RF 715
        
        ### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 4
    method = "gmp"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1725640015.7435527_rf_level_4_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")
    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    # ax.set_xticklabels([])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid(ls="--", alpha=0.5)
    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)
    # plt.title("RF={}".format(vgg_rfs[level]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_4_sgd_gmp.pdf")

    plt.close()

    """### Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 3
    method = "random"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1725639932.8630962_rf_level_3_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)
    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid(ls="--", alpha=0.5)
    # plt.title("RF={}".format(vgg_rfs[level]))

    # plt.title("RF={}".format(vgg_rfs[level]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_4_sgd_random.pdf")

    plt.close()

    """# TODO: EKFAC"""

    import seaborn as sns
    import matplotlib.pyplot as plt

    all_df = all_df1[all_df1["optimiser"] == "EKFAC"]

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            list_of_string = string.slit("_")
            layer_name = list_of_string[4]
            # o=string.replace("gmp_Accuracy_pruning_from_","")
            # o=o.replace("-","")
            # o=o.replace("-",".")
            return layer_name

    all_df

    """## RF 181
        
        ### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    mean_df = all_df[all_df["RF"] == vgg_rfs[1]].filter(regex="gmp")

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    ax2.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_1_ekfac_gmp.pdf")
    plt.grid()
    # plt.title("RF={}".format(vgg_rfs[1]))
    plt.close()

    layer_names, o

    """## Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    mean_df = all_df[all_df["RF"] == vgg_rfs[1]].filter(regex="random")

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_2_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()

    # plt.title("RF={}".format(vgg_rfs[1]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_1_ekfac_random.pdf")
    plt.close()

    """## RF 359
        
        ### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 2
    method = "gmp"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_2_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()

    # plt.title("RF={}".format(vgg_rfs[level]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_2_ekfac_gmp.pdf")

    plt.close()

    """### Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 2
    method = "random"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_2_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()

    # plt.title("RF={}".format(vgg_rfs[level]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_2_ekfac_random.pdf")
    plt.close()

    """## RF 537
        
        ### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 3
    method = "gmp"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_3_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()

    # plt.title("RF={}".format(vgg_rfs[level]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_3_ekfac_gmp.pdf")
    plt.close()

    """### Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 3
    method = "random"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_3_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()

    # plt.title("RF={}".format(vgg_rfs[level]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_3_ekfac_random.pdf")

    plt.close()

    """## RF 715
        
        ### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 4
    method = "gmp"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_4_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()

    # plt.title("RF={}".format(vgg_rfs[level]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_4_ekfac_gmp.pdf")

    plt.close()

    """ ## Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 4
    method = "random"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_4_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()

    # plt.title("RF={}".format(vgg_rfs[level]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_2_ekfac_random.pdf")

    plt.close()

    """# TODO: ASAM"""

    import seaborn as sns
    import matplotlib.pyplot as plt

    all_df = all_df1[all_df1["optimiser"] == "ASAM"]

    def change_and_sort_names(df):
        pass
        # names = list(df["name"])
        # sorted_index = []
        #
        # def trim(string):
        # list_of_string = string.slit("_")
        # layer_name = list_of_string[4]
        # # o=string.replace("gmp_Accuracy_pruning_from_","")
        # # o=o.replace("-","")
        # # o=o.replace("-",".")
        # return layer_name

    all_df

    """## RF 181
        
        ### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    mean_df = all_df[all_df["RF"] == vgg_rfs[1]].filter(regex="gmp")

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()

    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/ASAM/vgg19_normal_cifar10_rf_level_1_sam_optim_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))

    means = []
    stds = []

    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_1_sam_gmp.pdf")
    plt.grid()
    # plt.title("RF={}".format(vgg_rfs[1]))
    plt.close()

    layer_names, o

    """### Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    mean_df = all_df[all_df["RF"] == vgg_rfs[1]].filter(regex="random")

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_2_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()

    # plt.title("RF={}".format(vgg_rfs[1]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_1_sam_random.pdf")

    plt.close()

    """## RF 359
        
        ### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 2
    method = "gmp"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_2_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()

    # plt.title("RF={}".format(vgg_rfs[level]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_2_sam_gmp.pdf")

    plt.close()

    """### Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 2
    method = "random"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_2_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()

    # plt.title("RF={}".format(vgg_rfs[level]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_2_sam_random.pdf")

    plt.close()

    """## RF 537
        
        ### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 3
    method = "gmp"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_3_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()

    # plt.title("RF={}".format(vgg_rfs[level]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_3_sam_gmp.pdf")
    plt.close()

    """### RANDOM"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 3
    method = "random"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_3_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()

    # plt.title("RF={}".format(vgg_rfs[level]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_3_sam_random.pdf")
    plt.close()

    """## RF 715
        
        ### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 4
    method = "gmp"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_4_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()

    # plt.title("RF={}".format(vgg_rfs[level]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_4_sam_gmp.pdf")
    plt.close()

    """### Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 4
    method = "random"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_4_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()

    # plt.title("RF={}".format(vgg_rfs[level]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_4_sam_random.pdf")

    plt.close()

    """# TODO: Resnet50
        
        # Out block
        """

    ekfac_lvl1 = "RF_resnet50_1_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"
    sgd_lvl1 = "RF_resnet50_1_cifar10_0.9_recording_200_no_ffcv_one_shot_in_block_layers_summary.csv"
    sam_lvl1 = "RF_resnet50_1_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"

    ekfac_lvl2 = "RF_resnet50_2_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"
    sgd_lvl2 = "RF_resnet50_2_cifar10_0.9_recording_200_no_ffcv_one_shot_in_block_layers_summary.csv"
    sam_lvl2 = "RF_resnet50_2_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"

    ekfac_lvl3 = "RF_resnet50_3_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"
    sgd_lvl3 = "RF_resnet50_3_cifar10_0.9_recording_200_no_ffcv_one_shot_in_block_layers_summary.csv"
    sam_lvl3 = "RF_resnet50_3_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"

    ekfac_lvl4 = "RF_resnet50_4_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"
    sgd_lvl4 = "RF_resnet50_4_cifar10_0.9_recording_200_no_ffcv_one_shot_in_block_layers_summary.csv"
    sam_lvl4 = "RF_resnet50_4_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"

    preamble = "inter_layer_pruning_results/"

    df_level1_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl1}", delimiter=",")
    df_level1_ekfac["RF"] = [resnets_rfs[1]] * len(df_level1_ekfac)
    df_level2_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl2}", delimiter=",")
    df_level2_ekfac["RF"] = [resnets_rfs[2]] * len(df_level2_ekfac)
    df_level3_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl3}", delimiter=",")
    df_level3_ekfac["RF"] = [resnets_rfs[3]] * len(df_level3_ekfac)
    df_level4_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl4}", delimiter=",")
    df_level4_ekfac["RF"] = [resnets_rfs[4]] * len(df_level4_ekfac)

    all_ekfac = pd.concat([df_level1_ekfac, df_level2_ekfac, df_level3_ekfac, df_level4_ekfac])

    df_level1_sam = pd.read_csv(f"{preamble}{sam_lvl1}", delimiter=",")
    df_level1_sam["RF"] = [resnets_rfs[1]] * len(df_level1_sam)
    df_level2_sam = pd.read_csv(f"{preamble}{sam_lvl2}", delimiter=",")

    df_level2_sam["RF"] = [resnets_rfs[2]] * len(df_level2_sam)
    df_level3_sam = pd.read_csv(f"{preamble}{sam_lvl3}", delimiter=",")
    df_level3_sam["RF"] = [resnets_rfs[3]] * len(df_level3_sam)
    df_level4_sam = pd.read_csv(f"{preamble}{sam_lvl4}", delimiter=",")
    df_level4_sam["RF"] = [resnets_rfs[4]] * len(df_level4_sam)

    all_sam = pd.concat([df_level1_sam, df_level2_sam, df_level3_sam, df_level4_sam])

    df_level1_sgd = pd.read_csv(f"{preamble}{sgd_lvl1}", delimiter=",")
    df_level1_sgd["RF"] = [resnets_rfs[1]] * len(df_level1_sgd)
    df_level2_sgd = pd.read_csv(f"{preamble}{sgd_lvl2}", delimiter=",")
    df_level2_sgd["RF"] = [resnets_rfs[2]] * len(df_level2_sgd)
    df_level3_sgd = pd.read_csv(f"{preamble}{sgd_lvl3}", delimiter=",")
    df_level3_sgd["RF"] = [resnets_rfs[3]] * len(df_level3_sgd)
    df_level4_sgd = pd.read_csv(f"{preamble}{sgd_lvl4}", delimiter=",")
    df_level4_sgd["RF"] = [resnets_rfs[4]] * len(df_level4_sgd)

    all_sgd = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd])
    all_sgd["optimiser"] = ["SGD"] * len(all_sgd)
    all_sam["optimiser"] = ["ASAM"] * len(all_sam)
    all_ekfac["optimiser"] = ["EKFAC"] * len(all_ekfac)

    all_df_in_block = pd.concat([all_ekfac, all_sam, all_sgd])

    ekfac_lvl1 = "RF_resnet50_1_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"
    sgd_lvl1 = "RF_resnet50_1_cifar10_0.9_recording_200_no_ffcv_one_shot_out_block_layer_summary.csv"
    sam_lvl1 = "RF_resnet50_1_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"

    ekfac_lvl2 = "RF_resnet50_2_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"
    sgd_lvl2 = "RF_resnet50_2_cifar10_0.9_recording_200_no_ffcv_one_shot_out_block_layer_summary.csv"
    sam_lvl2 = "RF_resnet50_2_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"

    ekfac_lvl3 = "RF_resnet50_3_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"
    sgd_lvl3 = "RF_resnet50_3_cifar10_0.9_recording_200_no_ffcv_one_shot_out_block_layer_summary.csv"
    sam_lvl3 = "RF_resnet50_3_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"

    ekfac_lvl4 = "RF_resnet50_4_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"
    sgd_lvl4 = "RF_resnet50_4_cifar10_0.9_recording_200_no_ffcv_one_shot_out_block_layer_summary.csv"
    sam_lvl4 = "RF_resnet50_4_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"

    preamble = "inter_layer_pruning_results/"

    df_level1_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl1}", delimiter=",")
    df_level1_ekfac["RF"] = [resnets_rfs[1]] * len(df_level1_ekfac)
    df_level2_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl2}", delimiter=",")
    df_level2_ekfac["RF"] = [resnets_rfs[2]] * len(df_level2_ekfac)
    df_level3_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl3}", delimiter=",")
    df_level3_ekfac["RF"] = [resnets_rfs[3]] * len(df_level3_ekfac)
    df_level4_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl4}", delimiter=",")
    df_level4_ekfac["RF"] = [resnets_rfs[4]] * len(df_level4_ekfac)

    all_ekfac = pd.concat([df_level1_ekfac, df_level2_ekfac, df_level3_ekfac, df_level4_ekfac])

    df_level1_sam = pd.read_csv(f"{preamble}{sam_lvl1}", delimiter=",")
    df_level1_sam["RF"] = [resnets_rfs[1]] * len(df_level1_sam)
    df_level2_sam = pd.read_csv(f"{preamble}{sam_lvl2}", delimiter=",")

    df_level2_sam["RF"] = [resnets_rfs[2]] * len(df_level2_sam)
    df_level3_sam = pd.read_csv(f"{preamble}{sam_lvl3}", delimiter=",")
    df_level3_sam["RF"] = [resnets_rfs[3]] * len(df_level3_sam)
    df_level4_sam = pd.read_csv(f"{preamble}{sam_lvl4}", delimiter=",")
    df_level4_sam["RF"] = [resnets_rfs[4]] * len(df_level4_sam)

    all_sam = pd.concat([df_level1_sam, df_level2_sam, df_level3_sam, df_level4_sam])

    df_level1_sgd = pd.read_csv(f"{preamble}{sgd_lvl1}", delimiter=",")
    df_level1_sgd["RF"] = [resnets_rfs[1]] * len(df_level1_sgd)
    df_level2_sgd = pd.read_csv(f"{preamble}{sgd_lvl2}", delimiter=",")
    df_level2_sgd["RF"] = [resnets_rfs[2]] * len(df_level2_sgd)
    df_level3_sgd = pd.read_csv(f"{preamble}{sgd_lvl3}", delimiter=",")
    df_level3_sgd["RF"] = [resnets_rfs[3]] * len(df_level3_sgd)
    df_level4_sgd = pd.read_csv(f"{preamble}{sgd_lvl4}", delimiter=",")
    df_level4_sgd["RF"] = [resnets_rfs[4]] * len(df_level4_sgd)

    all_sgd = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd])
    all_sgd["optimiser"] = ["SGD"] * len(all_sgd)
    all_sam["optimiser"] = ["ASAM"] * len(all_sam)
    all_ekfac["optimiser"] = ["EKFAC"] * len(all_ekfac)

    all_df_out_block = pd.concat([all_ekfac, all_sam, all_sgd])

    """## EKFAC"""

    import seaborn as sns
    import matplotlib.pyplot as plt

    all_df = all_df_out_block[all_df_out_block["optimiser"] == "EKFAC"]

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            list_of_string = string.slit(" ")
            layer_name = list_of_string[2]
            layer_name = layer_name.split("-")[0]
            # o=string.replace("gmp_Accuracy_pruning_from_","")
            # o=o.replace("-","")
            # o=o.replace("-",".")
            return layer_name

    def trim(string):
        list_of_string = string.split(" ")
        layer_name = list_of_string[2]
        layer_name = layer_name.split("-")[0]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name

    all_df_in_block

    """### RF 110
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[1]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[1]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_1_ekfac_gmp.pdf")
    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[1]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[1]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_1_ekfac_random.pdf")

    plt.close()

    mean_df

    """### RF 213
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[2]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')
    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[2]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_2_ekfac_gmp.pdf")
    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[2]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[2]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_2_ekfac_random.pdf")
    plt.close()

    """### RF 318
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[3]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[3]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_3_ekfac_gmp.pdf")

    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[3]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[3]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_3_ekfac_random.pdf")
    plt.close()

    """### RF 423
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[4]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[4]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_4_ekfac_gmp.pdf")

    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[4]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[4]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_4_ekfac_random.pdf")

    plt.close()

    """## SGD"""

    import seaborn as sns
    import matplotlib.pyplot as plt

    all_df = all_df_out_block[all_df_out_block["optimiser"] == "SGD"]

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            list_of_string = string.slit(" ")
            layer_name = list_of_string[2]
            layer_name = layer_name.split("-")[0]
            # o=string.replace("gmp_Accuracy_pruning_from_","")
            # o=o.replace("-","")
            # o=o.replace("-",".")
            return layer_name

    def trim(string):
        list_of_string = string.split(" ")
        layer_name = list_of_string[2]
        layer_name = layer_name.split("-")[0]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name

    all_df_in_block

    """### RF 110
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[1]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1726773378.6547081_rf_level_1_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")
    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    # ax.set_xticklabels([])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.xaxis.set_major_locator(ticker.MultipleLocator(5))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(3))
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid(ls="--", alpha=0.5)
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_1_sgd_gmp.pdf")
    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[1]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[1]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_1_sgd_random.pdf")
    plt.close()

    mean_df

    """### RF 213
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[2]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1726773352.3026712_rf_level_2_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")
    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    # ax.set_xticklabels([])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.xaxis.set_major_locator(ticker.MultipleLocator(5))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(3))
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid(ls="--", alpha=0.5)
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_2_sgd_gmp.pdf")
    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[2]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[2]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_2_sgd_random.pdf")
    plt.close()

    """### RF 318
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[3]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1726248344.7113843_rf_level_3_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")
    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    # ax.set_xticklabels([])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.xaxis.set_major_locator(ticker.MultipleLocator(5))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(3))
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid(ls="--", alpha=0.5)

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_3_sgd_gmp.pdf")

    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[3]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[3]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_3_sgd_random.pdf")

    plt.close()

    """### RF 423
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[4]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1726248344.4095678_rf_level_4_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")
    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    # ax.set_xticklabels([])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.xaxis.set_major_locator(ticker.MultipleLocator(5))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(3))
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid(ls="--", alpha=0.5)

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_4_sgd_gmp.pdf")

    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[4]].filter(regex=method)

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[4]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_4_sgd_random.pdf")
    plt.close()

    """## ASAM"""

    import seaborn as sns
    import matplotlib.pyplot as plt

    all_df = all_df_out_block[all_df_out_block["optimiser"] == "ASAM"]

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            list_of_string = string.slit(" ")
            layer_name = list_of_string[2]
            layer_name = layer_name.split("-")[0]
            # o=string.replace("gmp_Accuracy_pruning_from_","")
            # o=o.replace("-","")
            # o=o.replace("-",".")
            return layer_name

    def trim(string):
        list_of_string = string.split(" ")
        layer_name = list_of_string[2]
        layer_name = layer_name.split("-")[0]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name

    """### RF 110
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[1]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[1]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_1_sam_gmp.pdf")

    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[1]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[1]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_1_sam_random.pdf")
    plt.close()

    mean_df

    """### RF 213
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[2]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[2]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_2_sam_gmp.pdf")
    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[2]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[2]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_2_sam_random.pdf")
    plt.close()

    """### RF 318
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[3]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[3]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_3_sam_gmp.pdf")
    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[3]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:

        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')
    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[3]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_3_sam_random.pdf")
    plt.close()

    """### RF 423
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[4]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[4]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_4_sam_gmp.pdf")
    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[4]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:

        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[4]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_4_sam_random.pdf")
    plt.close()

    """# TODO: In block"""

    ekfac_lvl1 = "RF_resnet50_1_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"
    sgd_lvl1 = "RF_resnet50_1_cifar10_0.9_recording_200_no_ffcv_one_shot_in_block_layers_summary.csv"
    sam_lvl1 = "RF_resnet50_1_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"

    ekfac_lvl2 = "RF_resnet50_2_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"
    sgd_lvl2 = "RF_resnet50_2_cifar10_0.9_recording_200_no_ffcv_one_shot_in_block_layers_summary.csv"
    sam_lvl2 = "RF_resnet50_2_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"

    ekfac_lvl3 = "RF_resnet50_3_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"
    sgd_lvl3 = "RF_resnet50_3_cifar10_0.9_recording_200_no_ffcv_one_shot_in_block_layers_summary.csv"
    sam_lvl3 = "RF_resnet50_3_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"

    ekfac_lvl4 = "RF_resnet50_4_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"
    sgd_lvl4 = "RF_resnet50_4_cifar10_0.9_recording_200_no_ffcv_one_shot_in_block_layers_summary.csv"
    sam_lvl4 = "RF_resnet50_4_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"

    preamble = "inter_layer_pruning_results/"

    df_level1_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl1}", delimiter=",")
    df_level1_ekfac["RF"] = [resnets_rfs[1]] * len(df_level1_ekfac)
    df_level2_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl2}", delimiter=",")
    df_level2_ekfac["RF"] = [resnets_rfs[2]] * len(df_level2_ekfac)
    df_level3_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl3}", delimiter=",")
    df_level3_ekfac["RF"] = [resnets_rfs[3]] * len(df_level3_ekfac)
    df_level4_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl4}", delimiter=",")
    df_level4_ekfac["RF"] = [resnets_rfs[4]] * len(df_level4_ekfac)

    all_ekfac = pd.concat([df_level1_ekfac, df_level2_ekfac, df_level3_ekfac, df_level4_ekfac])

    df_level1_sam = pd.read_csv(f"{preamble}{sam_lvl1}", delimiter=",")
    df_level1_sam["RF"] = [resnets_rfs[1]] * len(df_level1_sam)
    df_level2_sam = pd.read_csv(f"{preamble}{sam_lvl2}", delimiter=",")

    df_level2_sam["RF"] = [resnets_rfs[2]] * len(df_level2_sam)
    df_level3_sam = pd.read_csv(f"{preamble}{sam_lvl3}", delimiter=",")
    df_level3_sam["RF"] = [resnets_rfs[3]] * len(df_level3_sam)
    df_level4_sam = pd.read_csv(f"{preamble}{sam_lvl4}", delimiter=",")
    df_level4_sam["RF"] = [resnets_rfs[4]] * len(df_level4_sam)

    all_sam = pd.concat([df_level1_sam, df_level2_sam, df_level3_sam, df_level4_sam])

    df_level1_sgd = pd.read_csv(f"{preamble}{sgd_lvl1}", delimiter=",")
    df_level1_sgd["RF"] = [resnets_rfs[1]] * len(df_level1_sgd)
    df_level2_sgd = pd.read_csv(f"{preamble}{sgd_lvl2}", delimiter=",")
    df_level2_sgd["RF"] = [resnets_rfs[2]] * len(df_level2_sgd)
    df_level3_sgd = pd.read_csv(f"{preamble}{sgd_lvl3}", delimiter=",")
    df_level3_sgd["RF"] = [resnets_rfs[3]] * len(df_level3_sgd)
    df_level4_sgd = pd.read_csv(f"{preamble}{sgd_lvl4}", delimiter=",")
    df_level4_sgd["RF"] = [resnets_rfs[4]] * len(df_level4_sgd)

    all_sgd = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd])
    all_sgd["optimiser"] = ["SGD"] * len(all_sgd)
    all_sam["optimiser"] = ["ASAM"] * len(all_sam)
    all_ekfac["optimiser"] = ["EKFAC"] * len(all_ekfac)

    all_df_in_block = pd.concat([all_ekfac, all_sam, all_sgd])

    # all_df_in_block=all_df_in_block.filter(regex="layer4.2.conv2")
    # all_df_in_block.filter(regex="layer4.2.conv2")

    ekfac_lvl1 = "RF_resnet50_1_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"
    sgd_lvl1 = "RF_resnet50_1_cifar10_0.9_recording_200_no_ffcv_one_shot_out_block_layer_summary.csv"
    sam_lvl1 = "RF_resnet50_1_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"

    ekfac_lvl2 = "RF_resnet50_2_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"
    sgd_lvl2 = "RF_resnet50_2_cifar10_0.9_recording_200_no_ffcv_one_shot_out_block_layer_summary.csv"
    sam_lvl2 = "RF_resnet50_2_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"

    ekfac_lvl3 = "RF_resnet50_3_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"
    sgd_lvl3 = "RF_resnet50_3_cifar10_0.9_recording_200_no_ffcv_one_shot_out_block_layer_summary.csv"
    sam_lvl3 = "RF_resnet50_3_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"

    ekfac_lvl4 = "RF_resnet50_4_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"
    sgd_lvl4 = "RF_resnet50_4_cifar10_0.9_recording_200_no_ffcv_one_shot_out_block_layer_summary.csv"
    sam_lvl4 = "RF_resnet50_4_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"

    preamble = "inter_layer_pruning_results/"

    df_level1_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl1}", delimiter=",")
    df_level1_ekfac["RF"] = [resnets_rfs[1]] * len(df_level1_ekfac)
    df_level2_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl2}", delimiter=",")
    df_level2_ekfac["RF"] = [resnets_rfs[2]] * len(df_level2_ekfac)
    df_level3_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl3}", delimiter=",")
    df_level3_ekfac["RF"] = [resnets_rfs[3]] * len(df_level3_ekfac)
    df_level4_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl4}", delimiter=",")
    df_level4_ekfac["RF"] = [resnets_rfs[4]] * len(df_level4_ekfac)

    all_ekfac = pd.concat([df_level1_ekfac, df_level2_ekfac, df_level3_ekfac, df_level4_ekfac])

    df_level1_sam = pd.read_csv(f"{preamble}{sam_lvl1}", delimiter=",")
    df_level1_sam["RF"] = [resnets_rfs[1]] * len(df_level1_sam)
    df_level2_sam = pd.read_csv(f"{preamble}{sam_lvl2}", delimiter=",")

    df_level2_sam["RF"] = [resnets_rfs[2]] * len(df_level2_sam)
    df_level3_sam = pd.read_csv(f"{preamble}{sam_lvl3}", delimiter=",")
    df_level3_sam["RF"] = [resnets_rfs[3]] * len(df_level3_sam)
    df_level4_sam = pd.read_csv(f"{preamble}{sam_lvl4}", delimiter=",")
    df_level4_sam["RF"] = [resnets_rfs[4]] * len(df_level4_sam)

    all_sam = pd.concat([df_level1_sam, df_level2_sam, df_level3_sam, df_level4_sam])

    df_level1_sgd = pd.read_csv(f"{preamble}{sgd_lvl1}", delimiter=",")
    df_level1_sgd["RF"] = [resnets_rfs[1]] * len(df_level1_sgd)
    df_level2_sgd = pd.read_csv(f"{preamble}{sgd_lvl2}", delimiter=",")
    df_level2_sgd["RF"] = [resnets_rfs[2]] * len(df_level2_sgd)
    df_level3_sgd = pd.read_csv(f"{preamble}{sgd_lvl3}", delimiter=",")
    df_level3_sgd["RF"] = [resnets_rfs[3]] * len(df_level3_sgd)
    df_level4_sgd = pd.read_csv(f"{preamble}{sgd_lvl4}", delimiter=",")
    df_level4_sgd["RF"] = [resnets_rfs[4]] * len(df_level4_sgd)

    all_sgd = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd])
    all_sgd["optimiser"] = ["SGD"] * len(all_sgd)
    all_sam["optimiser"] = ["ASAM"] * len(all_sam)
    all_ekfac["optimiser"] = ["EKFAC"] * len(all_ekfac)

    # all_df_out_block = pd.concat([all_ekfac, all_sam, all_sgd])

    """## EKFAC"""

    import seaborn as sns
    import matplotlib.pyplot as plt

    all_df = all_df_in_block[all_df_in_block["optimiser"] == "EKFAC"]

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            list_of_string = string.slit(" ")
            layer_name = list_of_string[2]
            layer_name = layer_name.split("-")[0]
            # o=string.replace("gmp_Accuracy_pruning_from_","")
            # o=o.replace("-","")
            # o=o.replace("-",".")
            return layer_name

    def trim(string):
        list_of_string = string.split(" ")
        layer_name = list_of_string[2]
        layer_name = layer_name.split("-")[0]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name

    all_df_in_block.filter(regex="layer4.2.conv2")

    """### RF 110
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[1]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Pruned Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[1]))
    # plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet50_GMP_in_block_pruning_sat_lvl_1.pdf")
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_1_ekfac_gmp.pdf")

    plt.close()

    mean_df.filter(regex="layer4.2.conv")

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[1]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[1]))
    # plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet50_RANDOM_in_block_pruning_sat_lvl_1.pdf")
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_1_ekfac_random.pdf")
    plt.close()

    mean_df

    """### RF 213
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[2]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[1]))
    # plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet50_GMP_in_block_pruning_sat_lvl_2.pdf")
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_2_ekfac_gmp.pdf")
    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[2]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[1]))
    # plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet50_RANDOM_in_block_pruning_sat_lvl_2.pdf")
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_2_ekfac_random.pdf")
    plt.close()

    """### RF 318
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[3]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[1]))
    # plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet50_GMP_in_block_pruning_sat_lvl_3.pdf")
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_3_ekfac_gmp.pdf")
    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[3]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[1]))
    # plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet50_RANDOM_in_block_pruning_sat_lvl_3.pdf")
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_3_ekfac_random.pdf")
    plt.close()

    """### RF 423
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[4]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[4]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_4_ekfac_gmp.pdf")
    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[4]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')
    plt.grid()

    # plt.title("RF={}".format(resnets_rfs_values[4]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_4_ekfac_random.pdf")
    plt.close()

    """## SGD"""

    import seaborn as sns
    import matplotlib.pyplot as plt

    all_df = all_df_in_block[all_df_in_block["optimiser"] == "SGD"]

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            list_of_string = string.slit(" ")
            layer_name = list_of_string[2]
            layer_name = layer_name.split("-")[0]
            # o=string.replace("gmp_Accuracy_pruning_from_","")
            # o=o.replace("-","")
            # o=o.replace("-",".")
            return layer_name

    def trim(string):
        list_of_string = string.split(" ")
        layer_name = list_of_string[2]
        layer_name = layer_name.split("-")[0]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name

    all_df_in_block

    """### RF 110
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[1]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1726773378.6547081_rf_level_1_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))

    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")
    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)
    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    # ax.set_xticklabels([])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.xaxis.set_major_locator(ticker.MultipleLocator(10))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid(ls="--", alpha=0.5)
    # plt.title("RF={}".format(resnets_rfs_values[1]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_1_sgd_gmp.pdf")
    plt.close()
    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[1]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[1]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_1_sgd_random.pdf")

    plt.close()

    mean_df

    """### RF 213
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[2]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1726773352.3026712_rf_level_2_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")
    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.xaxis.set_major_locator(ticker.MultipleLocator(10))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)
    plt.grid(ls="--", alpha=0.5)
    # plt.title("RF={}".format(resnets_rfs_values[2]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_2_sgd_gmp.pdf")
    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[2]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[2]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_2_sgd_random.pdf")

    plt.close()

    """### RF 318
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[3]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1726248344.7113843_rf_level_3_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")
    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    # ax.set_xticklabels([])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.xaxis.set_major_locator(ticker.MultipleLocator(10))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)
    plt.grid(ls="--", alpha=0.5)
    # plt.title("RF={}".format(resnets_rfs_values[3]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_3_sgd_gmp.pdf")
    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[3]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[3]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_3_sgd_random.pdf")
    plt.close()

    """### RF 423
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[4]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1726248344.4095678_rf_level_4_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")
    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    # ax.set_xticklabels([])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.xaxis.set_major_locator(ticker.MultipleLocator(10))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)
    plt.grid(ls="--", alpha=0.5)

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_4_sgd_gmp.pdf")

    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[4]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[4]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_4_sgd_random.pdf")
    plt.close()

    """## ASAM"""

    import seaborn as sns
    import matplotlib.pyplot as plt

    all_df = all_df_in_block[all_df_in_block["optimiser"] == "ASAM"]

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            list_of_string = string.slit(" ")
            layer_name = list_of_string[2]
            layer_name = layer_name.split("-")[0]
            # o=string.replace("gmp_Accuracy_pruning_from_","")
            # o=o.replace("-","")
            # o=o.replace("-",".")
            return layer_name

    def trim(string):
        list_of_string = string.split(" ")
        layer_name = list_of_string[2]
        layer_name = layer_name.split("-")[0]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name

    all_df_in_block

    """### RF 110
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[1]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[1]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_1_sam_gmp.pdf")
    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[1]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[1]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_1_sam_random.pdf")
    plt.close()

    mean_df

    """### RF 213
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[2]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[2]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_2_sam_gmp.pdf")
    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[2]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[2]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_2_sam_random.pdf")
    plt.close()

    """### RF 318
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[3]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[3]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_3_sam_gmp.pdf")
    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[3]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[3]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_3_sam_random.pdf")
    plt.close()

    """### RF 423
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[4]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[4]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_4_sam_gmp.pdf")
    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[4]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[4]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_4_sam_random.pdf")
    plt.close()
def saturation_accuracy_resnet50_plots():
    """# TODO: In block"""

    ekfac_lvl1 = "RF_resnet50_1_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"
    sgd_lvl1 = "RF_resnet50_1_cifar10_0.9_recording_200_no_ffcv_one_shot_in_block_layers_summary.csv"
    sam_lvl1 = "RF_resnet50_1_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"

    ekfac_lvl2 = "RF_resnet50_2_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"
    sgd_lvl2 = "RF_resnet50_2_cifar10_0.9_recording_200_no_ffcv_one_shot_in_block_layers_summary.csv"
    sam_lvl2 = "RF_resnet50_2_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"

    ekfac_lvl3 = "RF_resnet50_3_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"
    sgd_lvl3 = "RF_resnet50_3_cifar10_0.9_recording_200_no_ffcv_one_shot_in_block_layers_summary.csv"
    sam_lvl3 = "RF_resnet50_3_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"

    ekfac_lvl4 = "RF_resnet50_4_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"
    sgd_lvl4 = "RF_resnet50_4_cifar10_0.9_recording_200_no_ffcv_one_shot_in_block_layers_summary.csv"
    sam_lvl4 = "RF_resnet50_4_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_in_block_layers_summary.csv"

    preamble = "inter_layer_pruning_results/"

    df_level1_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl1}", delimiter=",")
    df_level1_ekfac["RF"] = [resnets_rfs[1]] * len(df_level1_ekfac)
    df_level2_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl2}", delimiter=",")
    df_level2_ekfac["RF"] = [resnets_rfs[2]] * len(df_level2_ekfac)
    df_level3_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl3}", delimiter=",")
    df_level3_ekfac["RF"] = [resnets_rfs[3]] * len(df_level3_ekfac)
    df_level4_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl4}", delimiter=",")
    df_level4_ekfac["RF"] = [resnets_rfs[4]] * len(df_level4_ekfac)

    all_ekfac = pd.concat([df_level1_ekfac, df_level2_ekfac, df_level3_ekfac, df_level4_ekfac])

    df_level1_sam = pd.read_csv(f"{preamble}{sam_lvl1}", delimiter=",")
    df_level1_sam["RF"] = [resnets_rfs[1]] * len(df_level1_sam)
    df_level2_sam = pd.read_csv(f"{preamble}{sam_lvl2}", delimiter=",")

    df_level2_sam["RF"] = [resnets_rfs[2]] * len(df_level2_sam)
    df_level3_sam = pd.read_csv(f"{preamble}{sam_lvl3}", delimiter=",")
    df_level3_sam["RF"] = [resnets_rfs[3]] * len(df_level3_sam)
    df_level4_sam = pd.read_csv(f"{preamble}{sam_lvl4}", delimiter=",")
    df_level4_sam["RF"] = [resnets_rfs[4]] * len(df_level4_sam)

    all_sam = pd.concat([df_level1_sam, df_level2_sam, df_level3_sam, df_level4_sam])

    df_level1_sgd = pd.read_csv(f"{preamble}{sgd_lvl1}", delimiter=",")
    df_level1_sgd["RF"] = [resnets_rfs[1]] * len(df_level1_sgd)
    df_level2_sgd = pd.read_csv(f"{preamble}{sgd_lvl2}", delimiter=",")
    df_level2_sgd["RF"] = [resnets_rfs[2]] * len(df_level2_sgd)
    df_level3_sgd = pd.read_csv(f"{preamble}{sgd_lvl3}", delimiter=",")
    df_level3_sgd["RF"] = [resnets_rfs[3]] * len(df_level3_sgd)
    df_level4_sgd = pd.read_csv(f"{preamble}{sgd_lvl4}", delimiter=",")
    df_level4_sgd["RF"] = [resnets_rfs[4]] * len(df_level4_sgd)

    all_sgd = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd])
    all_sgd["optimiser"] = ["SGD"] * len(all_sgd)
    all_sam["optimiser"] = ["ASAM"] * len(all_sam)
    all_ekfac["optimiser"] = ["EKFAC"] * len(all_ekfac)

    all_df_in_block = pd.concat([all_ekfac, all_sam, all_sgd])

    # all_df_in_block=all_df_in_block.filter(regex="layer4.2.conv2")
    # all_df_in_block.filter(regex="layer4.2.conv2")

    ekfac_lvl1 = "RF_resnet50_1_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"
    sgd_lvl1 = "RF_resnet50_1_cifar10_0.9_recording_200_no_ffcv_one_shot_out_block_layer_summary.csv"
    sam_lvl1 = "RF_resnet50_1_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"

    ekfac_lvl2 = "RF_resnet50_2_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"
    sgd_lvl2 = "RF_resnet50_2_cifar10_0.9_recording_200_no_ffcv_one_shot_out_block_layer_summary.csv"
    sam_lvl2 = "RF_resnet50_2_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"

    ekfac_lvl3 = "RF_resnet50_3_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"
    sgd_lvl3 = "RF_resnet50_3_cifar10_0.9_recording_200_no_ffcv_one_shot_out_block_layer_summary.csv"
    sam_lvl3 = "RF_resnet50_3_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"

    ekfac_lvl4 = "RF_resnet50_4_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"
    sgd_lvl4 = "RF_resnet50_4_cifar10_0.9_recording_200_no_ffcv_one_shot_out_block_layer_summary.csv"
    sam_lvl4 = "RF_resnet50_4_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_out_block_layer_summary.csv"

    preamble = "inter_layer_pruning_results/"

    df_level1_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl1}", delimiter=",")
    df_level1_ekfac["RF"] = [resnets_rfs[1]] * len(df_level1_ekfac)
    df_level2_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl2}", delimiter=",")
    df_level2_ekfac["RF"] = [resnets_rfs[2]] * len(df_level2_ekfac)
    df_level3_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl3}", delimiter=",")
    df_level3_ekfac["RF"] = [resnets_rfs[3]] * len(df_level3_ekfac)
    df_level4_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl4}", delimiter=",")
    df_level4_ekfac["RF"] = [resnets_rfs[4]] * len(df_level4_ekfac)

    all_ekfac = pd.concat([df_level1_ekfac, df_level2_ekfac, df_level3_ekfac, df_level4_ekfac])

    df_level1_sam = pd.read_csv(f"{preamble}{sam_lvl1}", delimiter=",")
    df_level1_sam["RF"] = [resnets_rfs[1]] * len(df_level1_sam)
    df_level2_sam = pd.read_csv(f"{preamble}{sam_lvl2}", delimiter=",")

    df_level2_sam["RF"] = [resnets_rfs[2]] * len(df_level2_sam)
    df_level3_sam = pd.read_csv(f"{preamble}{sam_lvl3}", delimiter=",")
    df_level3_sam["RF"] = [resnets_rfs[3]] * len(df_level3_sam)
    df_level4_sam = pd.read_csv(f"{preamble}{sam_lvl4}", delimiter=",")
    df_level4_sam["RF"] = [resnets_rfs[4]] * len(df_level4_sam)

    all_sam = pd.concat([df_level1_sam, df_level2_sam, df_level3_sam, df_level4_sam])

    df_level1_sgd = pd.read_csv(f"{preamble}{sgd_lvl1}", delimiter=",")
    df_level1_sgd["RF"] = [resnets_rfs[1]] * len(df_level1_sgd)
    df_level2_sgd = pd.read_csv(f"{preamble}{sgd_lvl2}", delimiter=",")
    df_level2_sgd["RF"] = [resnets_rfs[2]] * len(df_level2_sgd)
    df_level3_sgd = pd.read_csv(f"{preamble}{sgd_lvl3}", delimiter=",")
    df_level3_sgd["RF"] = [resnets_rfs[3]] * len(df_level3_sgd)
    df_level4_sgd = pd.read_csv(f"{preamble}{sgd_lvl4}", delimiter=",")
    df_level4_sgd["RF"] = [resnets_rfs[4]] * len(df_level4_sgd)

    all_sgd = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd])
    all_sgd["optimiser"] = ["SGD"] * len(all_sgd)
    all_sam["optimiser"] = ["ASAM"] * len(all_sam)
    all_ekfac["optimiser"] = ["EKFAC"] * len(all_ekfac)
    all_df_out_block = pd.concat([all_ekfac,all_sam,all_sgd])
    """## SGD out_of_block"""

    import seaborn as sns
    import matplotlib.pyplot as plt

    all_df = all_df_out_block[all_df_out_block["optimiser"] == "SGD"]

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            list_of_string = string.slit(" ")
            layer_name = list_of_string[2]
            layer_name = layer_name.split("-")[0]
            # o=string.replace("gmp_Accuracy_pruning_from_","")
            # o=o.replace("-","")
            # o=o.replace("-",".")
            return layer_name

    def trim(string):
        list_of_string = string.split(" ")
        layer_name = list_of_string[2]
        layer_name = layer_name.split("-")[0]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name


    """### RF 110
      
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[1]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}

    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]

    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []

    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1726773378.6547081_rf_level_1_recording_200_no_ffcv.csv",
        delimiter=";")


    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")
    col_names = epoch_df.columns



    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")


    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")

    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")
    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    # ax.set_xticklabels([])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.xaxis.set_major_locator(ticker.MultipleLocator(5))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(3))
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid(ls="--", alpha=0.5)

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_1_sgd_gmp.pdf")

    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[1]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[1]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_1_sgd_random.pdf")
    plt.close()

    mean_df

    """### RF 213
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[2]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1726773352.3026712_rf_level_2_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")
    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")
    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    # ax.set_xticklabels([])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.xaxis.set_major_locator(ticker.MultipleLocator(5))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(3))
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid(ls="--", alpha=0.5)
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_2_sgd_gmp.pdf")
    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[2]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[2]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_2_sgd_random.pdf")
    plt.close()

    """### RF 318
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[3]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1726248344.7113843_rf_level_3_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")
    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")
    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    # ax.set_xticklabels([])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.xaxis.set_major_locator(ticker.MultipleLocator(5))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(3))
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid(ls="--", alpha=0.5)

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_3_sgd_gmp.pdf")

    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[3]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[3]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_3_sgd_random.pdf")

    plt.close()

    """### RF 423
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[4]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1726248344.4095678_rf_level_4_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")
    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")
    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    # ax.set_xticklabels([])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.xaxis.set_major_locator(ticker.MultipleLocator(5))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(3))
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid(ls="--", alpha=0.5)

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_4_sgd_gmp.pdf")

    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[4]].filter(regex=method)

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[4]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_outblock_rf_4_sgd_random.pdf")
    plt.close()


    """## SGD"""

    import matplotlib.pyplot as plt

    all_df = all_df_in_block[all_df_in_block["optimiser"] == "SGD"]

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            list_of_string = string.slit(" ")
            layer_name = list_of_string[2]
            layer_name = layer_name.split("-")[0]
            # o=string.replace("gmp_Accuracy_pruning_from_","")
            # o=o.replace("-","")
            # o=o.replace("-",".")
            return layer_name

    def trim(string):
        list_of_string = string.split(" ")
        layer_name = list_of_string[2]
        layer_name = layer_name.split("-")[0]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name


    """### RF 110
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[1]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1726773378.6547081_rf_level_1_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))

    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")
    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    # ax.set_xticklabels([])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.xaxis.set_major_locator(ticker.MultipleLocator(10))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)
    plt.grid(ls="--", alpha=0.5)
    # plt.title("RF={}".format(resnets_rfs_values[1]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_1_sgd_gmp.pdf")
    plt.close()
    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[1]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[1]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_1_sgd_random.pdf")

    plt.close()

    mean_df

    """### RF 213
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[2]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1726773352.3026712_rf_level_2_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")
    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.xaxis.set_major_locator(ticker.MultipleLocator(10))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)
    plt.grid(ls="--", alpha=0.5)
    # plt.title("RF={}".format(resnets_rfs_values[2]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_2_sgd_gmp.pdf")
    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[2]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[2]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_2_sgd_random.pdf")

    plt.close()

    """### RF 318
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[3]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1726248344.7113843_rf_level_3_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")
    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    # ax.set_xticklabels([])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.xaxis.set_major_locator(ticker.MultipleLocator(10))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)
    plt.grid(ls="--", alpha=0.5)
    # plt.title("RF={}".format(resnets_rfs_values[3]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_3_sgd_gmp.pdf")
    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[3]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[3]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_3_sgd_random.pdf")
    plt.close()

    """### RF 423
        
        #### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "GMP"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[4]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1726248344.4095678_rf_level_4_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")
    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    # ax.set_xticklabels([])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.xaxis.set_major_locator(ticker.MultipleLocator(10))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)
    plt.grid(ls="--", alpha=0.5)

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_4_sgd_gmp.pdf")

    plt.close()

    """####  Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    method = "RANDOM"
    mean_df = all_df[all_df["RF"] == resnets_rfs_values[4]].filter(regex=method)

    mean_df1 = mean_df.filter(regex="conv2")
    mean_df2 = mean_df.filter(regex="conv1")
    mean_df = pd.concat([mean_df1, mean_df2], axis=0)
    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        # print(name)
        # print(o)
        t = name.replace(".", "-")
        if t in o:
            tick_index.append(o.index(t))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 55))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * 1.7)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()
    # plt.title("RF={}".format(resnets_rfs_values[4]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_resnet50_inblock_rf_4_sgd_random.pdf")
    plt.close()

def saturation_accuracy_vgg19_plots():
    """"
    # vgg19
    """

    ekfac_lvl1 = "RF_vgg19_1_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_inter_layers_summary.csv"
    sgd_lvl1 = "RF_vgg19_1_cifar10_0.9_recording_200_no_ffcv_one_shot_inter_layers_summary.csv"
    sam_lvl1 = "RF_vgg19_1_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_inter_layers_summary.csv"

    ekfac_lvl2 = "RF_vgg19_2_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_inter_layers_summary.csv"
    sgd_lvl2 = "RF_vgg19_2_cifar10_0.9_recording_200_no_ffcv_one_shot_inter_layers_summary.csv"
    sam_lvl2 = "RF_vgg19_2_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_inter_layers_summary.csv"

    ekfac_lvl3 = "RF_vgg19_3_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_inter_layers_summary.csv"
    sgd_lvl3 = "RF_vgg19_3_cifar10_0.9_recording_200_no_ffcv_one_shot_inter_layers_summary.csv"
    sam_lvl3 = "RF_vgg19_3_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_inter_layers_summary.csv"

    ekfac_lvl4 = "RF_vgg19_4_cifar10_0.9_ekfac_optim_hyper_saturation_200_gc_0_one_shot_inter_layers_summary.csv"
    sgd_lvl4 = "RF_vgg19_4_cifar10_0.9_recording_200_no_ffcv_one_shot_inter_layers_summary.csv"
    sam_lvl4 = "RF_vgg19_4_cifar10_0.9_sam_optim_saturation_200_gc_0_one_shot_inter_layers_summary.csv"

    preamble = "inter_layer_pruning_results/"

    df_level1_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl1}", delimiter=",")
    df_level1_ekfac["RF"] = [vgg_rfs[1]] * len(df_level1_ekfac)
    df_level2_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl2}", delimiter=",")
    df_level2_ekfac["RF"] = [vgg_rfs[2]] * len(df_level2_ekfac)
    df_level3_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl3}", delimiter=",")
    df_level3_ekfac["RF"] = [vgg_rfs[3]] * len(df_level3_ekfac)
    df_level4_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl4}", delimiter=",")
    df_level4_ekfac["RF"] = [vgg_rfs[4]] * len(df_level4_ekfac)

    all_ekfac = pd.concat([df_level1_ekfac, df_level2_ekfac, df_level3_ekfac, df_level4_ekfac])

    df_level1_sam = pd.read_csv(f"{preamble}{sam_lvl1}", delimiter=",")
    df_level1_sam["RF"] = [vgg_rfs[1]] * len(df_level1_sam)
    df_level2_sam = pd.read_csv(f"{preamble}{sam_lvl2}", delimiter=",")

    df_level2_sam["RF"] = [vgg_rfs[2]] * len(df_level2_sam)
    df_level3_sam = pd.read_csv(f"{preamble}{sam_lvl3}", delimiter=",")
    df_level3_sam["RF"] = [vgg_rfs[3]] * len(df_level3_sam)
    df_level4_sam = pd.read_csv(f"{preamble}{sam_lvl4}", delimiter=",")
    df_level4_sam["RF"] = [vgg_rfs[4]] * len(df_level4_sam)

    all_sam = pd.concat([df_level1_sam, df_level2_sam, df_level3_sam, df_level4_sam])

    df_level1_sgd = pd.read_csv(f"{preamble}{sgd_lvl1}", delimiter=",")
    df_level1_sgd["RF"] = [vgg_rfs[1]] * len(df_level1_sgd)
    df_level2_sgd = pd.read_csv(f"{preamble}{sgd_lvl2}", delimiter=",")
    df_level2_sgd["RF"] = [vgg_rfs[2]] * len(df_level2_sgd)
    df_level3_sgd = pd.read_csv(f"{preamble}{sgd_lvl3}", delimiter=",")
    df_level3_sgd["RF"] = [vgg_rfs[3]] * len(df_level3_sgd)
    df_level4_sgd = pd.read_csv(f"{preamble}{sgd_lvl4}", delimiter=",")
    df_level4_sgd["RF"] = [vgg_rfs[4]] * len(df_level4_sgd)

    all_sgd = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd])
    all_sgd["optimiser"] = ["SGD"] * len(all_sgd)
    all_sam["optimiser"] = ["ASAM"] * len(all_sam)
    all_ekfac["optimiser"] = ["EKFAC"] * len(all_ekfac)

    all_df1 = pd.concat([all_ekfac, all_sam, all_sgd])

    """# TODO: SGD"""

    import seaborn as sns
    import matplotlib.pyplot as plt

    all_df = all_df1[all_df1["optimiser"] == "SGD"]

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            list_of_string = string.slit("_")
            layer_name = list_of_string[4]
            # o=string.replace("gmp_Accuracy_pruning_from_","")
            # o=o.replace("-","")
            # o=o.replace("-",".")
            return layer_name

    """## RF 131

    ### GMP
    """

    from delve.writers import plot_stat_level_from_results, plot_stat
    mean_df = all_df[all_df["RF"] == vgg_rfs[1]].filter(regex="gmp")

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:

        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")
    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")
    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    # ax.set_xticklabels([])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid(ls="--", alpha=0.5)
    # plt.title("RF={}".format(vgg_rfs[1]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_1_sgd_gmp.pdf")
    plt.close()

    """### Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    mean_df = all_df[all_df["RF"] == vgg_rfs[1]].filter(regex="random")

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy")
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)

    ax2.tick_params(axis='y', labelsize=fs * 1.7, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * 1.7, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * labels_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid()

    # plt.title("{}".format(vgg_rfs[1]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_1_sgd_random.pdf")
    plt.close()

    """## RF 315
        
        ### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 2
    method = "gmp"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726773380.2706754_rf_level_2_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")
    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    # ax.set_xticklabels([])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid(ls="--", alpha=0.5)
    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_2_sgd_gmp.pdf")
    plt.close()

    """### Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 2
    method = "random"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726773380.2706754_rf_level_2_recording_200_no_ffcv.csv",
        delimiter=";")
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # #plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)
    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid(ls="--", alpha=0.5)

    # plt.title("RF={}".format(vgg_rfs[level]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_2_sgd_random.pdf")
    plt.close()

    from delve.writers import plot_stat_level_from_results

    plot_stat_level_from_results(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1725640015.7435527_rf_level_4_recording_200_no_ffcv.csv",
        199, "lsat", stat_mode="train")
    plt.close()

    """## RF 537
        
        ### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 3
    method = "gmp"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1725639932.8630962_rf_level_3_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")
    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    # ax.set_xticklabels([])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid(ls="--", alpha=0.5)

    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)
    # plt.title("RF={}".format(vgg_rfs[level]))
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_3_sgd_gmp.pdf")

    plt.close()

    """### Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 3
    method = "random"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1725640015.7435527_rf_level_4_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)
    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid(ls="--", alpha=0.5)

    # plt.title("RF={}".format(vgg_rfs[level]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_3_sgd_random.pdf")

    plt.close()

    """## RF 715
        
        ### GMP
        """

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 4
    method = "gmp"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1725640015.7435527_rf_level_4_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    raw = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].dropna().mean())
        stds.append(layer_df["Accuracy"].dropna().std())
        raw.append(layer_df["Accuracy"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()
    tick_index.reverse()
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(tick_index)), y=means, yerr=stds, ecolor="red", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    # plot_saturation(epoch_df=epoch_df, ax=ax2,index_to_keep=tick_index)
    # ax2.errorbar(x=range(len(tick_index)),y=means,yerr=stds,ecolor="red",marker='o', mfc='red',capsize=2,markeredgewidth=1,markeredgecolor="k",ls="none")
    ax2.scatter(x=range(len(tick_index)), y=epoch_df.values[0][tick_index], color="blue", marker="o", s=100)

    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    # ax.set_xticklabels(range(1, 55))
    ax.set_xticks(range(len(tick_index)), tick_index)
    # ax.set_xticklabels([])
    # ax.xaxis.set_major_locator(ticker.AutoLocator())
    # ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    # ax2.xaxis.set_major_locator(ticker.MultipleLocator(15))
    # ax2.xaxis.set_minor_locator(ticker.MultipleLocator(5))
    ax.set_yticks(list(range(0, 110, 10)), list(range(0, 110, 10)))
    ax2.set_yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid(ls="--", alpha=0.5)
    # plt.title("RF={}".format(vgg_rfs[level]))

    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_4_sgd_gmp.pdf")

    plt.close()

    """### Random"""

    from delve.writers import plot_stat_level_from_results, plot_stat

    level = 3
    method = "random"
    mean_df = all_df[all_df["RF"] == vgg_rfs[level]].filter(regex=method)

    # sns.barplot(data=mean_df,x="gmp",)
    # plt.gca().invert_xaxis()
    plt.close()
    # mean_df.plot.bar(x="gmp")
    # plt.gca().invert_xaxis()
    plt.close()

    # def change_and_sort_names(df):
    #   names=list(df["name"])
    #   sorted_index = []

    def trim(string):
        list_of_string = string.split("_")
        layer_name = list_of_string[4]
        # o=string.replace("gmp_Accuracy_pruning_from_","")
        # o=o.replace("-","")
        # o=o.replace("-",".")
        return layer_name.replace(".", "-")

    columns_names = list(mean_df.columns)
    new_names = list(map(trim, columns_names))
    dict_names = {}
    for i in range(len(new_names)):
        dict_names[columns_names[i]] = new_names[i]
    mean_df.rename(columns=dict_names, inplace=True)
    new_dict = {}
    accuracies_list = []
    names_list = []
    for name in mean_df.columns:
        accuracies = list(mean_df[name])
        accuracies_list.extend(accuracies)
        names_list.extend([name] * len(accuracies))

    new_df = pd.DataFrame({"Accuracy": accuracies_list, "Pruned layer": names_list})

    # new_df["Accuracy"] = new_df["Accuracy"]/100

    saturation_df = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1725639932.8630962_rf_level_3_recording_200_no_ffcv.csv",
        delimiter=";")

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    epoch_df, pm = extract_layer_stat(saturation_df,
                                      epoch=199,
                                      primary_metric=None,
                                      stat='saturation',
                                      state_mode="train")

    col_names = epoch_df.columns

    tick_index = []
    layer_names = list(new_df["Pruned layer"].unique())
    o = [col_name.split('_', )[1] for col_name in col_names]

    for name in layer_names:
        name = name.replace(".", "-")
        if name in o:
            tick_index.append(o.index(name))
    means = []
    stds = []
    for layer in new_df["Pruned layer"].unique():
        layer_df = new_df[new_df["Pruned layer"] == layer]
        means.append(layer_df["Accuracy"].mean())
        stds.append(layer_df["Accuracy"].std())

    ax.bar(x=tick_index, height=means, yerr=stds, color="red")
    ax.set_ylabel("Accuracy", fontsize=fs * labels_multiplier)
    # ax = plot_stat(saturation_df,"lstat",epoch=-1,save=False)
    # ax2=ax1.twinx()
    # sns.barplot(ax=axs[1],data=new_df,x="Pruned layer",y="Accuracy")
    # plt.xticks(rotation=90)
    # plt.gca().invert_xaxis()

    ax2 = ax.twinx()

    plot_saturation(epoch_df=epoch_df, ax=ax2)
    ax2.set_ylabel("Saturation", fontsize=fs * labels_multiplier)
    ax2.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="blue")
    ax.tick_params(axis='y', labelsize=fs * ticks_multiplier, colors="red")

    # ax2.tick_params(axis='x',labelsize=fs*1.7)
    ax.set_xticklabels(range(1, 18))
    # ax.set_xticklabels([])
    ax.xaxis.set_major_locator(ticker.AutoLocator())
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.tick_params(axis='x', labelsize=fs * ticks_multiplier)
    ax2.yaxis.label.set_color('blue')  # setting up X-axis label color to yellow
    ax.yaxis.label.set_color('red')

    plt.grid(ls="--", alpha=0.5)
    # plt.title("RF={}".format(vgg_rfs[level]))

    # plt.title("RF={}".format(vgg_rfs[level]))

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/sat_pruning_vgg19_rf_4_sgd_random.pdf")

    plt.close()

def probes_accuracy():
    accuracy_ticks =range(0,110,10)
    """# TODO: Probes accuracy
    ## VGG X cifar10
    """

    vgg_rfs = [180, 181, 359, 537, 715]
    all_layers_vgg19 = ["features.0", "features.4", "features.8", "features.11", "features.15", "features.18",
                        "features.21",
                        "features.24", "features.28", "features.31", "features.34", "features.37", "features.40",
                        "features.43", "features.46", "features.49", "classifier"]

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            o = string.replace("train-", "")
            o = o.replace("-", ".")
            return o

        new_names = list(map(trim, names))

        for name in new_names:
            sorted_index.append(all_layers_vgg19.index(name))
        df["depth"] = sorted_index
        df["name"] = new_names
        df.sort_values(by="depth", inplace=True)

    l1 = pd.read_csv("probes_logs/vgg19_cifar10_32_1/probe_performances.csv", delimiter=";")
    l1["RF"] = [vgg_rfs[1]] * len(l1)
    l2 = pd.read_csv("probes_logs/vgg19_cifar10_32_2/probe_performances.csv", delimiter=";")
    l2["RF"] = [vgg_rfs[2]] * len(l2)
    l3 = pd.read_csv("probes_logs/vgg19_cifar10_32_3/probe_performances.csv", delimiter=";")
    l3["RF"] = [vgg_rfs[3]] * len(l3)
    l4 = pd.read_csv("probes_logs/vgg19_cifar10_32_4/probe_performances.csv", delimiter=";")
    l4["RF"] = [vgg_rfs[4]] * len(l4)

    change_and_sort_names(l1)
    change_and_sort_names(l2)
    change_and_sort_names(l3)
    change_and_sort_names(l4)

    l = pd.concat([l1, l2, l3, l4])
    l["eval_acc"] = l["eval_acc"] * 100
    # l.sort_values(by="depth",inplace=True)

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    unique_RF = l["RF"].unique()
    num_colors = len(unique_RF)
    cm = mpl.cm.get_cmap(name='magma')
    currentColors = [cm(1. * i / num_colors) for i in range(num_colors)]

    for i, color in enumerate(currentColors):
        current_df = l[l["RF"] == unique_RF[i]]
        axs.plot(current_df["name"], current_df["eval_acc"], color=currentColors[i], label=f"{unique_RF[i]}")

    axs.set_xlabel("Layer", size=fs * labels_multiplier)
    axs.set_ylabel("Accuracy", size=fs * labels_multiplier)
    axs.set_xticks(range(1, 17))
    axs.set_xticklabels(range(1, 17))

    axs.set_yticks(accuracy_ticks)
    axs.set_yticklabels(accuracy_ticks)

    # ax.set_xticklabels([])
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelsize=fs * ticks_multiplier)
    axs.xaxis.set_major_locator(ticker.MultipleLocator(2))
    axs.xaxis.set_minor_locator(ticker.MultipleLocator(1))
    # plt.xticks(rotation=90
    axs.legend(prop={"size": fs * legends_multiplier})

    plt.grid(ls="--")
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/probe_accuracy_vgg_cifar_32.pdf")
    # plt.xticks(rotation=45)
    plt.close()

    """## ResNet50 X Cifar10"""

    all_layers_resnet50 = ["conv1", "layer1.0.conv1", "layer1.0.conv2", "layer1.0.conv3", "layer1.0.shortcut.0",
                           "layer1.1.conv1", "layer1.1.conv2", "layer1.1.conv3", "layer1.2.conv1", "layer1.2.conv2",
                           "layer1.2.conv3", "layer2.0.conv1", "layer2.0.conv2", "layer2.0.conv3",
                           "layer2.0.shortcut.0", "layer2.1.conv1", "layer2.1.conv2", "layer2.1.conv3",
                           "layer2.2.conv1", "layer2.2.conv2", "layer2.2.conv3", "layer2.3.conv1", "layer2.3.conv2",
                           "layer2.3.conv3", "layer3.0.conv1", "layer3.0.conv2", "layer3.0.conv3",
                           "layer3.0.shortcut.0", "layer3.1.conv1", "layer3.1.conv2", "layer3.1.conv3",
                           "layer3.2.conv1", "layer3.2.conv2", "layer3.2.conv3", "layer3.3.conv1", "layer3.3.conv2",
                           "layer3.3.conv3", "layer3.4.conv1", "layer3.4.conv2", "layer3.4.conv3", "layer3.5.conv1",
                           "layer3.5.conv2", "layer3.5.conv3", "layer4.0.conv1", "layer4.0.conv2", "layer4.0.conv3",
                           "layer4.0.shortcut.0", "layer4.1.conv1", "layer4.1.conv2", "layer4.1.conv3",
                           "layer4.2.conv1", "layer4.2.conv2", "layer4.2.conv3", "linear"]

    resnets_rfs_values = [108, 110, 213, 318, 423, 538, 645, 752, 859, 1415, 1920, 3100]

    resnet_rfs_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]

    resnets_rfs = dict(zip(resnet_rfs_keys, resnets_rfs_values))

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            o = string.replace("train-", "")
            o = o.replace("-", ".")
            return o

        new_names = list(map(trim, names))

        for name in new_names:
            sorted_index.append(all_layers_resnet50.index(name))
        df["depth"] = sorted_index
        df["name"] = new_names
        df.sort_values(by="depth", inplace=True)

    l1 = pd.read_csv("probes_logs/resnet50_cifar10_32_1/probe_performances.csv", delimiter=";")
    l1["RF"] = [resnets_rfs[1]] * len(l1)
    l2 = pd.read_csv("probes_logs/resnet50_cifar10_32_2/probe_performances.csv", delimiter=";")
    l2["RF"] = [resnets_rfs[2]] * len(l2)
    l3 = pd.read_csv("probes_logs/resnet50_cifar10_32_3/probe_performances.csv", delimiter=";")
    l3["RF"] = [resnets_rfs[3]] * len(l3)
    l4 = pd.read_csv("probes_logs/resnet50_cifar10_32_4/probe_performances.csv", delimiter=";")
    l4["RF"] = [resnets_rfs[4]] * len(l4)

    l9 = pd.read_csv("probes_logs/resnet50_cifar10_32_9/probe_performances.csv", delimiter=";")
    l9["RF"] = [resnets_rfs[9]] * len(l9)

    l10 = pd.read_csv("probes_logs/resnet50_cifar10_32_10/probe_performances.csv", delimiter=";")
    l10["RF"] = [resnets_rfs[10]] * len(l10)
    l11 = pd.read_csv("probes_logs/resnet50_cifar10_32_11/probe_performances.csv", delimiter=";")
    l11["RF"] = [resnets_rfs[11]] * len(l11)

    change_and_sort_names(l1)
    change_and_sort_names(l2)
    change_and_sort_names(l3)
    change_and_sort_names(l4)
    change_and_sort_names(l9)
    change_and_sort_names(l10)
    change_and_sort_names(l11)

    # l=pd.concat([l1,l2,l3,l4,l9,l10,l11])
    l = pd.concat([l1, l2, l3, l4])
    l["eval_acc"] = l["eval_acc"] * 100
    # l=pd.concat([l9,l10,l11])
    # l.sort_values(by="depth",inplace=True)

    fig, axs = plt.subplots(figsize=fig_size, layout="compressed")

    unique_RF = l["RF"].unique()
    num_colors = len(unique_RF)
    cm = mpl.cm.get_cmap(name='magma')
    currentColors = [cm(1. * i / num_colors) for i in range(num_colors)]

    for i, color in enumerate(currentColors):
        current_df = l[l["RF"] == unique_RF[i]]
        axs.plot(current_df["name"], current_df["eval_acc"], color=currentColors[i], label=f"{unique_RF[i]}")

    axs.set_xlabel("Layer", size=fs * labels_multiplier)
    axs.set_ylabel("Accuracy", size=fs * labels_multiplier)

    axs.set_xticks(range(1, 54))
    axs.set_xticklabels(range(1, 54))
    axs.set_yticks(accuracy_ticks)
    axs.set_yticklabels(accuracy_ticks)
    axs.tick_params(axis='y', which='major', labelsize=fs * ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelsize=fs * ticks_multiplier)
    axs.legend(prop={"size": fs * legends_multiplier})
    axs.xaxis.set_major_locator(ticker.MultipleLocator(5))
    axs.xaxis.set_minor_locator(ticker.MultipleLocator(1))
    # #plt.xticks(rotation=90)
    plt.grid(ls="--")
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/probe_accuracy_resnet50_cifar_32_low_levels.pdf")

    plt.close()

    """## Smooth version"""

    def smooth_function(array):
        max = 0
        new_array = []
        for value in array:
            if value > max:
                max = value
            new_array.append(max)
        return new_array

    all_layers_resnet50 = ["conv1", "layer1.0.conv1", "layer1.0.conv2", "layer1.0.conv3", "layer1.0.shortcut.0",
                           "layer1.1.conv1", "layer1.1.conv2", "layer1.1.conv3", "layer1.2.conv1", "layer1.2.conv2",
                           "layer1.2.conv3", "layer2.0.conv1", "layer2.0.conv2", "layer2.0.conv3",
                           "layer2.0.shortcut.0", "layer2.1.conv1", "layer2.1.conv2", "layer2.1.conv3",
                           "layer2.2.conv1", "layer2.2.conv2", "layer2.2.conv3", "layer2.3.conv1", "layer2.3.conv2",
                           "layer2.3.conv3", "layer3.0.conv1", "layer3.0.conv2", "layer3.0.conv3",
                           "layer3.0.shortcut.0", "layer3.1.conv1", "layer3.1.conv2", "layer3.1.conv3",
                           "layer3.2.conv1", "layer3.2.conv2", "layer3.2.conv3", "layer3.3.conv1", "layer3.3.conv2",
                           "layer3.3.conv3", "layer3.4.conv1", "layer3.4.conv2", "layer3.4.conv3", "layer3.5.conv1",
                           "layer3.5.conv2", "layer3.5.conv3", "layer4.0.conv1", "layer4.0.conv2", "layer4.0.conv3",
                           "layer4.0.shortcut.0", "layer4.1.conv1", "layer4.1.conv2", "layer4.1.conv3",
                           "layer4.2.conv1", "layer4.2.conv2", "layer4.2.conv3", "linear"]

    resnets_rfs_values = [108, 110, 213, 318, 423, 538, 645, 752, 859, 1415, 1920, 3100]

    resnet_rfs_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]

    resnets_rfs = dict(zip(resnet_rfs_keys, resnets_rfs_values))

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            o = string.replace("train-", "")
            o = o.replace("-", ".")
            return o

        new_names = list(map(trim, names))

        for name in new_names:
            sorted_index.append(all_layers_resnet50.index(name))
        df["depth"] = sorted_index
        df["name"] = new_names
        df.sort_values(by="depth", inplace=True)

    l1 = pd.read_csv("probes_logs/resnet50_cifar10_32_1/probe_performances.csv", delimiter=";")
    l1["smooth_eval_acc"] = smooth_function(list(l1["eval_acc"]))
    l1["RF"] = [resnets_rfs[1]] * len(l1)
    l2 = pd.read_csv("probes_logs/resnet50_cifar10_32_2/probe_performances.csv", delimiter=";")
    l2["smooth_eval_acc"] = smooth_function(list(l2["eval_acc"]))
    l2["RF"] = [resnets_rfs[2]] * len(l2)
    l3 = pd.read_csv("probes_logs/resnet50_cifar10_32_3/probe_performances.csv", delimiter=";")
    l3["smooth_eval_acc"] = smooth_function(list(l3["eval_acc"]))
    l3["RF"] = [resnets_rfs[3]] * len(l3)
    l4 = pd.read_csv("probes_logs/resnet50_cifar10_32_4/probe_performances.csv", delimiter=";")
    l4["smooth_eval_acc"] = smooth_function(list(l4["eval_acc"]))
    l4["RF"] = [resnets_rfs[4]] * len(l4)

    l9 = pd.read_csv("probes_logs/resnet50_cifar10_32_9/probe_performances.csv", delimiter=";")
    l9["smooth_eval_acc"] = smooth_function(list(l9["eval_acc"]))
    l9["RF"] = [resnets_rfs[9]] * len(l9)

    l10 = pd.read_csv("probes_logs/resnet50_cifar10_32_10/probe_performances.csv", delimiter=";")
    l10["smooth_eval_acc"] = smooth_function(list(l10["eval_acc"]))
    l10["RF"] = [resnets_rfs[10]] * len(l10)
    l11 = pd.read_csv("probes_logs/resnet50_cifar10_32_11/probe_performances.csv", delimiter=";")
    l11["RF"] = [resnets_rfs[11]] * len(l11)
    l11["smooth_eval_acc"] = smooth_function(list(l11["eval_acc"]))

    change_and_sort_names(l1)
    change_and_sort_names(l2)
    change_and_sort_names(l3)
    change_and_sort_names(l4)
    change_and_sort_names(l9)
    change_and_sort_names(l10)
    change_and_sort_names(l11)

    # l=pd.concat([l1,l2,l3,l4,l9,l10,l11])
    l = pd.concat([l1, l2, l3, l4])
    l["eval_acc"] = l["eval_acc"] * 100
    l["smooth_eval_acc"] = l["smooth_eval_acc"] * 100
    # l=pd.concat([l9,l10,l11])
    # l.sort_values(by="depth",inplace=True)

    fig, axs = plt.subplots(figsize=fig_size, layout="compressed")

    axs.set_xlabel("Layer", size=fs * labels_multiplier)
    axs.set_ylabel("Accuracy", size=fs * labels_multiplier)
    unique_RF = l["RF"].unique()
    num_colors = len(unique_RF)
    cm = mpl.cm.get_cmap(name='magma')
    currentColors = [cm(1. * i / num_colors) for i in range(num_colors)]

    for i, color in enumerate(currentColors):
        current_df = l[l["RF"] == unique_RF[i]]
        axs.plot(current_df["name"], current_df["smooth_eval_acc"], color=currentColors[i], label=f"{unique_RF[i]}")

    axs.set_xticks(range(1, 54))
    axs.set_xticklabels(range(1, 54))
    axs.set_yticks(accuracy_ticks)
    axs.set_yticklabels(accuracy_ticks)
    axs.xaxis.set_major_locator(ticker.AutoLocator())
    axs.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    axs.tick_params(axis='y', which='major', labelsize=fs * ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelsize=fs * ticks_multiplier)
    axs.legend(prop={"size": fs * legends_multiplier})
    axs.xaxis.set_major_locator(ticker.MultipleLocator(5))
    axs.xaxis.set_minor_locator(ticker.MultipleLocator(1))
    # #plt.xticks(rotation=90)
    plt.grid(ls="--")
    plt.savefig(
        "/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/probe_accuracy_resnet50_cifar_32_low_levels_smooth.pdf")

    plt.close()

    all_layers_resnet50 = ["conv1", "layer1.0.conv1", "layer1.0.conv2", "layer1.0.conv3", "layer1.0.shortcut.0",
                           "layer1.1.conv1", "layer1.1.conv2", "layer1.1.conv3", "layer1.2.conv1", "layer1.2.conv2",
                           "layer1.2.conv3", "layer2.0.conv1", "layer2.0.conv2", "layer2.0.conv3",
                           "layer2.0.shortcut.0", "layer2.1.conv1", "layer2.1.conv2", "layer2.1.conv3",
                           "layer2.2.conv1", "layer2.2.conv2", "layer2.2.conv3", "layer2.3.conv1", "layer2.3.conv2",
                           "layer2.3.conv3", "layer3.0.conv1", "layer3.0.conv2", "layer3.0.conv3",
                           "layer3.0.shortcut.0", "layer3.1.conv1", "layer3.1.conv2", "layer3.1.conv3",
                           "layer3.2.conv1", "layer3.2.conv2", "layer3.2.conv3", "layer3.3.conv1", "layer3.3.conv2",
                           "layer3.3.conv3", "layer3.4.conv1", "layer3.4.conv2", "layer3.4.conv3", "layer3.5.conv1",
                           "layer3.5.conv2", "layer3.5.conv3", "layer4.0.conv1", "layer4.0.conv2", "layer4.0.conv3",
                           "layer4.0.shortcut.0", "layer4.1.conv1", "layer4.1.conv2", "layer4.1.conv3",
                           "layer4.2.conv1", "layer4.2.conv2", "layer4.2.conv3", "linear"]

    resnets_rfs_values = [108, 110, 213, 318, 423, 538, 645, 752, 859, 1415, 1920, 3100]

    resnet_rfs_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]

    resnets_rfs = dict(zip(resnet_rfs_keys, resnets_rfs_values))

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            o = string.replace("train-", "")
            o = o.replace("-", ".")
            return o

        new_names = list(map(trim, names))

        for name in new_names:
            sorted_index.append(all_layers_resnet50.index(name))
        df["depth"] = sorted_index
        df["name"] = new_names
        df.sort_values(by="depth", inplace=True)

    l1 = pd.read_csv("probes_logs/resnet50_cifar10_32_1/probe_performances.csv", delimiter=";")
    l1["RF"] = [resnets_rfs[1]] * len(l1)
    l2 = pd.read_csv("probes_logs/resnet50_cifar10_32_2/probe_performances.csv", delimiter=";")
    l2["RF"] = [resnets_rfs[2]] * len(l2)
    l3 = pd.read_csv("probes_logs/resnet50_cifar10_32_3/probe_performances.csv", delimiter=";")
    l3["RF"] = [resnets_rfs[3]] * len(l3)
    l4 = pd.read_csv("probes_logs/resnet50_cifar10_32_4/probe_performances.csv", delimiter=";")
    l4["RF"] = [resnets_rfs[4]] * len(l4)

    l9 = pd.read_csv("probes_logs/resnet50_cifar10_32_9/probe_performances.csv", delimiter=";")
    l9["RF"] = [resnets_rfs[9]] * len(l9)

    l10 = pd.read_csv("probes_logs/resnet50_cifar10_32_10/probe_performances.csv", delimiter=";")
    l10["RF"] = [resnets_rfs[10]] * len(l10)
    l11 = pd.read_csv("probes_logs/resnet50_cifar10_32_11/probe_performances.csv", delimiter=";")
    l11["RF"] = [resnets_rfs[11]] * len(l11)

    change_and_sort_names(l1)
    change_and_sort_names(l2)
    change_and_sort_names(l3)
    change_and_sort_names(l4)
    change_and_sort_names(l9)
    change_and_sort_names(l10)
    change_and_sort_names(l11)

    # l=pd.concat([l1,l2,l3,l4,l9,l10,l11])
    # l=pd.concat([l1,l2,l3,l4])
    l = pd.concat([l9, l10, l11])
    l["eval_acc"] = l["eval_acc"] * 100
    # l.sort_values(by="depth",inplace=True)

    fig, axs = plt.subplots(figsize=fig_size, layout="compressed")

    unique_RF = l["RF"].unique()
    num_colors = len(unique_RF)
    cm = mpl.cm.get_cmap(name='magma')
    currentColors = [cm(1. * i / num_colors) for i in range(num_colors)]

    for i, color in enumerate(currentColors):
        current_df = l[l["RF"] == unique_RF[i]]
        axs.plot(current_df["name"], current_df["eval_acc"], color=currentColors[i], label=f"{unique_RF[i]}")

    axs.set_xlabel("Layer", size=fs * labels_multiplier)
    axs.set_ylabel("Accuracy", size=fs * labels_multiplier)

    axs.set_xticks(range(1, 54))
    axs.set_xticklabels(range(1, 54))
    axs.set_yticks(accuracy_ticks)
    axs.set_yticklabels(accuracy_ticks)
    axs.xaxis.set_major_locator(ticker.AutoLocator())
    axs.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    axs.tick_params(axis='y', which='major', labelsize=fs * ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelsize=fs * ticks_multiplier)
    axs.legend(prop={"size": fs * legends_multiplier})
    axs.xaxis.set_major_locator(ticker.MultipleLocator(5))
    axs.xaxis.set_minor_locator(ticker.MultipleLocator(1))
    # #plt.xticks(rotation=90)
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/probe_accuracy_resnet50_cifar_32_high_levels.pdf")

    plt.close()

    """### Smooth version"""

    def smooth_function(array):
        max = 0
        new_array = []
        for value in array:
            if value > max:
                max = value
            new_array.append(max)
        return new_array

    all_layers_resnet50 = ["conv1", "layer1.0.conv1", "layer1.0.conv2", "layer1.0.conv3", "layer1.0.shortcut.0",
                           "layer1.1.conv1", "layer1.1.conv2", "layer1.1.conv3", "layer1.2.conv1", "layer1.2.conv2",
                           "layer1.2.conv3", "layer2.0.conv1", "layer2.0.conv2", "layer2.0.conv3",
                           "layer2.0.shortcut.0", "layer2.1.conv1", "layer2.1.conv2", "layer2.1.conv3",
                           "layer2.2.conv1", "layer2.2.conv2", "layer2.2.conv3", "layer2.3.conv1", "layer2.3.conv2",
                           "layer2.3.conv3", "layer3.0.conv1", "layer3.0.conv2", "layer3.0.conv3",
                           "layer3.0.shortcut.0", "layer3.1.conv1", "layer3.1.conv2", "layer3.1.conv3",
                           "layer3.2.conv1", "layer3.2.conv2", "layer3.2.conv3", "layer3.3.conv1", "layer3.3.conv2",
                           "layer3.3.conv3", "layer3.4.conv1", "layer3.4.conv2", "layer3.4.conv3", "layer3.5.conv1",
                           "layer3.5.conv2", "layer3.5.conv3", "layer4.0.conv1", "layer4.0.conv2", "layer4.0.conv3",
                           "layer4.0.shortcut.0", "layer4.1.conv1", "layer4.1.conv2", "layer4.1.conv3",
                           "layer4.2.conv1", "layer4.2.conv2", "layer4.2.conv3", "linear"]

    resnets_rfs_values = [108, 110, 213, 318, 423, 538, 645, 752, 859, 1415, 1920, 3100]

    resnet_rfs_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]

    resnets_rfs = dict(zip(resnet_rfs_keys, resnets_rfs_values))

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            o = string.replace("train-", "")
            o = o.replace("-", ".")
            return o

        new_names = list(map(trim, names))

        for name in new_names:
            sorted_index.append(all_layers_resnet50.index(name))
        df["depth"] = sorted_index
        df["name"] = new_names
        df.sort_values(by="depth", inplace=True)

    l1 = pd.read_csv("probes_logs/resnet50_cifar10_32_1/probe_performances.csv", delimiter=";")
    l1["smooth_eval_acc"] = smooth_function(list(l1["eval_acc"]))
    l1["RF"] = [resnets_rfs[1]] * len(l1)
    l2 = pd.read_csv("probes_logs/resnet50_cifar10_32_2/probe_performances.csv", delimiter=";")
    l2["smooth_eval_acc"] = smooth_function(list(l2["eval_acc"]))
    l2["RF"] = [resnets_rfs[2]] * len(l2)
    l3 = pd.read_csv("probes_logs/resnet50_cifar10_32_3/probe_performances.csv", delimiter=";")
    l3["smooth_eval_acc"] = smooth_function(list(l3["eval_acc"]))
    l3["RF"] = [resnets_rfs[3]] * len(l3)
    l4 = pd.read_csv("probes_logs/resnet50_cifar10_32_4/probe_performances.csv", delimiter=";")
    l4["smooth_eval_acc"] = smooth_function(list(l4["eval_acc"]))
    l4["RF"] = [resnets_rfs[4]] * len(l4)

    l9 = pd.read_csv("probes_logs/resnet50_cifar10_32_9/probe_performances.csv", delimiter=";")
    l9["smooth_eval_acc"] = smooth_function(list(l9["eval_acc"]))
    l9["RF"] = [resnets_rfs[9]] * len(l9)

    l10 = pd.read_csv("probes_logs/resnet50_cifar10_32_10/probe_performances.csv", delimiter=";")
    l10["smooth_eval_acc"] = smooth_function(list(l10["eval_acc"]))
    l10["RF"] = [resnets_rfs[10]] * len(l10)
    l11 = pd.read_csv("probes_logs/resnet50_cifar10_32_11/probe_performances.csv", delimiter=";")
    l11["RF"] = [resnets_rfs[11]] * len(l11)
    l11["smooth_eval_acc"] = smooth_function(list(l11["eval_acc"]))

    change_and_sort_names(l1)
    change_and_sort_names(l2)
    change_and_sort_names(l3)
    change_and_sort_names(l4)
    change_and_sort_names(l9)
    change_and_sort_names(l10)
    change_and_sort_names(l11)

    # l=pd.concat([l1,l2,l3,l4,l9,l10,l11])
    # l=pd.concat([l1,l2,l3,l4])
    l = pd.concat([l9, l10, l11])
    l["eval_acc"] = l["eval_acc"] * 100
    l["smooth_eval_acc"] = l["smooth_eval_acc"] * 100
    # l.sort_values(by="depth",inplace=True)

    fig, axs = plt.subplots(figsize=fig_size, layout="compressed")

    unique_RF = l["RF"].unique()
    num_colors = len(unique_RF)
    cm = mpl.cm.get_cmap(name='magma')
    currentColors = [cm(1. * i / num_colors) for i in range(num_colors)]

    for i, color in enumerate(currentColors):
        current_df = l[l["RF"] == unique_RF[i]]
        axs.plot(current_df["name"], current_df["smooth_eval_acc"], color=currentColors[i], label=f"{unique_RF[i]}")

    axs.set_xlabel("Layer", size=fs * labels_multiplier)
    axs.set_ylabel("Accuracy", size=fs * labels_multiplier)

    axs.set_xticks(range(1, 54))
    axs.set_xticklabels(range(1, 54))
    axs.set_yticks(accuracy_ticks)
    axs.set_yticklabels(accuracy_ticks)
    axs.xaxis.set_major_locator(ticker.AutoLocator())
    axs.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    axs.tick_params(axis='y', which='major', labelsize=fs * ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelsize=fs * ticks_multiplier)
    axs.legend(prop={"size": fs * legends_multiplier})
    axs.xaxis.set_major_locator(ticker.MultipleLocator(5))
    axs.xaxis.set_minor_locator(ticker.MultipleLocator(1))
    # #plt.xticks(rotation=90)
    plt.grid(ls="--")
    plt.savefig(
        "/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/probe_accuracy_resnet50_cifar_32_high_levels_smooth.pdf")

    plt.close()

    """## ResNet25 x Small imagenet"""

    # all_layers_resnet50 = ["conv1","layer1.0.conv1", "layer1.0.conv2", "layer1.0.conv3", "layer1.0.shortcut.0",
    #                                "layer1.1.conv1", "layer1.1.conv2", "layer1.1.conv3", "layer1.2.conv1", "layer1.2.conv2",
    #                                "layer1.2.conv3", "layer2.0.conv1", "layer2.0.conv2", "layer2.0.conv3",
    #                                "layer2.0.shortcut.0", "layer2.1.conv1", "layer2.1.conv2", "layer2.1.conv3",
    #                                "layer2.2.conv1", "layer2.2.conv2", "layer2.2.conv3", "layer2.3.conv1", "layer2.3.conv2",
    #                                "layer2.3.conv3", "layer3.0.conv1", "layer3.0.conv2", "layer3.0.conv3",
    #                                "layer3.0.shortcut.0", "layer3.1.conv1", "layer3.1.conv2", "layer3.1.conv3",
    #                                "layer3.2.conv1", "layer3.2.conv2", "layer3.2.conv3", "layer3.3.conv1", "layer3.3.conv2",
    #                                "layer3.3.conv3", "layer3.4.conv1", "layer3.4.conv2", "layer3.4.conv3", "layer3.5.conv1",
    #                                "layer3.5.conv2", "layer3.5.conv3", "layer4.0.conv1", "layer4.0.conv2", "layer4.0.conv3",
    #                                "layer4.0.shortcut.0", "layer4.1.conv1", "layer4.1.conv2", "layer4.1.conv3",
    #                                "layer4.2.conv1", "layer4.2.conv2", "layer4.2.conv3","linear"]
    all_layers_resnet25_dict = {"0": "conv1", "1": "layer1.0.conv1_1x1", "2": "layer1.0.conv2_1x1",
                                "3": "layer1.0.conv3_3x3", "4": "layer1.0.conv4_1x1",
                                "5": "layer1.0.conv5_1x1", "6": "layer1.0.shortcut.0", "7": "layer2.0.conv1_1x1",
                                "8": "layer2.0.conv2_1x1", "9": "layer2.0.conv3_3x3",
                                "10": "layer2.0.conv4_1x1", "11": "layer2.0.conv5_1x1", "12": "layer2.0.shortcut.0",
                                "13": "layer3.0.conv1_1x1", "14": "layer3.0.conv2_1x1",
                                "15": "layer3.0.conv3_3x3", "16": "layer3.0.conv4_1x1", "17": "layer3.0.conv5_1x1",
                                "18": "layer3.0.shortcut.0", "19": "layer3.1.conv1_1x1",
                                "20": "layer3.1.conv2_1x1", "21": "layer3.1.conv3_3x3", "22": "layer3.1.conv4_1x1",
                                "23": "layer3.1.conv5_1x1", "24": "layer4.0.conv1_1x1",
                                "25": "layer4.0.conv2_1x1", "26": "layer4.0.conv3_3x3", "27": "layer4.0.conv4_1x1",
                                "28": "layer4.0.conv5_1x1", "29": "layer4.0.shortcut.0", "30": "linear"}

    all_layers_resnet25 = list(all_layers_resnet25_dict.values())

    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            o = string.replace("train-", "")
            o = o.replace("-", ".")
            return o

        new_names = list(map(trim, names))

        for name in new_names:
            sorted_index.append(all_layers_resnet25.index(name))
        df["depth"] = sorted_index
        df["name"] = new_names
        df.sort_values(by="depth", inplace=True)

    l5 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_5/probe_performances.csv", delimiter=";")
    l5["RF"] = [resnets_rfs[5]] * len(l5)

    l6 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_6/probe_performances.csv", delimiter=";")
    l6["RF"] = [resnets_rfs[6]] * len(l6)

    l7 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_7/probe_performances.csv", delimiter=";")
    l7["RF"] = [resnets_rfs[7]] * len(l7)

    l8 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_5/probe_performances.csv", delimiter=";")
    l8["RF"] = [resnets_rfs[8]] * len(l8)

    l10 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_10/probe_performances.csv", delimiter=";")
    l10["RF"] = [resnets_rfs[10]] * len(l10)

    l11 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_11/probe_performances.csv", delimiter=";")
    l11["RF"] = [resnets_rfs[11]] * len(l11)
    l12 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_12/probe_performances.csv", delimiter=";")
    l12["RF"] = [resnets_rfs[12]] * len(l12)

    l13 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_12/probe_performances.csv", delimiter=";")
    l13["RF"] = [resnets_rfs[13]] * len(l13)

    change_and_sort_names(l5)
    change_and_sort_names(l6)
    change_and_sort_names(l7)
    change_and_sort_names(l8)
    change_and_sort_names(l10)
    change_and_sort_names(l11)
    change_and_sort_names(l12)
    change_and_sort_names(l13)

    # l=pd.concat([l1,l2,l3,l4,l9,l10,l11])
    # l=pd.concat([l5,l6,l7,l8,l10,l11,l12,l13])
    l = pd.concat([l5, l6, l7, l8, l10])
    l["eval_acc"] = l["eval_acc"] * 100
    # l=pd.concat([l9,l10,l11])
    # l.sort_values(by="depth",inplace=True)

    fig, axs = plt.subplots(figsize=fig_size, layout="compressed")

    unique_RF = l["RF"].unique()
    num_colors = len(unique_RF)
    cm = mpl.cm.get_cmap(name='magma')
    currentColors = [cm(1. * i / num_colors) for i in range(num_colors)]

    for i, color in enumerate(currentColors):
        current_df = l[l["RF"] == unique_RF[i]]
        axs.plot(current_df["name"], current_df["eval_acc"], color=currentColors[i], label=f"{unique_RF[i]}")

    axs.set_xlabel("Layer", size=fs * labels_multiplier)
    axs.set_ylabel("Accuracy", size=fs * labels_multiplier)

    axs.set_xticks(range(1, 30))
    axs.set_xticklabels(range(1, 30))
    axs.set_yticks(accuracy_ticks)
    axs.set_yticklabels(accuracy_ticks)
    axs.xaxis.set_major_locator(ticker.AutoLocator())
    axs.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    axs.tick_params(axis='y', which='major', labelsize=fs * ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelsize=fs * ticks_multiplier)
    axs.legend(prop={"size": fs * legends_multiplier})
    axs.xaxis.set_major_locator(ticker.MultipleLocator(5))
    axs.xaxis.set_minor_locator(ticker.MultipleLocator(1))
    # #plt.xticks(rotation=90)

    plt.grid(ls="--")
    plt.savefig(
        "/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/probe_accuracy_resnet25_small_imagenet_detailed_224_lower_levels.pdf")

    plt.close()

    """### smooth version"""

    def smooth_function(array):
        max = 0
        new_array = []
        for value in array:
            if value > max:
                max = value
            new_array.append(max)
        return new_array

    # all_layers_resnet50 = ["conv1","layer1.0.conv1", "layer1.0.conv2", "layer1.0.conv3", "layer1.0.shortcut.0",
    #                                "layer1.1.conv1", "layer1.1.conv2", "layer1.1.conv3", "layer1.2.conv1", "layer1.2.conv2",
    #                                "layer1.2.conv3", "layer2.0.conv1", "layer2.0.conv2", "layer2.0.conv3",
    #                                "layer2.0.shortcut.0", "layer2.1.conv1", "layer2.1.conv2", "layer2.1.conv3",
    #                                "layer2.2.conv1", "layer2.2.conv2", "layer2.2.conv3", "layer2.3.conv1", "layer2.3.conv2",
    #                                "layer2.3.conv3", "layer3.0.conv1", "layer3.0.conv2", "layer3.0.conv3",
    #                                "layer3.0.shortcut.0", "layer3.1.conv1", "layer3.1.conv2", "layer3.1.conv3",
    #                                "layer3.2.conv1", "layer3.2.conv2", "layer3.2.conv3", "layer3.3.conv1", "layer3.3.conv2",
    #                                "layer3.3.conv3", "layer3.4.conv1", "layer3.4.conv2", "layer3.4.conv3", "layer3.5.conv1",
    #                                "layer3.5.conv2", "layer3.5.conv3", "layer4.0.conv1", "layer4.0.conv2", "layer4.0.conv3",
    #                                "layer4.0.shortcut.0", "layer4.1.conv1", "layer4.1.conv2", "layer4.1.conv3",
    #                                "layer4.2.conv1", "layer4.2.conv2", "layer4.2.conv3","linear"]
    all_layers_resnet25_dict = {"0": "conv1", "1": "layer1.0.conv1_1x1", "2": "layer1.0.conv2_1x1",
                                "3": "layer1.0.conv3_3x3", "4": "layer1.0.conv4_1x1",
                                "5": "layer1.0.conv5_1x1", "6": "layer1.0.shortcut.0", "7": "layer2.0.conv1_1x1",
                                "8": "layer2.0.conv2_1x1", "9": "layer2.0.conv3_3x3",
                                "10": "layer2.0.conv4_1x1", "11": "layer2.0.conv5_1x1", "12": "layer2.0.shortcut.0",
                                "13": "layer3.0.conv1_1x1", "14": "layer3.0.conv2_1x1",
                                "15": "layer3.0.conv3_3x3", "16": "layer3.0.conv4_1x1", "17": "layer3.0.conv5_1x1",
                                "18": "layer3.0.shortcut.0", "19": "layer3.1.conv1_1x1",
                                "20": "layer3.1.conv2_1x1", "21": "layer3.1.conv3_3x3", "22": "layer3.1.conv4_1x1",
                                "23": "layer3.1.conv5_1x1", "24": "layer4.0.conv1_1x1",
                                "25": "layer4.0.conv2_1x1", "26": "layer4.0.conv3_3x3", "27": "layer4.0.conv4_1x1",
                                "28": "layer4.0.conv5_1x1", "29": "layer4.0.shortcut.0", "30": "linear"}

    all_layers_resnet25 = list(all_layers_resnet25_dict.values())

    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            o = string.replace("train-", "")
            o = o.replace("-", ".")
            return o

        new_names = list(map(trim, names))

        for name in new_names:
            sorted_index.append(all_layers_resnet25.index(name))
        df["depth"] = sorted_index
        df["name"] = new_names
        df.sort_values(by="depth", inplace=True)

    l5 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_5/probe_performances.csv", delimiter=";")
    l5["smooth_eval_acc"] = smooth_function(l5["eval_acc"])
    l5["RF"] = [resnets_rfs[5]] * len(l5)

    l6 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_6/probe_performances.csv", delimiter=";")
    l6["smooth_eval_acc"] = smooth_function(l6["eval_acc"])
    l6["RF"] = [resnets_rfs[6]] * len(l6)

    l7 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_7/probe_performances.csv", delimiter=";")
    l7["smooth_eval_acc"] = smooth_function(l7["eval_acc"])
    l7["RF"] = [resnets_rfs[7]] * len(l7)

    l8 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_5/probe_performances.csv", delimiter=";")
    l8["smooth_eval_acc"] = smooth_function(l8["eval_acc"])
    l8["RF"] = [resnets_rfs[8]] * len(l8)

    l10 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_10/probe_performances.csv", delimiter=";")
    l10["smooth_eval_acc"] = smooth_function(l10["eval_acc"])
    l10["RF"] = [resnets_rfs[10]] * len(l10)

    l11 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_11/probe_performances.csv", delimiter=";")
    l11["smooth_eval_acc"] = smooth_function(l11["eval_acc"])
    l11["RF"] = [resnets_rfs[11]] * len(l11)

    l12 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_12/probe_performances.csv", delimiter=";")
    l12["smooth_eval_acc"] = smooth_function(l12["eval_acc"])
    l12["RF"] = [resnets_rfs[12]] * len(l12)

    l13 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_12/probe_performances.csv", delimiter=";")
    l13["smooth_eval_acc"] = smooth_function(l13["eval_acc"])
    l13["RF"] = [resnets_rfs[13]] * len(l13)

    change_and_sort_names(l5)
    change_and_sort_names(l6)
    change_and_sort_names(l7)
    change_and_sort_names(l8)
    change_and_sort_names(l10)
    change_and_sort_names(l11)
    change_and_sort_names(l12)
    change_and_sort_names(l13)

    # l=pd.concat([l1,l2,l3,l4,l9,l10,l11])
    # l=pd.concat([l5,l6,l7,l8,l10,l11,l12,l13])
    l = pd.concat([l5, l6, l7, l8, l10])
    l["eval_acc"] = l["eval_acc"] * 100
    l["smooth_eval_acc"] = l["smooth_eval_acc"] * 100
    # l=pd.concat([l9,l10,l11])
    # l.sort_values(by="depth",inplace=True)

    fig, axs = plt.subplots(figsize=fig_size, layout="compressed")

    unique_RF = l["RF"].unique()
    num_colors = len(unique_RF)
    cm = mpl.cm.get_cmap(name='magma')
    currentColors = [cm(1. * i / num_colors) for i in range(num_colors)]

    for i, color in enumerate(currentColors):
        current_df = l[l["RF"] == unique_RF[i]]
        axs.plot(current_df["name"], current_df["smooth_eval_acc"], color=currentColors[i], label=f"{unique_RF[i]}")

    axs.set_xlabel("Layer", size=fs * labels_multiplier)
    axs.set_ylabel("Accuracy", size=fs * labels_multiplier)

    axs.set_xticks(range(1, 30))
    axs.set_xticklabels(range(1, 30))
    axs.set_yticks(accuracy_ticks)
    axs.set_yticklabels(accuracy_ticks)
    axs.xaxis.set_major_locator(ticker.AutoLocator())
    axs.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    axs.tick_params(axis='y', which='major', labelsize=fs * ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelsize=fs * ticks_multiplier)
    axs.legend(prop={"size": fs * legends_multiplier})
    axs.xaxis.set_major_locator(ticker.MultipleLocator(5))
    axs.xaxis.set_minor_locator(ticker.MultipleLocator(1))
    # #plt.xticks(rotation=90)

    plt.grid(ls="--")
    plt.savefig(
        "/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/probe_accuracy_resnet25_small_imagenet_detailed_224_lower_levels_smooth.pdf")
    plt.close()

    linear_l5 = float(l5[l5["name"] == "linear"]["eval_acc"])
    linear_l6 = float(l6[l6["name"] == "linear"]["eval_acc"])

    linear_l7 = float(l7[l7["name"] == "linear"]["eval_acc"])
    linear_l8 = float(l8[l8["name"] == "linear"]["eval_acc"])
    linear_l10 = float(l10[l10["name"] == "linear"]["eval_acc"])
    linear_l11 = float(l11[l11["name"] == "linear"]["eval_acc"])
    linear_l12 = float(l12[l12["name"] == "linear"]["eval_acc"])
    linear_l13 = float(l13[l13["name"] == "linear"]["eval_acc"])
    o = [linear_l5, linear_l6, linear_l7, linear_l8, linear_l10, linear_l11, linear_l12, linear_l13]

    def smooth_function(array):
        max = 0
        new_array = []
        for value in array:
            if value > max:
                max = value
            new_array.append(max)
        return new_array

    # all_layers_resnet50 = ["conv1","layer1.0.conv1", "layer1.0.conv2", "layer1.0.conv3", "layer1.0.shortcut.0",
    #                                "layer1.1.conv1", "layer1.1.conv2", "layer1.1.conv3", "layer1.2.conv1", "layer1.2.conv2",
    #                                "layer1.2.conv3", "layer2.0.conv1", "layer2.0.conv2", "layer2.0.conv3",
    #                                "layer2.0.shortcut.0", "layer2.1.conv1", "layer2.1.conv2", "layer2.1.conv3",
    #                                "layer2.2.conv1", "layer2.2.conv2", "layer2.2.conv3", "layer2.3.conv1", "layer2.3.conv2",
    #                                "layer2.3.conv3", "layer3.0.conv1", "layer3.0.conv2", "layer3.0.conv3",
    #                                "layer3.0.shortcut.0", "layer3.1.conv1", "layer3.1.conv2", "layer3.1.conv3",
    #                                "layer3.2.conv1", "layer3.2.conv2", "layer3.2.conv3", "layer3.3.conv1", "layer3.3.conv2",
    #                                "layer3.3.conv3", "layer3.4.conv1", "layer3.4.conv2", "layer3.4.conv3", "layer3.5.conv1",
    #                                "layer3.5.conv2", "layer3.5.conv3", "layer4.0.conv1", "layer4.0.conv2", "layer4.0.conv3",
    #                                "layer4.0.shortcut.0", "layer4.1.conv1", "layer4.1.conv2", "layer4.1.conv3",
    #                                "layer4.2.conv1", "layer4.2.conv2", "layer4.2.conv3","linear"]
    all_layers_resnet25_dict = {"0": "conv1", "1": "layer1.0.conv1_1x1", "2": "layer1.0.conv2_1x1",
                                "3": "layer1.0.conv3_3x3", "4": "layer1.0.conv4_1x1",
                                "5": "layer1.0.conv5_1x1", "6": "layer1.0.shortcut.0", "7": "layer2.0.conv1_1x1",
                                "8": "layer2.0.conv2_1x1", "9": "layer2.0.conv3_3x3",
                                "10": "layer2.0.conv4_1x1", "11": "layer2.0.conv5_1x1", "12": "layer2.0.shortcut.0",
                                "13": "layer3.0.conv1_1x1", "14": "layer3.0.conv2_1x1",
                                "15": "layer3.0.conv3_3x3", "16": "layer3.0.conv4_1x1", "17": "layer3.0.conv5_1x1",
                                "18": "layer3.0.shortcut.0", "19": "layer3.1.conv1_1x1",
                                "20": "layer3.1.conv2_1x1", "21": "layer3.1.conv3_3x3", "22": "layer3.1.conv4_1x1",
                                "23": "layer3.1.conv5_1x1", "24": "layer4.0.conv1_1x1",
                                "25": "layer4.0.conv2_1x1", "26": "layer4.0.conv3_3x3", "27": "layer4.0.conv4_1x1",
                                "28": "layer4.0.conv5_1x1", "29": "layer4.0.shortcut.0", "30": "linear"}

    all_layers_resnet25 = list(all_layers_resnet25_dict.values())

    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            o = string.replace("train-", "")
            o = o.replace("-", ".")
            return o

        new_names = list(map(trim, names))

        for name in new_names:
            sorted_index.append(all_layers_resnet25.index(name))
        df["depth"] = sorted_index
        df["name"] = new_names
        df.sort_values(by="depth", inplace=True)

    l5 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_5/probe_performances.csv", delimiter=";")
    l5["smooth_eval_acc"] = smooth_function(l5["eval_acc"])
    l5["RF"] = [resnets_rfs[5]] * len(l5)

    l6 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_6/probe_performances.csv", delimiter=";")
    l6["smooth_eval_acc"] = smooth_function(l6["eval_acc"])
    l6["RF"] = [resnets_rfs[6]] * len(l6)

    l7 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_7/probe_performances.csv", delimiter=";")
    l7["smooth_eval_acc"] = smooth_function(l7["eval_acc"])
    l7["RF"] = [resnets_rfs[7]] * len(l7)

    l8 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_5/probe_performances.csv", delimiter=";")
    l8["smooth_eval_acc"] = smooth_function(l8["eval_acc"])
    l8["RF"] = [resnets_rfs[8]] * len(l8)

    l10 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_10/probe_performances.csv", delimiter=";")
    l10["smooth_eval_acc"] = smooth_function(l10["eval_acc"])
    l10["RF"] = [resnets_rfs[10]] * len(l10)

    l11 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_11/probe_performances.csv", delimiter=";")
    l11["smooth_eval_acc"] = smooth_function(l11["eval_acc"])
    l11["RF"] = [resnets_rfs[11]] * len(l11)

    l12 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_12/probe_performances.csv", delimiter=";")
    l12["smooth_eval_acc"] = smooth_function(l12["eval_acc"])
    l12["RF"] = [resnets_rfs[12]] * len(l12)

    l13 = pd.read_csv("probes_logs/resnet25_small_small_imagenet_224_12/probe_performances.csv", delimiter=";")
    l13["smooth_eval_acc"] = smooth_function(l13["eval_acc"])
    l13["RF"] = [resnets_rfs[13]] * len(l13)

    change_and_sort_names(l5)
    change_and_sort_names(l6)
    change_and_sort_names(l7)
    change_and_sort_names(l8)
    change_and_sort_names(l10)
    change_and_sort_names(l11)
    change_and_sort_names(l12)
    change_and_sort_names(l13)

    # l=pd.concat([l1,l2,l3,l4,l9,l10,l11])
    # l=pd.concat([l5,l6,l7,l8,l10,l11,l12,l13])
    l = pd.concat([l11, l12, l13])
    l["eval_acc"] = l["eval_acc"] * 100
    l["smooth_eval_acc"] = l["smooth_eval_acc"] * 100
    # l=pd.concat([l9,l10,l11])
    # l.sort_values(by="depth",inplace=True)

    unique_RF = l["RF"].unique()
    num_colors = len(unique_RF)
    cm = mpl.cm.get_cmap(name='magma')
    currentColors = [cm(1. * i / num_colors) for i in range(num_colors)]

    for i, color in enumerate(currentColors):
        current_df = l[l["RF"] == unique_RF[i]]
        axs.plot(current_df["name"], current_df["smooth_eval_acc"], color=currentColors[i], label=f"{unique_RF[i]}")

    axs.set_xlabel("Layer", size=fs * labels_multiplier)
    axs.set_ylabel("Accuracy", size=fs * labels_multiplier)

    axs.set_xticks(range(1, 30))
    axs.set_xticklabels(range(1, 30))
    axs.set_yticks(accuracy_ticks)
    axs.set_yticklabels(accuracy_ticks)
    axs.xaxis.set_major_locator(ticker.AutoLocator())
    axs.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    axs.tick_params(axis='y', which='major', labelsize=fs * ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelsize=fs * ticks_multiplier)
    axs.legend(prop={"size": fs * legends_multiplier})
    # #plt.xticks(rotation=90)

    plt.grid(ls="--")
    plt.savefig(
        "/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/probe_accuracy_resnet25_small_imagenet_detailed_224_higher_levels_smooth.pdf")

    plt.close()

    fig, axs = plt.subplots(figsize=fig_size, layout="compressed")

    unique_RF = l["RF"].unique()
    num_colors = len(unique_RF)
    cm = mpl.cm.get_cmap(name='magma')
    currentColors = [cm(1. * i / num_colors) for i in range(num_colors)]

    for i, color in enumerate(currentColors):
        current_df = l[l["RF"] == unique_RF[i]]
        axs.plot(current_df["name"], current_df["smooth_eval_acc"], color=currentColors[i], label=f"{unique_RF[i]}")

    axs.set_xlabel("Layer", size=fs * labels_multiplier)
    axs.set_ylabel("Accuracy", size=fs * labels_multiplier)
    axs.set_yticks(accuracy_ticks)
    axs.set_yticklabels(accuracy_ticks)
    axs.set_xticks(range(1, 30))
    axs.set_xticklabels(range(1, 30))
    axs.xaxis.set_major_locator(ticker.AutoLocator())
    axs.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    axs.tick_params(axis='y', which='major', labelsize=fs * ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelsize=fs * ticks_multiplier)
    axs.legend(prop={"size": fs * legends_multiplier})
    axs.xaxis.set_major_locator(ticker.MultipleLocator(5))
    axs.xaxis.set_minor_locator(ticker.MultipleLocator(1))
    plt.grid(ls="--")
    plt.savefig(
        "/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/probe_accuracy_resnet25_small_imagenet_detailed_224_higher_levels.pdf")

    """## ResNet25 x Small imagenet pruned $\gamma=0.95$ *batch norm adjusted*"""

    # all_layers_resnet50 = ["conv1","layer1.0.conv1", "layer1.0.conv2", "layer1.0.conv3", "layer1.0.shortcut.0",
    #                                "layer1.1.conv1", "layer1.1.conv2", "layer1.1.conv3", "layer1.2.conv1", "layer1.2.conv2",
    #                                "layer1.2.conv3", "layer2.0.conv1", "layer2.0.conv2", "layer2.0.conv3",
    #                                "layer2.0.shortcut.0", "layer2.1.conv1", "layer2.1.conv2", "layer2.1.conv3",
    #                                "layer2.2.conv1", "layer2.2.conv2", "layer2.2.conv3", "layer2.3.conv1", "layer2.3.conv2",
    #                                "layer2.3.conv3", "layer3.0.conv1", "layer3.0.conv2", "layer3.0.conv3",
    #                                "layer3.0.shortcut.0", "layer3.1.conv1", "layer3.1.conv2", "layer3.1.conv3",
    #                                "layer3.2.conv1", "layer3.2.conv2", "layer3.2.conv3", "layer3.3.conv1", "layer3.3.conv2",
    #                                "layer3.3.conv3", "layer3.4.conv1", "layer3.4.conv2", "layer3.4.conv3", "layer3.5.conv1",
    #                                "layer3.5.conv2", "layer3.5.conv3", "layer4.0.conv1", "layer4.0.conv2", "layer4.0.conv3",
    #                                "layer4.0.shortcut.0", "layer4.1.conv1", "layer4.1.conv2", "layer4.1.conv3",
    #                                "layer4.2.conv1", "layer4.2.conv2", "layer4.2.conv3","linear"]
    all_layers_resnet25_dict = {"0": "conv1", "1": "layer1.0.conv1_1x1", "2": "layer1.0.conv2_1x1",
                                "3": "layer1.0.conv3_3x3", "4": "layer1.0.conv4_1x1",
                                "5": "layer1.0.conv5_1x1", "6": "layer1.0.shortcut.0", "7": "layer2.0.conv1_1x1",
                                "8": "layer2.0.conv2_1x1", "9": "layer2.0.conv3_3x3",
                                "10": "layer2.0.conv4_1x1", "11": "layer2.0.conv5_1x1", "12": "layer2.0.shortcut.0",
                                "13": "layer3.0.conv1_1x1", "14": "layer3.0.conv2_1x1",
                                "15": "layer3.0.conv3_3x3", "16": "layer3.0.conv4_1x1", "17": "layer3.0.conv5_1x1",
                                "18": "layer3.0.shortcut.0", "19": "layer3.1.conv1_1x1",
                                "20": "layer3.1.conv2_1x1", "21": "layer3.1.conv3_3x3", "22": "layer3.1.conv4_1x1",
                                "23": "layer3.1.conv5_1x1", "24": "layer4.0.conv1_1x1",
                                "25": "layer4.0.conv2_1x1", "26": "layer4.0.conv3_3x3", "27": "layer4.0.conv4_1x1",
                                "28": "layer4.0.conv5_1x1", "29": "layer4.0.shortcut.0", "30": "linear"}

    all_layers_resnet25 = list(all_layers_resnet25_dict.values())

    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            o = string.replace("train-", "")
            o = o.replace("-", ".")
            return o

        new_names = list(map(trim, names))

        for name in new_names:
            sorted_index.append(all_layers_resnet25.index(name))
        df["depth"] = sorted_index
        df["name"] = new_names
        df.sort_values(by="depth", inplace=True)

    l5 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_5_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l5["RF"] = [resnets_rfs[5]] * len(l5)

    l6 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_6_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l6["RF"] = [resnets_rfs[6]] * len(l6)

    l7 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_7_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l7["RF"] = [resnets_rfs[7]] * len(l7)

    l8 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_8_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l8["RF"] = [resnets_rfs[8]] * len(l8)

    l10 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_10_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l10["RF"] = [resnets_rfs[10]] * len(l10)

    l11 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_11_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l11["RF"] = [resnets_rfs[11]] * len(l11)
    l12 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_12_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l12["RF"] = [resnets_rfs[12]] * len(l12)

    l13 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_13_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l13["RF"] = [resnets_rfs[13]] * len(l13)

    change_and_sort_names(l5)
    change_and_sort_names(l6)
    change_and_sort_names(l7)
    change_and_sort_names(l8)
    change_and_sort_names(l10)
    change_and_sort_names(l11)
    change_and_sort_names(l12)
    change_and_sort_names(l13)

    # l=pd.concat([l1,l2,l3,l4,l9,l10,l11])
    # l=pd.concat([l5,l6,l7,l8,l10,l11,l12,l13])
    l = pd.concat([l5, l6, l7, l8, l10])
    l["eval_acc"] = l["eval_acc"] * 100
    # l=pd.concat([l9,l10,l11])
    # l.sort_values(by="depth",inplace=True)

    fig, axs = plt.subplots(figsize=fig_size, layout="compressed")

    unique_RF = l["RF"].unique()
    num_colors = len(unique_RF)
    cm = mpl.cm.get_cmap(name='magma')
    currentColors = [cm(1. * i / num_colors) for i in range(num_colors)]

    for i, color in enumerate(currentColors):
        current_df = l[l["RF"] == unique_RF[i]]
        axs.plot(current_df["name"], current_df["eval_acc"], color=currentColors[i], label=f"{unique_RF[i]}")

    axs.set_xlabel("Layer", size=fs * labels_multiplier)
    axs.set_ylabel("Accuracy", size=fs * labels_multiplier)

    axs.set_xticks(range(1, 30))
    axs.set_xticklabels(range(1, 30))
    axs.set_yticks(accuracy_ticks)
    axs.set_yticklabels(accuracy_ticks)
    axs.tick_params(axis='y', which='major', labelsize=fs * ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelsize=fs * ticks_multiplier)
    axs.legend(prop={"size": fs * legends_multiplier})
    axs.xaxis.set_major_locator(ticker.MultipleLocator(5))
    axs.xaxis.set_minor_locator(ticker.MultipleLocator(1))

    # #plt.xticks(rotation=90)

    plt.grid(ls="--")
    plt.savefig(
        "/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/probe_accuracy_resnet25_small_imagenet_detailed_224_lower_levels_batchnorm_adjusted.pdf")

    plt.close()

    """### smooth version"""

    def smooth_function(array):
        max = 0
        new_array = []
        for value in array:
            if value > max:
                max = value
            new_array.append(max)
        return new_array

    # all_layers_resnet50 = ["conv1","layer1.0.conv1", "layer1.0.conv2", "layer1.0.conv3", "layer1.0.shortcut.0",
    #                                "layer1.1.conv1", "layer1.1.conv2", "layer1.1.conv3", "layer1.2.conv1", "layer1.2.conv2",
    #                                "layer1.2.conv3", "layer2.0.conv1", "layer2.0.conv2", "layer2.0.conv3",
    #                                "layer2.0.shortcut.0", "layer2.1.conv1", "layer2.1.conv2", "layer2.1.conv3",
    #                                "layer2.2.conv1", "layer2.2.conv2", "layer2.2.conv3", "layer2.3.conv1", "layer2.3.conv2",
    #                                "layer2.3.conv3", "layer3.0.conv1", "layer3.0.conv2", "layer3.0.conv3",
    #                                "layer3.0.shortcut.0", "layer3.1.conv1", "layer3.1.conv2", "layer3.1.conv3",
    #                                "layer3.2.conv1", "layer3.2.conv2", "layer3.2.conv3", "layer3.3.conv1", "layer3.3.conv2",
    #                                "layer3.3.conv3", "layer3.4.conv1", "layer3.4.conv2", "layer3.4.conv3", "layer3.5.conv1",
    #                                "layer3.5.conv2", "layer3.5.conv3", "layer4.0.conv1", "layer4.0.conv2", "layer4.0.conv3",
    #                                "layer4.0.shortcut.0", "layer4.1.conv1", "layer4.1.conv2", "layer4.1.conv3",
    #                                "layer4.2.conv1", "layer4.2.conv2", "layer4.2.conv3","linear"]
    all_layers_resnet25_dict = {"0": "conv1", "1": "layer1.0.conv1_1x1", "2": "layer1.0.conv2_1x1",
                                "3": "layer1.0.conv3_3x3", "4": "layer1.0.conv4_1x1",
                                "5": "layer1.0.conv5_1x1", "6": "layer1.0.shortcut.0", "7": "layer2.0.conv1_1x1",
                                "8": "layer2.0.conv2_1x1", "9": "layer2.0.conv3_3x3",
                                "10": "layer2.0.conv4_1x1", "11": "layer2.0.conv5_1x1", "12": "layer2.0.shortcut.0",
                                "13": "layer3.0.conv1_1x1", "14": "layer3.0.conv2_1x1",
                                "15": "layer3.0.conv3_3x3", "16": "layer3.0.conv4_1x1", "17": "layer3.0.conv5_1x1",
                                "18": "layer3.0.shortcut.0", "19": "layer3.1.conv1_1x1",
                                "20": "layer3.1.conv2_1x1", "21": "layer3.1.conv3_3x3", "22": "layer3.1.conv4_1x1",
                                "23": "layer3.1.conv5_1x1", "24": "layer4.0.conv1_1x1",
                                "25": "layer4.0.conv2_1x1", "26": "layer4.0.conv3_3x3", "27": "layer4.0.conv4_1x1",
                                "28": "layer4.0.conv5_1x1", "29": "layer4.0.shortcut.0", "30": "linear"}

    all_layers_resnet25 = list(all_layers_resnet25_dict.values())

    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            o = string.replace("train-", "")
            o = o.replace("-", ".")
            return o

        new_names = list(map(trim, names))

        for name in new_names:
            sorted_index.append(all_layers_resnet25.index(name))
        df["depth"] = sorted_index
        df["name"] = new_names
        df.sort_values(by="depth", inplace=True)

    l5 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_5_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l5["smooth_eval_acc"] = smooth_function(l5["eval_acc"])
    l5["RF"] = [resnets_rfs[5]] * len(l5)

    l6 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_6_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l6["smooth_eval_acc"] = smooth_function(l6["eval_acc"])
    l6["RF"] = [resnets_rfs[6]] * len(l6)

    l7 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_7_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l7["smooth_eval_acc"] = smooth_function(l7["eval_acc"])
    l7["RF"] = [resnets_rfs[7]] * len(l7)

    l8 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_8_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l8["smooth_eval_acc"] = smooth_function(l8["eval_acc"])
    l8["RF"] = [resnets_rfs[8]] * len(l8)

    l10 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_10_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l10["smooth_eval_acc"] = smooth_function(l10["eval_acc"])
    l10["RF"] = [resnets_rfs[10]] * len(l10)

    l11 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_11_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l11["smooth_eval_acc"] = smooth_function(l11["eval_acc"])
    l11["RF"] = [resnets_rfs[11]] * len(l11)

    l12 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_12_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l12["smooth_eval_acc"] = smooth_function(l12["eval_acc"])
    l12["RF"] = [resnets_rfs[12]] * len(l12)

    l13 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_13_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l13["smooth_eval_acc"] = smooth_function(l13["eval_acc"])
    l13["RF"] = [resnets_rfs[13]] * len(l13)

    change_and_sort_names(l5)
    change_and_sort_names(l6)
    change_and_sort_names(l7)
    change_and_sort_names(l8)
    change_and_sort_names(l10)
    change_and_sort_names(l11)
    change_and_sort_names(l12)
    change_and_sort_names(l13)

    # l=pd.concat([l1,l2,l3,l4,l9,l10,l11])
    # l=pd.concat([l5,l6,l7,l8,l10,l11,l12,l13])
    l = pd.concat([l5, l6, l7, l8, l10])
    l["eval_acc"] = l["eval_acc"] * 100
    l["smooth_eval_acc"] = l["smooth_eval_acc"] * 100
    # l=pd.concat([l9,l10,l11])
    # l.sort_values(by="depth",inplace=True)

    fig, axs = plt.subplots(figsize=fig_size, layout="compressed")

    unique_RF = l["RF"].unique()
    num_colors = len(unique_RF)
    cm = mpl.cm.get_cmap(name='magma')
    currentColors = [cm(1. * i / num_colors) for i in range(num_colors)]

    for i, color in enumerate(currentColors):
        current_df = l[l["RF"] == unique_RF[i]]
        axs.plot(current_df["name"], current_df["smooth_eval_acc"], color=currentColors[i], label=f"{unique_RF[i]}")

    axs.set_xlabel("Layer", size=fs * labels_multiplier)
    axs.set_ylabel("Accuracy", size=fs * labels_multiplier)

    axs.set_xticks(range(1, 30))
    axs.set_xticklabels(range(1, 30))
    axs.set_yticks(accuracy_ticks)
    axs.set_yticklabels(accuracy_ticks)
    axs.xaxis.set_major_locator(ticker.MultipleLocator(5))
    axs.xaxis.set_minor_locator(ticker.MultipleLocator(1))
    axs.tick_params(axis='y', which='major', labelsize=fs * ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelsize=fs * ticks_multiplier)
    axs.legend(prop={"size": fs * legends_multiplier})

    # #plt.xticks(rotation=90)

    plt.grid(ls="--")

    plt.savefig(
        "/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/probe_accuracy_resnet25_small_imagenet_detailed_224_lower_levels_smooth_batchnorm_adjusted.pdf")
    plt.close()

    def smooth_function(array):
        max = 0
        new_array = []
        for value in array:
            if value > max:
                max = value
            new_array.append(max)
        return new_array

    # all_layers_resnet50 = ["conv1","layer1.0.conv1", "layer1.0.conv2", "layer1.0.conv3", "layer1.0.shortcut.0",
    #                                "layer1.1.conv1", "layer1.1.conv2", "layer1.1.conv3", "layer1.2.conv1", "layer1.2.conv2",
    #                                "layer1.2.conv3", "layer2.0.conv1", "layer2.0.conv2", "layer2.0.conv3",
    #                                "layer2.0.shortcut.0", "layer2.1.conv1", "layer2.1.conv2", "layer2.1.conv3",
    #                                "layer2.2.conv1", "layer2.2.conv2", "layer2.2.conv3", "layer2.3.conv1", "layer2.3.conv2",
    #                                "layer2.3.conv3", "layer3.0.conv1", "layer3.0.conv2", "layer3.0.conv3",
    #                                "layer3.0.shortcut.0", "layer3.1.conv1", "layer3.1.conv2", "layer3.1.conv3",
    #                                "layer3.2.conv1", "layer3.2.conv2", "layer3.2.conv3", "layer3.3.conv1", "layer3.3.conv2",
    #                                "layer3.3.conv3", "layer3.4.conv1", "layer3.4.conv2", "layer3.4.conv3", "layer3.5.conv1",
    #                                "layer3.5.conv2", "layer3.5.conv3", "layer4.0.conv1", "layer4.0.conv2", "layer4.0.conv3",
    #                                "layer4.0.shortcut.0", "layer4.1.conv1", "layer4.1.conv2", "layer4.1.conv3",
    #                                "layer4.2.conv1", "layer4.2.conv2", "layer4.2.conv3","linear"]
    all_layers_resnet25_dict = {"0": "conv1", "1": "layer1.0.conv1_1x1", "2": "layer1.0.conv2_1x1",
                                "3": "layer1.0.conv3_3x3", "4": "layer1.0.conv4_1x1",
                                "5": "layer1.0.conv5_1x1", "6": "layer1.0.shortcut.0", "7": "layer2.0.conv1_1x1",
                                "8": "layer2.0.conv2_1x1", "9": "layer2.0.conv3_3x3",
                                "10": "layer2.0.conv4_1x1", "11": "layer2.0.conv5_1x1", "12": "layer2.0.shortcut.0",
                                "13": "layer3.0.conv1_1x1", "14": "layer3.0.conv2_1x1",
                                "15": "layer3.0.conv3_3x3", "16": "layer3.0.conv4_1x1", "17": "layer3.0.conv5_1x1",
                                "18": "layer3.0.shortcut.0", "19": "layer3.1.conv1_1x1",
                                "20": "layer3.1.conv2_1x1", "21": "layer3.1.conv3_3x3", "22": "layer3.1.conv4_1x1",
                                "23": "layer3.1.conv5_1x1", "24": "layer4.0.conv1_1x1",
                                "25": "layer4.0.conv2_1x1", "26": "layer4.0.conv3_3x3", "27": "layer4.0.conv4_1x1",
                                "28": "layer4.0.conv5_1x1", "29": "layer4.0.shortcut.0", "30": "linear"}

    all_layers_resnet25 = list(all_layers_resnet25_dict.values())

    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            o = string.replace("train-", "")
            o = o.replace("-", ".")
            return o

        new_names = list(map(trim, names))

        for name in new_names:
            sorted_index.append(all_layers_resnet25.index(name))
        df["depth"] = sorted_index
        df["name"] = new_names
        df.sort_values(by="depth", inplace=True)

    l5 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_5_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l5["smooth_eval_acc"] = smooth_function(l5["eval_acc"])
    l5["RF"] = [resnets_rfs[5]] * len(l5)

    l6 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_6_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l6["smooth_eval_acc"] = smooth_function(l6["eval_acc"])
    l6["RF"] = [resnets_rfs[6]] * len(l6)

    l7 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_7_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l7["smooth_eval_acc"] = smooth_function(l7["eval_acc"])
    l7["RF"] = [resnets_rfs[7]] * len(l7)

    l8 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_8_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l8["smooth_eval_acc"] = smooth_function(l8["eval_acc"])
    l8["RF"] = [resnets_rfs[8]] * len(l8)

    l10 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_10_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l10["smooth_eval_acc"] = smooth_function(l10["eval_acc"])
    l10["RF"] = [resnets_rfs[10]] * len(l10)

    l11 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_11_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l11["smooth_eval_acc"] = smooth_function(l11["eval_acc"])
    l11["RF"] = [resnets_rfs[11]] * len(l11)

    l12 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_12_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l12["smooth_eval_acc"] = smooth_function(l12["eval_acc"])
    l12["RF"] = [resnets_rfs[12]] * len(l12)

    l13 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_13_sgd_100_res_224_no_ffcv_test_pr_0.95_adjusted_bn/probe_performances.csv",
        delimiter=";")
    l13["smooth_eval_acc"] = smooth_function(l13["eval_acc"])
    l13["RF"] = [resnets_rfs[13]] * len(l13)

    change_and_sort_names(l5)
    change_and_sort_names(l6)
    change_and_sort_names(l7)
    change_and_sort_names(l8)
    change_and_sort_names(l10)
    change_and_sort_names(l11)
    change_and_sort_names(l12)
    change_and_sort_names(l13)

    # l=pd.concat([l1,l2,l3,l4,l9,l10,l11])
    # l=pd.concat([l5,l6,l7,l8,l10,l11,l12,l13])
    l = pd.concat([l11, l12, l13])
    l["eval_acc"] = l["eval_acc"] * 100
    l["smooth_eval_acc"] = l["smooth_eval_acc"] * 100
    # l=pd.concat([l9,l10,l11])
    # l.sort_values(by="depth",inplace=True)

    fig, axs = plt.subplots(figsize=fig_size, layout="compressed")

    unique_RF = l["RF"].unique()
    num_colors = len(unique_RF)
    cm = mpl.cm.get_cmap(name='magma')
    currentColors = [cm(1. * i / num_colors) for i in range(num_colors)]

    for i, color in enumerate(currentColors):
        current_df = l[l["RF"] == unique_RF[i]]
        axs.plot(current_df["name"], current_df["smooth_eval_acc"], color=currentColors[i], label=f"{unique_RF[i]}")

    axs.set_xlabel("Layer", size=fs * labels_multiplier)
    axs.set_ylabel("Accuracy", size=fs * labels_multiplier)

    axs.set_xticks(range(1, 30))
    axs.set_xticklabels(range(1, 30))
    axs.set_yticks(accuracy_ticks)
    axs.set_yticklabels(accuracy_ticks)
    axs.xaxis.set_major_locator(ticker.MultipleLocator(5))
    axs.xaxis.set_minor_locator(ticker.MultipleLocator(1))
    axs.tick_params(axis='y', which='major', labelsize=fs * ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelsize=fs * ticks_multiplier)
    axs.legend(prop={"size": fs * legends_multiplier})
    # #plt.xticks(rotation=90)

    # plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/probe_accuracy_resnet25_small_imagenet_detailed_224.pdf")
    plt.grid(ls="--")
    plt.savefig(
        "/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/probe_accuracy_resnet25_small_imagenet_detailed_224_higher_levels_smooth_batchnorm_adjusted.pdf")

    plt.close()

    """
    ## ResNet25 x Small imagenet pruned $\gamma=0.8$ **NO** *batch norm adjusted*"""

    # all_layers_resnet50 = ["conv1","layer1.0.conv1", "layer1.0.conv2", "layer1.0.conv3", "layer1.0.shortcut.0",
    #                                "layer1.1.conv1", "layer1.1.conv2", "layer1.1.conv3", "layer1.2.conv1", "layer1.2.conv2",
    #                                "layer1.2.conv3", "layer2.0.conv1", "layer2.0.conv2", "layer2.0.conv3",
    #                                "layer2.0.shortcut.0", "layer2.1.conv1", "layer2.1.conv2", "layer2.1.conv3",
    #                                "layer2.2.conv1", "layer2.2.conv2", "layer2.2.conv3", "layer2.3.conv1", "layer2.3.conv2",
    #                                "layer2.3.conv3", "layer3.0.conv1", "layer3.0.conv2", "layer3.0.conv3",
    #                                "layer3.0.shortcut.0", "layer3.1.conv1", "layer3.1.conv2", "layer3.1.conv3",
    #                                "layer3.2.conv1", "layer3.2.conv2", "layer3.2.conv3", "layer3.3.conv1", "layer3.3.conv2",
    #                                "layer3.3.conv3", "layer3.4.conv1", "layer3.4.conv2", "layer3.4.conv3", "layer3.5.conv1",
    #                                "layer3.5.conv2", "layer3.5.conv3", "layer4.0.conv1", "layer4.0.conv2", "layer4.0.conv3",
    #                                "layer4.0.shortcut.0", "layer4.1.conv1", "layer4.1.conv2", "layer4.1.conv3",
    #                                "layer4.2.conv1", "layer4.2.conv2", "layer4.2.conv3","linear"]
    all_layers_resnet25_dict = {"0": "conv1", "1": "layer1.0.conv1_1x1", "2": "layer1.0.conv2_1x1",
                                "3": "layer1.0.conv3_3x3", "4": "layer1.0.conv4_1x1",
                                "5": "layer1.0.conv5_1x1", "6": "layer1.0.shortcut.0", "7": "layer2.0.conv1_1x1",
                                "8": "layer2.0.conv2_1x1", "9": "layer2.0.conv3_3x3",
                                "10": "layer2.0.conv4_1x1", "11": "layer2.0.conv5_1x1", "12": "layer2.0.shortcut.0",
                                "13": "layer3.0.conv1_1x1", "14": "layer3.0.conv2_1x1",
                                "15": "layer3.0.conv3_3x3", "16": "layer3.0.conv4_1x1", "17": "layer3.0.conv5_1x1",
                                "18": "layer3.0.shortcut.0", "19": "layer3.1.conv1_1x1",
                                "20": "layer3.1.conv2_1x1", "21": "layer3.1.conv3_3x3", "22": "layer3.1.conv4_1x1",
                                "23": "layer3.1.conv5_1x1", "24": "layer4.0.conv1_1x1",
                                "25": "layer4.0.conv2_1x1", "26": "layer4.0.conv3_3x3", "27": "layer4.0.conv4_1x1",
                                "28": "layer4.0.conv5_1x1", "29": "layer4.0.shortcut.0", "30": "linear"}

    all_layers_resnet25 = list(all_layers_resnet25_dict.values())

    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            o = string.replace("train-", "")
            o = o.replace("-", ".")
            return o

        new_names = list(map(trim, names))

        for name in new_names:
            sorted_index.append(all_layers_resnet25.index(name))
        df["depth"] = sorted_index
        df["name"] = new_names
        df.sort_values(by="depth", inplace=True)

    l5 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_5_sgd_100_res_224_no_ffcv_test_pr_0.8/probe_performances.csv",
        delimiter=";")
    l5["RF"] = [resnets_rfs[5]] * len(l5)

    l6 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_6_sgd_100_res_224_no_ffcv_test_pr_0.8/probe_performances.csv",
        delimiter=";")
    l6["RF"] = [resnets_rfs[6]] * len(l6)

    l7 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_7_sgd_100_res_224_no_ffcv_test_pr_0.8/probe_performances.csv",
        delimiter=";")
    l7["RF"] = [resnets_rfs[7]] * len(l7)

    l8 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_8_sgd_100_res_224_no_ffcv_test_pr_0.8/probe_performances.csv",
        delimiter=";")
    l8["RF"] = [resnets_rfs[8]] * len(l8)

    l10 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_10_sgd_100_res_224_no_ffcv_test_pr_0.8/probe_performances.csv",
        delimiter=";")
    l10["RF"] = [resnets_rfs[10]] * len(l10)

    l11 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_11_sgd_100_res_224_no_ffcv_test_pr_0.8/probe_performances.csv",
        delimiter=";")
    l11["RF"] = [resnets_rfs[11]] * len(l11)
    l12 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_12_sgd_100_res_224_no_ffcv_test_pr_0.8/probe_performances.csv",
        delimiter=";")
    l12["RF"] = [resnets_rfs[12]] * len(l12)

    l13 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_13_sgd_100_res_224_no_ffcv_test_pr_0.8/probe_performances.csv",
        delimiter=";")
    l13["RF"] = [resnets_rfs[13]] * len(l13)

    change_and_sort_names(l5)
    change_and_sort_names(l6)
    change_and_sort_names(l7)
    change_and_sort_names(l8)
    change_and_sort_names(l10)
    change_and_sort_names(l11)
    change_and_sort_names(l12)
    change_and_sort_names(l13)

    # l=pd.concat([l1,l2,l3,l4,l9,l10,l11])
    # l=pd.concat([l5,l6,l7,l8,l10,l11,l12,l13])
    l = pd.concat([l5, l6, l7, l8, l10])
    l["eval_acc"] = l["eval_acc"] * 100
    # l=pd.concat([l9,l10,l11])
    # l.sort_values(by="depth",inplace=True)

    fig, axs = plt.subplots(figsize=fig_size, layout="compressed")

    unique_RF = l["RF"].unique()
    num_colors = len(unique_RF)
    cm = mpl.cm.get_cmap(name='magma')
    currentColors = [cm(1. * i / num_colors) for i in range(num_colors)]

    for i, color in enumerate(currentColors):
        current_df = l[l["RF"] == unique_RF[i]]
        axs.plot(current_df["name"], current_df["eval_acc"], color=currentColors[i], label=f"{unique_RF[i]}")

    axs.set_xlabel("Layer", size=fs * labels_multiplier)
    axs.set_ylabel("Accuracy", size=fs * labels_multiplier)

    axs.set_xticks(range(1, 30))
    axs.set_xticklabels(range(1, 30))
    axs.set_yticks(accuracy_ticks)
    axs.set_yticklabels(accuracy_ticks)
    axs.xaxis.set_major_locator(ticker.MultipleLocator(5))
    axs.xaxis.set_minor_locator(ticker.MultipleLocator(1))
    axs.tick_params(axis='y', which='major', labelsize=fs * ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelsize=fs * ticks_multiplier)
    axs.legend(prop={"size": fs * legends_multiplier})
    # #plt.xticks(rotation=90)

    plt.grid(ls="--")
    plt.savefig(
        "/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/probe_accuracy_resnet25_small_imagenet_detailed_224_lower_levels.pdf")

    plt.close()

    """#### Smooth version"""

    def smooth_function(array):
        max = 0
        new_array = []
        for value in array:
            if value > max:
                max = value
            new_array.append(max)
        return new_array

    # all_layers_resnet50 = ["conv1","layer1.0.conv1", "layer1.0.conv2", "layer1.0.conv3", "layer1.0.shortcut.0",
    #                                "layer1.1.conv1", "layer1.1.conv2", "layer1.1.conv3", "layer1.2.conv1", "layer1.2.conv2",
    #                                "layer1.2.conv3", "layer2.0.conv1", "layer2.0.conv2", "layer2.0.conv3",
    #                                "layer2.0.shortcut.0", "layer2.1.conv1", "layer2.1.conv2", "layer2.1.conv3",
    #                                "layer2.2.conv1", "layer2.2.conv2", "layer2.2.conv3", "layer2.3.conv1", "layer2.3.conv2",
    #                                "layer2.3.conv3", "layer3.0.conv1", "layer3.0.conv2", "layer3.0.conv3",
    #                                "layer3.0.shortcut.0", "layer3.1.conv1", "layer3.1.conv2", "layer3.1.conv3",
    #                                "layer3.2.conv1", "layer3.2.conv2", "layer3.2.conv3", "layer3.3.conv1", "layer3.3.conv2",
    #                                "layer3.3.conv3", "layer3.4.conv1", "layer3.4.conv2", "layer3.4.conv3", "layer3.5.conv1",
    #                                "layer3.5.conv2", "layer3.5.conv3", "layer4.0.conv1", "layer4.0.conv2", "layer4.0.conv3",
    #                                "layer4.0.shortcut.0", "layer4.1.conv1", "layer4.1.conv2", "layer4.1.conv3",
    #                                "layer4.2.conv1", "layer4.2.conv2", "layer4.2.conv3","linear"]
    all_layers_resnet25_dict = {"0": "conv1", "1": "layer1.0.conv1_1x1", "2": "layer1.0.conv2_1x1",
                                "3": "layer1.0.conv3_3x3", "4": "layer1.0.conv4_1x1",
                                "5": "layer1.0.conv5_1x1", "6": "layer1.0.shortcut.0", "7": "layer2.0.conv1_1x1",
                                "8": "layer2.0.conv2_1x1", "9": "layer2.0.conv3_3x3",
                                "10": "layer2.0.conv4_1x1", "11": "layer2.0.conv5_1x1", "12": "layer2.0.shortcut.0",
                                "13": "layer3.0.conv1_1x1", "14": "layer3.0.conv2_1x1",
                                "15": "layer3.0.conv3_3x3", "16": "layer3.0.conv4_1x1", "17": "layer3.0.conv5_1x1",
                                "18": "layer3.0.shortcut.0", "19": "layer3.1.conv1_1x1",
                                "20": "layer3.1.conv2_1x1", "21": "layer3.1.conv3_3x3", "22": "layer3.1.conv4_1x1",
                                "23": "layer3.1.conv5_1x1", "24": "layer4.0.conv1_1x1",
                                "25": "layer4.0.conv2_1x1", "26": "layer4.0.conv3_3x3", "27": "layer4.0.conv4_1x1",
                                "28": "layer4.0.conv5_1x1", "29": "layer4.0.shortcut.0", "30": "linear"}

    all_layers_resnet25 = list(all_layers_resnet25_dict.values())

    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))

    def change_and_sort_names(df):
        names = list(df["name"])
        sorted_index = []

        def trim(string):
            o = string.replace("train-", "")
            o = o.replace("-", ".")
            return o

        new_names = list(map(trim, names))

        for name in new_names:
            sorted_index.append(all_layers_resnet25.index(name))
        df["depth"] = sorted_index
        df["name"] = new_names
        df.sort_values(by="depth", inplace=True)

    l5 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_5_sgd_100_res_224_no_ffcv_test_pr_0.8/probe_performances.csv",
        delimiter=";")
    l5["smooth_eval_acc"] = smooth_function(l5["eval_acc"])
    l5["RF"] = [resnets_rfs[5]] * len(l5)

    l6 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_6_sgd_100_res_224_no_ffcv_test_pr_0.8/probe_performances.csv",
        delimiter=";")
    l6["smooth_eval_acc"] = smooth_function(l6["eval_acc"])
    l6["RF"] = [resnets_rfs[6]] * len(l6)

    l7 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_7_sgd_100_res_224_no_ffcv_test_pr_0.8/probe_performances.csv",
        delimiter=";")
    l7["smooth_eval_acc"] = smooth_function(l7["eval_acc"])
    l7["RF"] = [resnets_rfs[7]] * len(l7)

    l8 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_8_sgd_100_res_224_no_ffcv_test_pr_0.8/probe_performances.csv",
        delimiter=";")
    l8["smooth_eval_acc"] = smooth_function(l8["eval_acc"])
    l8["RF"] = [resnets_rfs[8]] * len(l8)

    l10 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_10_sgd_100_res_224_no_ffcv_test_pr_0.8/probe_performances.csv",
        delimiter=";")
    l10["smooth_eval_acc"] = smooth_function(l10["eval_acc"])
    l10["RF"] = [resnets_rfs[10]] * len(l10)

    l11 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_11_sgd_100_res_224_no_ffcv_test_pr_0.8/probe_performances.csv",
        delimiter=";")
    l11["smooth_eval_acc"] = smooth_function(l11["eval_acc"])
    l11["RF"] = [resnets_rfs[11]] * len(l11)

    l12 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_12_sgd_100_res_224_no_ffcv_test_pr_0.8/probe_performances.csv",
        delimiter=";")
    l12["smooth_eval_acc"] = smooth_function(l12["eval_acc"])
    l12["RF"] = [resnets_rfs[12]] * len(l12)

    l13 = pd.read_csv(
        "probes_logs/resnet25_small_small_imagenet_224_13_sgd_100_res_224_no_ffcv_test_pr_0.8/probe_performances.csv",
        delimiter=";")
    l13["smooth_eval_acc"] = smooth_function(l13["eval_acc"])
    l13["RF"] = [resnets_rfs[13]] * len(l13)

    change_and_sort_names(l5)
    change_and_sort_names(l6)
    change_and_sort_names(l7)
    change_and_sort_names(l8)
    change_and_sort_names(l10)
    change_and_sort_names(l11)
    change_and_sort_names(l12)
    change_and_sort_names(l13)

    # l=pd.concat([l1,l2,l3,l4,l9,l10,l11])
    l = pd.concat([l5, l6, l7, l8, l10])
    l["eval_acc"] = l["eval_acc"] * 100
    l["smooth_eval_acc"] = l["smooth_eval_acc"] * 100
    # l=pd.concat([l11,l12,l13])
    # l=pd.concat([l9,l10,l11])
    # l.sort_values(by="depth",inplace=True)

    fig, axs = plt.subplots(figsize=fig_size, layout="compressed")

    unique_RF = l["RF"].unique()
    num_colors = len(unique_RF)
    cm = mpl.cm.get_cmap(name='magma')
    currentColors = [cm(1. * i / num_colors) for i in range(num_colors)]

    for i, color in enumerate(currentColors):
        current_df = l[l["RF"] == unique_RF[i]]
        axs.plot(current_df["name"], current_df["smooth_eval_acc"], color=currentColors[i], label=f"{unique_RF[i]}")

    axs.set_xlabel("Layer", size=fs * labels_multiplier)
    axs.set_ylabel("Accuracy", size=fs * labels_multiplier)

    axs.set_xticks(range(1, 30))
    axs.set_xticklabels(range(1, 30))
    axs.set_yticks(accuracy_ticks)
    axs.set_yticklabels(accuracy_ticks)
    axs.xaxis.set_major_locator(ticker.MultipleLocator(5))
    axs.xaxis.set_minor_locator(ticker.MultipleLocator(1))
    axs.tick_params(axis='y', which='major', labelsize=fs * ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelsize=fs * ticks_multiplier)
    axs.legend(prop={"size": fs * legends_multiplier})
    # #plt.xticks(rotation=90)

    # plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/probe_accuracy_resnet25_small_imagenet_detailed_224.pdf")
    plt.grid(ls="--")
    plt.savefig(
        "/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/probe_accuracy_resnet25_small_imagenet_detailed_224_higher_levels_smooth.pdf")

    plt.close()


def filter_quiality():
    """# TODO: Filter quality

    ## RESNET50 X CIFAR10
    """

    ekfac_lvl1 = "RF_resnet50_1_cifar10_ekfac_optim_hyper_saturation_200_gc_0_0.9_filter_quality_summary.csv"
    sgd_lvl1 = "RF_resnet50_1_cifar10_recording_200_no_ffcv_0.9_filter_quality_summary.csv"
    sam_lvl1 = "RF_resnet50_1_cifar10_sam_optim_saturation_200_gc_0_0.9_filter_quality_summary.csv"

    ekfac_lvl2 = "RF_resnet50_2_cifar10_ekfac_optim_hyper_saturation_200_gc_0_0.9_filter_quality_summary.csv"
    sgd_lvl2 = "RF_resnet50_2_cifar10_recording_200_no_ffcv_0.9_filter_quality_summary.csv"
    sam_lvl2 = "RF_resnet50_2_cifar10_sam_optim_saturation_200_gc_0_0.9_filter_quality_summary.csv"

    ekfac_lvl3 = "RF_resnet50_3_cifar10_ekfac_optim_hyper_saturation_200_gc_0_0.9_filter_quality_summary.csv"
    sgd_lvl3 = "RF_resnet50_3_cifar10_recording_200_no_ffcv_0.9_filter_quality_summary.csv"
    sam_lvl3 = "RF_resnet50_3_cifar10_sam_optim_saturation_200_gc_0_0.9_filter_quality_summary.csv"

    ekfac_lvl4 = "RF_resnet50_1_cifar10_ekfac_optim_hyper_saturation_200_gc_0_0.9_filter_quality_summary.csv"
    sgd_lvl4 = "RF_resnet50_4_cifar10_recording_200_no_ffcv_0.9_filter_quality_summary.csv"
    sam_lvl4 = "RF_resnet50_4_cifar10_sam_optim_saturation_200_gc_0_0.9_filter_quality_summary.csv"

    preamble = "inter_layer_pruning_results/"

    resnets_rfs_values

    df_level1_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl1}", delimiter=",")
    df_level1_ekfac["RF"] = [resnets_rfs_values[1]] * len(df_level1_ekfac)
    df_level2_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl2}", delimiter=",")
    df_level2_ekfac["RF"] = [resnets_rfs_values[2]] * len(df_level2_ekfac)
    df_level3_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl3}", delimiter=",")
    df_level3_ekfac["RF"] = [resnets_rfs_values[3]] * len(df_level3_ekfac)
    df_level4_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl4}", delimiter=",")
    df_level4_ekfac["RF"] = [resnets_rfs_values[4]] * len(df_level4_ekfac)

    all_ekfac = pd.concat([df_level1_ekfac, df_level2_ekfac, df_level3_ekfac, df_level4_ekfac])

    df_level1_sam = pd.read_csv(f"{preamble}{sam_lvl1}", delimiter=",")
    df_level1_sam["RF"] = [resnets_rfs_values[1]] * len(df_level1_sam)
    df_level2_sam = pd.read_csv(f"{preamble}{sam_lvl2}", delimiter=",")

    df_level2_sam["RF"] = [resnets_rfs_values[2]] * len(df_level2_sam)
    df_level3_sam = pd.read_csv(f"{preamble}{sam_lvl3}", delimiter=",")
    df_level3_sam["RF"] = [resnets_rfs_values[3]] * len(df_level3_sam)
    df_level4_sam = pd.read_csv(f"{preamble}{sam_lvl4}", delimiter=",")
    df_level4_sam["RF"] = [resnets_rfs_values[4]] * len(df_level4_sam)

    all_sam = pd.concat([df_level1_sam, df_level2_sam, df_level3_sam, df_level4_sam])

    df_level1_sgd = pd.read_csv(f"{preamble}{sgd_lvl1}", delimiter=",")
    df_level1_sgd["RF"] = [resnets_rfs_values[1]] * len(df_level1_sgd)
    df_level2_sgd = pd.read_csv(f"{preamble}{sgd_lvl2}", delimiter=",")
    df_level2_sgd["RF"] = [resnets_rfs_values[2]] * len(df_level2_sgd)
    df_level3_sgd = pd.read_csv(f"{preamble}{sgd_lvl3}", delimiter=",")
    df_level3_sgd["RF"] = [resnets_rfs_values[3]] * len(df_level3_sgd)
    df_level4_sgd = pd.read_csv(f"{preamble}{sgd_lvl4}", delimiter=",")
    df_level4_sgd["RF"] = [resnets_rfs_values[4]] * len(df_level4_sgd)

    all_sgd = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd])

    all_sgd["optimiser"] = ["SGD"] * len(all_sgd)
    all_sam["optimiser"] = ["ASAM"] * len(all_sam)
    all_ekfac["optimiser"] = ["EKFAC"] * len(all_ekfac)
    all_df = pd.concat([all_ekfac, all_sgd, all_sam])

    import matplotlib.pyplot as plt
    import seaborn as sns

    fgi, axs = plt.subplots(2, 2, figsize=(15, 10), layout="compressed")

    optimisers = ["SGD", "ASAM", "EKFAC"]
    rf_unique = all_df["RF"].unique()

    for i, ax in enumerate(axs.flat):
        current_df = all_df[all_df["RF"] == rf_unique[i]]

        # sns.boxplot(ax=ax,
        #     data=current_df, x="layer_name", y="variance_entropy",hue="optimiser",
        # )
        sns.scatterplot(ax=ax,
                        data=current_df, x="layer_name", y="variance_entropy", hue="optimiser", style="optimiser"
                        )
        ax.tick_params(labelrotation=90)
        ax.set_xlabel('Layer Name')
        ax.set_ylabel('Entropy Variance (Filter diversity)')
        ax.set_title(f"RF={rf_unique[i]}")
        ax.grid(ls="--")

    # plt.tight_layout()
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/filter_quality_resnet50_cifar10s.pdf")
    plt.close()

    """## VGG19 X CIFAR10"""

    ekfac_lvl1 = "RF_vgg19_1_cifar10_ekfac_optim_hyper_saturation_200_gc_0_0.9_filter_quality_summary.csv"
    sgd_lvl1 = "RF_vgg19_1_cifar10_recording_200_no_ffcv_0.9_filter_quality_summary.csv"
    sam_lvl1 = "RF_vgg19_1_cifar10_sam_optim_saturation_200_gc_0_0.9_filter_quality_summary.csv"

    ekfac_lvl2 = "RF_vgg19_2_cifar10_ekfac_optim_hyper_saturation_200_gc_0_0.9_filter_quality_summary.csv"
    sgd_lvl2 = "RF_vgg19_2_cifar10_recording_200_no_ffcv_0.9_filter_quality_summary.csv"
    sam_lvl2 = "RF_vgg19_2_cifar10_sam_optim_saturation_200_gc_0_0.9_filter_quality_summary.csv"

    ekfac_lvl3 = "RF_vgg19_3_cifar10_ekfac_optim_hyper_saturation_200_gc_0_0.9_filter_quality_summary.csv"
    sgd_lvl3 = "RF_vgg19_3_cifar10_recording_200_no_ffcv_0.9_filter_quality_summary.csv"
    sam_lvl3 = "RF_vgg19_3_cifar10_sam_optim_saturation_200_gc_0_0.9_filter_quality_summary.csv"

    ekfac_lvl4 = "RF_vgg19_1_cifar10_ekfac_optim_hyper_saturation_200_gc_0_0.9_filter_quality_summary.csv"
    sgd_lvl4 = "RF_vgg19_4_cifar10_recording_200_no_ffcv_0.9_filter_quality_summary.csv"
    sam_lvl4 = "RF_vgg19_4_cifar10_sam_optim_saturation_200_gc_0_0.9_filter_quality_summary.csv"

    preamble = "inter_layer_pruning_results/"

    df_level1_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl1}", delimiter=",")
    df_level1_ekfac["RF"] = [vgg_rfs[1]] * len(df_level1_ekfac)
    df_level2_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl2}", delimiter=",")
    df_level2_ekfac["RF"] = [vgg_rfs[2]] * len(df_level2_ekfac)
    df_level3_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl3}", delimiter=",")
    df_level3_ekfac["RF"] = [vgg_rfs[3]] * len(df_level3_ekfac)
    df_level4_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl4}", delimiter=",")
    df_level4_ekfac["RF"] = [vgg_rfs[4]] * len(df_level4_ekfac)

    all_ekfac = pd.concat([df_level1_ekfac, df_level2_ekfac, df_level3_ekfac, df_level4_ekfac])

    df_level1_sam = pd.read_csv(f"{preamble}{sam_lvl1}", delimiter=",")
    df_level1_sam["RF"] = [vgg_rfs[1]] * len(df_level1_sam)
    df_level2_sam = pd.read_csv(f"{preamble}{sam_lvl2}", delimiter=",")

    df_level2_sam["RF"] = [vgg_rfs[2]] * len(df_level2_sam)
    df_level3_sam = pd.read_csv(f"{preamble}{sam_lvl3}", delimiter=",")
    df_level3_sam["RF"] = [vgg_rfs[3]] * len(df_level3_sam)
    df_level4_sam = pd.read_csv(f"{preamble}{sam_lvl4}", delimiter=",")
    df_level4_sam["RF"] = [vgg_rfs[4]] * len(df_level4_sam)

    all_sam = pd.concat([df_level1_sam, df_level2_sam, df_level3_sam, df_level4_sam])

    df_level1_sgd = pd.read_csv(f"{preamble}{sgd_lvl1}", delimiter=",")
    df_level1_sgd["RF"] = [vgg_rfs[1]] * len(df_level1_sgd)
    df_level2_sgd = pd.read_csv(f"{preamble}{sgd_lvl2}", delimiter=",")
    df_level2_sgd["RF"] = [vgg_rfs[2]] * len(df_level2_sgd)
    df_level3_sgd = pd.read_csv(f"{preamble}{sgd_lvl3}", delimiter=",")
    df_level3_sgd["RF"] = [vgg_rfs[3]] * len(df_level3_sgd)
    df_level4_sgd = pd.read_csv(f"{preamble}{sgd_lvl4}", delimiter=",")
    df_level4_sgd["RF"] = [vgg_rfs[4]] * len(df_level4_sgd)

    all_sgd = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd])

    all_sgd["optimiser"] = ["SGD"] * len(all_sgd)
    all_sam["optimiser"] = ["ASAM"] * len(all_sam)
    all_ekfac["optimiser"] = ["EKFAC"] * len(all_ekfac)

    all_df = pd.concat([all_ekfac, all_sgd, all_sam])

    import seaborn as sns
    import matplotlib.pyplot as plt
    axs = sns.relplot(
        data=all_df, x="layer_name", y="variance_entropy", col="optimiser", hue="optimiser", style="RF",
        kind="scatter", s=25
    )
    # plt.xticks(rotation=90)
    axs.set_ylabel('Entropy Variance (Filter Diversity)')
    # sns.barplot(data=all_df,x="layer_name",y="variance_entropy",hue="optimiser",errorbar="ci")
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/filter_quality_vgg19_cifar10.pdf")
    plt.close()

    import matplotlib.pyplot as plt
    import seaborn as sns

    fgi, axs = plt.subplots(2, 2, figsize=(15, 10), layout="compressed")

    optimisers = ["SGD", "ASAM", "EKFAC"]
    rf_unique = all_df["RF"].unique()

    for i, ax in enumerate(axs.flat):
        current_df = all_df[all_df["RF"] == rf_unique[i]]

        # sns.boxplot(ax=ax,
        #     data=current_df, x="layer_name", y="variance_entropy",hue="optimiser",
        # )
        sns.scatterplot(ax=ax,
                        data=current_df, x="layer_name", y="variance_entropy", hue="optimiser", style="optimiser"
                        )
        ax.tick_params(labelrotation=90)
        ax.set_xlabel('Layer Name')
        # ax.set_ylabel('Variance Entropy (Filter diversity)')
        ax.set_ylabel('Entropy Variance (Filter Diversity)')
        ax.set_title(f"RF={rf_unique[i]}")
        ax.grid(ls="--")

    # plt.tight_layout()

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/filter_quality_vgg19_cifar10.pdf")
    plt.close()

    """### Orthogonality"""

    import matplotlib.pyplot as plt
    import seaborn as sns

    fgi, axs = plt.subplots(2, 2, figsize=(15, 10), layout="compressed")

    optimisers = ["SGD", "ASAM", "EKFAC"]
    rf_unique = all_df["RF"].unique()

    for i, ax in enumerate(axs.flat):
        current_df = all_df[all_df["RF"] == rf_unique[i]]

        # sns.boxplot(ax=ax,
        #     data=current_df, x="layer_name", y="variance_entropy",hue="optimiser",
        # )
        sns.scatterplot(ax=ax,
                        data=current_df, x="layer_name", y="orthogonality", hue="optimiser", style="optimiser"
                        )
        ax.tick_params(labelrotation=90)
        ax.set_xlabel('Layer Name')
        ax.set_ylabel('Orthogonality')
        ax.set_title(f"RF={rf_unique[i]}")

    # plt.tight_layout()
    plt.close()

    """### Variance norm"""

    import matplotlib.pyplot as plt
    import seaborn as sns

    fgi, axs = plt.subplots(2, 2, figsize=(15, 10), layout="compressed")

    optimisers = ["SGD", "ASAM", "EKFAC"]
    rf_unique = all_df["RF"].unique()

    for i, ax in enumerate(axs.flat):
        current_df = all_df[all_df["RF"] == rf_unique[i]]

        # sns.boxplot(ax=ax,
        #     data=current_df, x="layer_name", y="variance_entropy",hue="optimiser",
        # )
        sns.scatterplot(ax=ax,
                        data=current_df, x="layer_name", y="variance_entropy_norm", hue="optimiser", style="optimiser"
                        )
        ax.tick_params(labelrotation=90)
        ax.set_xlabel('Layer Name')
        ax.set_ylabel('Entropy Variance norm')
        ax.set_title(f"RF={rf_unique[i]}")

    # plt.tight_layout()
    plt.close()

    """## RESNET25xSmall ImageNet Detailed"""

    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # ekfac_lvl1="RF_vgg19_1_small_imagenet_ekfac_optim_hyper_saturation_200_gc_0_0.9_filter_quality_summary.csv"
    sgd_lvl3 = "RF_resnet25_small_5_small_imagenet_sgd_100_res_224_no_ffcv_0.9_filter_quality_summary.csv"
    # sam_lvl1="RF_vgg19_1_small_imagenet_sam_optim_saturation_200_gc_0_0.9_filter_quality_summary.csv"

    # ekfac_lvl2="RF_vgg19_2_small_imagenet_ekfac_optim_hyper_saturation_200_gc_0_0.9_filter_quality_summary.csv"
    sgd_lvl4 = "RF_resnet25_small_6_small_imagenet_sgd_100_res_224_no_ffcv_0.9_filter_quality_summary.csv"
    # sam_lvl2= "RF_vgg19_2_small_imagenet_sam_optim_saturation_200_gc_0_0.9_filter_quality_summary.csv"

    # ekfac_lvl3="RF_vgg19_3_small_imagenet_ekfac_optim_hyper_saturation_200_gc_0_0.9_filter_quality_summary.csv"
    sgd_lvl5 = "RF_resnet25_small_7_small_imagenet_sgd_100_res_224_no_ffcv_0.9_filter_quality_summary.csv"
    # sam_lvl3= "RF_vgg19_3_small_imagenet_sam_optim_saturation_200_gc_0_0.9_filter_quality_summary.csv"

    # ekfac_lvl4="RF_vgg19_1_small_imagenet_ekfac_optim_hyper_saturation_200_gc_0_0.9_filter_quality_summary.csv"
    sgd_lvl6 = "RF_resnet25_small_8_small_imagenet_sgd_100_res_224_no_ffcv_0.9_filter_quality_summary.csv"
    # sam_lvl4= "RF_vgg19_4_small_imagenet_sam_optim_saturation_200_gc_0_0.9_filter_quality_summary.csv"

    sgd_lvl7 = "RF_resnet25_small_10_small_imagenet_sgd_100_res_224_no_ffcv_0.9_filter_quality_summary.csv"
    sgd_lvl8 = "RF_resnet25_small_11_small_imagenet_sgd_100_res_224_no_ffcv_0.9_filter_quality_summary.csv"
    sgd_lvl9 = "RF_resnet25_small_12_small_imagenet_sgd_100_res_224_no_ffcv_0.9_filter_quality_summary.csv"
    sgd_lvl10 = "RF_resnet25_small_13_small_imagenet_sgd_100_res_224_no_ffcv_0.9_filter_quality_summary.csv"

    preamble = "filter_quality_results/small_imagenet/"

    # df_level1_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl1}",delimiter=",")
    # df_level1_ekfac["RF"]=[vgg_rfs[1]]*len(df_level1_ekfac)
    # df_level2_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl2}",delimiter=",")
    # df_level2_ekfac["RF"]=[vgg_rfs[2]]*len(df_level2_ekfac)
    # df_level3_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl3}",delimiter=",")
    # df_level3_ekfac["RF"]=[vgg_rfs[3]]*len(df_level3_ekfac)
    # df_level4_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl4}",delimiter=",")
    # df_level4_ekfac["RF"]=[vgg_rfs[4]]*len(df_level4_ekfac)

    # all_ekfac=pd.concat([df_level1_ekfac,df_level2_ekfac,df_level3_ekfac,df_level4_ekfac])

    # df_level1_sam = pd.read_csv(f"{preamble}{sam_lvl1}",delimiter=",")
    # df_level1_sam["RF"]=[resnets_rfs[1]]*len(df_level1_sam)
    # df_level2_sam = pd.read_csv(f"{preamble}{sam_lvl2}",delimiter=",")

    # df_level2_sam["RF"]=[resnets_rfs[2]]*len(df_level2_sam)
    # df_level3_sam = pd.read_csv(f"{preamble}{sam_lvl3}",delimiter=",")
    # df_level3_sam["RF"]=[resnets_rfs[3]]*len(df_level3_sam)
    # df_level4_sam = pd.read_csv(f"{preamble}{sam_lvl4}",delimiter=",")
    # df_level4_sam["RF"]=[resnets_rfs[4]]*len(df_level4_sam)

    # all_sam=pd.concat([df_level1_sam,df_level2_sam,df_level3_sam,df_level4_sam])

    df_level3_sgd = pd.read_csv(f"{preamble}{sgd_lvl3}", delimiter=",")
    df_level3_sgd["RF"] = [resnets_rfs[5]] * len(df_level3_sgd)
    df_level4_sgd = pd.read_csv(f"{preamble}{sgd_lvl4}", delimiter=",")
    df_level4_sgd["RF"] = [resnets_rfs[6]] * len(df_level4_sgd)
    df_level5_sgd = pd.read_csv(f"{preamble}{sgd_lvl5}", delimiter=",")
    df_level5_sgd["RF"] = [resnets_rfs[7]] * len(df_level5_sgd)
    df_level6_sgd = pd.read_csv(f"{preamble}{sgd_lvl6}", delimiter=",")
    df_level6_sgd["RF"] = [resnets_rfs[8]] * len(df_level6_sgd)
    df_level7_sgd = pd.read_csv(f"{preamble}{sgd_lvl7}", delimiter=",")
    df_level7_sgd["RF"] = [resnets_rfs[10]] * len(df_level7_sgd)
    df_level8_sgd = pd.read_csv(f"{preamble}{sgd_lvl8}", delimiter=",")
    df_level8_sgd["RF"] = [resnets_rfs[11]] * len(df_level8_sgd)
    df_level9_sgd = pd.read_csv(f"{preamble}{sgd_lvl9}", delimiter=",")
    df_level9_sgd["RF"] = [resnets_rfs[12]] * len(df_level9_sgd)
    df_level10_sgd = pd.read_csv(f"{preamble}{sgd_lvl10}", delimiter=",")
    df_level10_sgd["RF"] = [resnets_rfs[13]] * len(df_level10_sgd)

    all_sgd = pd.concat(
        [df_level3_sgd, df_level4_sgd, df_level5_sgd, df_level6_sgd, df_level7_sgd, df_level8_sgd, df_level9_sgd,
         df_level10_sgd])

    all_sgd["optimiser"] = ["SGD"] * len(all_sgd)

    """
    ### Variance clean"""

    import matplotlib.pyplot as plt
    import seaborn as sns

    fig, ax = plt.subplots(1, 1, figsize=(15, 10), layout="compressed")

    optimisers = ["SGD", "ASAM", "EKFAC"]
    rf_unique = all_sgd["RF"].unique()

    # for i,ax in enumerate(axs.flat):

    #   current_df=all_df[all_df["RF"]==rf_unique[i]]

    #   # sns.boxplot(ax=ax,
    #   #     data=current_df, x="layer_name", y="variance_entropy",hue="optimiser",
    #   # )
    #   sns.scatterplot(ax=ax,
    #       data=current_df, x="layer_name", y="variance_entropy",hue="RF",style="RF"
    #   )
    #   ax.tick_params(labelrotation=90)
    #   ax.set_xlabel('Layer Name')
    #   ax.set_ylabel('Etropy Varince (Filter Diversity)')
    #   ax.set_title(f"RF={rf_unique[i]}")

    sns.boxplot(ax=ax,
                data=all_sgd, x="layer_name", y="variance_entropy_clean", hue="RF", legend="full", palette="deep"
                )
    ax.tick_params(labelrotation=90)
    ax.set_xlabel('Layer Name')
    # ax.set_ylabel('Entropy Variance (Filter Diversity)')
    ax.set_ylabel('Entropy Variance clean (Filter Diversity)')
    # ax.set_title(f"RF={rf_unique[i]}")
    # plt.tight_layout()
    plt.close()

    """#### Variance clean Norm"""

    import matplotlib.pyplot as plt
    import seaborn as sns

    fig, ax = plt.subplots(1, 1, figsize=(15, 10), layout="compressed")

    optimisers = ["SGD", "ASAM", "EKFAC"]
    rf_unique = all_sgd["RF"].unique()

    # for i,ax in enumerate(axs.flat):

    #   current_df=all_df[all_df["RF"]==rf_unique[i]]

    #   # sns.boxplot(ax=ax,
    #   #     data=current_df, x="layer_name", y="variance_entropy",hue="optimiser",
    #   # )
    #   sns.scatterplot(ax=ax,
    #       data=current_df, x="layer_name", y="variance_entropy",hue="RF",style="RF"
    #   )
    #   ax.tick_params(labelrotation=90)
    #   ax.set_xlabel('Layer Name')
    #   ax.set_ylabel('Etropy Varince (Filter Diversity)')
    #   ax.set_title(f"RF={rf_unique[i]}")

    sns.boxplot(ax=ax,
                data=all_sgd, x="layer_name", y="variance_entropy_clean_norm", hue="RF", legend="full", palette="deep"
                )
    ax.tick_params(labelrotation=90)
    ax.set_xlabel('Layer Name')
    # ax.set_ylabel('Entropy Variance (Filter Diversity)')
    ax.set_ylabel('Entropy Variance clean norm (Filter Diversity)')
    # ax.set_title(f"RF={rf_unique[i]}")
    # plt.tight_layout()
    plt.close()

    """### Sparsity"""

    import matplotlib.pyplot as plt
    import seaborn as sns

    fig, ax = plt.subplots(1, 1, figsize=(15, 10), layout="compressed")

    optimisers = ["SGD", "ASAM", "EKFAC"]
    rf_unique = all_sgd["RF"].unique()

    # for i,ax in enumerate(axs.flat):

    #   current_df=all_df[all_df["RF"]==rf_unique[i]]

    #   # sns.boxplot(ax=ax,
    #   #     data=current_df, x="layer_name", y="variance_entropy",hue="optimiser",
    #   # )
    #   sns.scatterplot(ax=ax,
    #       data=current_df, x="layer_name", y="variance_entropy",hue="RF",style="RF"
    #   )
    #   ax.tick_params(labelrotation=90)
    #   ax.set_xlabel('Layer Name')
    #   ax.set_ylabel('Etropy Varince (Filter Diversity)')
    #   ax.set_title(f"RF={rf_unique[i]}")

    sns.boxplot(ax=ax,
                data=all_sgd, x="layer_name", y="sparsity", hue="RF", legend="full", palette="deep"
                )
    ax.tick_params(labelrotation=90)
    ax.set_xlabel('Layer Name')
    # ax.set_ylabel('Entropy Variance (Filter Diversity)')
    ax.set_ylabel('Sparsity')
    # ax.set_title(f"RF={rf_unique[i]}")
    # plt.tight_layout()
    plt.close()

    """### Variance"""

    import matplotlib.pyplot as plt
    import seaborn as sns

    fig, ax = plt.subplots(1, 1, figsize=(15, 10), layout="compressed")

    optimisers = ["SGD", "ASAM", "EKFAC"]
    rf_unique = all_sgd["RF"].unique()

    # for i,ax in enumerate(axs.flat):

    #   current_df=all_df[all_df["RF"]==rf_unique[i]]

    #   # sns.boxplot(ax=ax,
    #   #     data=current_df, x="layer_name", y="variance_entropy",hue="optimiser",
    #   # )
    #   sns.scatterplot(ax=ax,
    #       data=current_df, x="layer_name", y="variance_entropy",hue="RF",style="RF"
    #   )
    #   ax.tick_params(labelrotation=90)
    #   ax.set_xlabel('Layer Name')
    #   ax.set_ylabel('Etropy Varince (Filter Diversity)')
    #   ax.set_title(f"RF={rf_unique[i]}")

    sns.boxplot(ax=ax,
                data=all_sgd, x="layer_name", y="variance_entropy", hue="RF", legend="full", palette="deep"
                )
    ax.tick_params(labelrotation=90)
    ax.set_xlabel('Layer Name')
    ax.grid(ls="--")
    # ax.set_ylabel('Entropy Variance (Filter Diversity)')
    ax.set_ylabel('Entropy Variance (Filter Diversity)')
    # ax.set_title(f"RF={rf_unique[i]}")
    # plt.tight_layout()
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/filter_quality_resnet25_small_imagenet.pdf")
    plt.close()

    """#### Variance norm"""

    import matplotlib.pyplot as plt
    import seaborn as sns

    fig, ax = plt.subplots(1, 1, figsize=(15, 10), layout="compressed")

    optimisers = ["SGD", "ASAM", "EKFAC"]
    rf_unique = all_sgd["RF"].unique()

    # for i,ax in enumerate(axs.flat):

    #   current_df=all_df[all_df["RF"]==rf_unique[i]]

    #   # sns.boxplot(ax=ax,
    #   #     data=current_df, x="layer_name", y="variance_entropy",hue="optimiser",
    #   # )
    #   sns.scatterplot(ax=ax,
    #       data=current_df, x="layer_name", y="variance_entropy",hue="RF",style="RF"
    #   )
    #   ax.tick_params(labelrotation=90)
    #   ax.set_xlabel('Layer Name')
    #   ax.set_ylabel('Etropy Varince (Filter Diversity)')
    #   ax.set_title(f"RF={rf_unique[i]}")

    sns.boxplot(ax=ax,

                data=all_sgd, x="layer_name", y="variance_entropy_norm", hue="RF", legend="full", palette="deep"

                )
    ax.tick_params(labelrotation=90)
    ax.set_xlabel('Layer Name')
    # ax.set_ylabel('Entropy Variance (Filter Diversity)')
    ax.set_ylabel('Entropy Variance Norm (Filter Diversity)')
    # ax.set_title(f"RF={rf_unique[i]}")
    # plt.tight_layout()
    plt.close()

    """### Orthogonality"""

    import matplotlib.pyplot as plt
    import seaborn as sns
    fig, ax = plt.subplots(1, 1, figsize=(15, 10), layout="compressed")

    # sns.scatterplot(ax=ax,
    # data=all_sgd, x="layer_name", y="orthogonality",hue="RF",style="RF",palette="deep"

    # )

    sns.boxplot(ax=ax,
                data=all_sgd, x="layer_name", y="orthogonality", hue="RF", legend="full", palette="deep"
                )
    ax.tick_params(labelrotation=90)
    ax.set_xlabel('Layer Name')
    ax.set_ylabel('Orthogonality')
    # ax.set_title(f"")

    # plt.tight_layout()
    plt.close()

    """## Whole model

    ### Variance
    """

    import matplotlib.pyplot as plt
    import seaborn as sns

    fig, ax = plt.subplots(1, 1, figsize=(15, 10), layout="compressed")

    optimisers = ["SGD", "ASAM", "EKFAC"]
    rf_unique = all_sgd["RF"].unique()

    # for i,ax in enumerate(axs.flat):

    #   current_df=all_df[all_df["RF"]==rf_unique[i]]

    #   # sns.boxplot(ax=ax,
    #   #     data=current_df, x="layer_name", y="variance_entropy",hue="optimiser",
    #   # )
    #   sns.scatterplot(ax=ax,
    #       data=current_df, x="layer_name", y="variance_entropy",hue="RF",style="RF"
    #   )
    #   ax.tick_params(labelrotation=90)
    #   ax.set_xlabel('Layer Name')
    #   ax.set_ylabel('Etropy Varince (Filter Diversity)')
    #   ax.set_title(f"RF={rf_unique[i]}")

    sns.boxplot(ax=ax,

                data=all_sgd, x="RF", y="variance_entropy", legend="full", palette="deep"

                )
    ax.tick_params(labelrotation=90)
    ax.set_xlabel('Receptive field')
    # ax.set_ylabel('Entropy Variance (Filter Diversity)')
    ax.set_ylabel('Entropy Variance (Filter Diversity)')
    # ax.set_title(f"RF={rf_unique[i]}")
    # plt.tight_layout()
    plt.close()

    """### Variance Clean"""

    import matplotlib.pyplot as plt
    import seaborn as sns

    fig, ax = plt.subplots(1, 1, figsize=(15, 10), layout="compressed")

    optimisers = ["SGD", "ASAM", "EKFAC"]
    rf_unique = all_sgd["RF"].unique()

    # for i,ax in enumerate(axs.flat):

    #   current_df=all_df[all_df["RF"]==rf_unique[i]]

    #   # sns.boxplot(ax=ax,
    #   #     data=current_df, x="layer_name", y="variance_entropy",hue="optimiser",
    #   # )
    #   sns.scatterplot(ax=ax,
    #       data=current_df, x="layer_name", y="variance_entropy",hue="RF",style="RF"
    #   )
    #   ax.tick_params(labelrotation=90)
    #   ax.set_xlabel('Layer Name')
    #   ax.set_ylabel('Etropy Varince (Filter Diversity)')
    #   ax.set_title(f"RF={rf_unique[i]}")

    sns.boxplot(ax=ax,
                data=all_sgd, x="RF", y="variance_entropy", legend="full"  # ,palette="deep"
                )
    ax.tick_params(labelrotation=90)

    ax.set_xlabel('Receptive Field')

    # ax.set_ylabel('Entropy Variance (Filter Diversity)')

    ax.set_ylabel('Entropy Variance Clean (Filter Diversity)')
    # ax.set_title(f"RF={rf_unique[i]}")
    # plt.tight_layout()
    plt.close()

    """### Orthogonality"""

    import matplotlib.pyplot as plt
    import seaborn as sns
    fig, ax = plt.subplots(1, 1, figsize=(15, 10), layout="compressed")

    # sns.scatterplot(ax=ax,
    # data=all_sgd, x="layer_name", y="orthogonality",hue="RF",style="RF",palette="deep"

    # )

    sns.boxplot(ax=ax,
                data=all_sgd, x="RF", y="orthogonality", legend="full"  # ,palette="deep"
                )
    ax.tick_params(labelrotation=90)
    ax.set_xlabel('Receptive Field')
    ax.set_ylabel('Orthogonality')
    # ax.set_title(f"")

    # plt.tight_layout()
    plt.close()

    """### Sparsity"""

    import matplotlib.pyplot as plt
    import seaborn as sns

    fig, ax = plt.subplots(1, 1, figsize=(15, 10), layout="compressed")

    optimisers = ["SGD", "ASAM", "EKFAC"]
    rf_unique = all_sgd["RF"].unique()

    # for i,ax in enumerate(axs.flat):

    #   current_df=all_df[all_df["RF"]==rf_unique[i]]

    #   # sns.boxplot(ax=ax,
    #   #     data=current_df, x="layer_name", y="variance_entropy",hue="optimiser",
    #   # )
    #   sns.scatterplot(ax=ax,
    #       data=current_df, x="layer_name", y="variance_entropy",hue="RF",style="RF"
    #   )
    #   ax.tick_params(labelrotation=90)
    #   ax.set_xlabel('Layer Name')
    #   ax.set_ylabel('Etropy Varince (Filter Diversity)')
    #   ax.set_title(f"RF={rf_unique[i]}")

    sns.boxplot(ax=ax,
                data=all_sgd, x="RF", y="sparsity", legend="full"  # ,palette="deep"
                )
    ax.tick_params(labelrotation=90)
    ax.set_xlabel('Receptive Field')
    # ax.set_ylabel('Entropy Variance (Filter Diversity)')
    ax.set_ylabel('Sparsity')
    # ax.set_title(f"RF={rf_unique[i]}")
    # plt.tight_layout()
    plt.close()

    """
    ## RESNET25xSmall ImageNet Resized"""

    # ekfac_lvl1="RF_vgg19_1_small_imagenet_ekfac_optim_hyper_saturation_200_gc_0_0.9_filter_quality_summary.csv"
    sgd_lvl3 = "RF_resnet25_small_5_small_imagenet_sgd_100_res_224_no_ffcv_0.9_filter_quality_summary.csv"
    # sam_lvl1="RF_vgg19_1_small_imagenet_sam_optim_saturation_200_gc_0_0.9_filter_quality_summary.csv"

    # ekfac_lvl2="RF_vgg19_2_small_imagenet_ekfac_optim_hyper_saturation_200_gc_0_0.9_filter_quality_summary.csv"
    sgd_lvl4 = "RF_resnet25_small_6_small_imagenet_sgd_100_res_224_no_ffcv_0.9_filter_quality_summary.csv"
    # sam_lvl2= "RF_vgg19_2_small_imagenet_sam_optim_saturation_200_gc_0_0.9_filter_quality_summary.csv"

    # ekfac_lvl3="RF_vgg19_3_small_imagenet_ekfac_optim_hyper_saturation_200_gc_0_0.9_filter_quality_summary.csv"
    sgd_lvl5 = "RF_resnet25_small_7_small_imagenet_sgd_100_res_224_no_ffcv_0.9_filter_quality_summary.csv"
    # sam_lvl3= "RF_vgg19_3_small_imagenet_sam_optim_saturation_200_gc_0_0.9_filter_quality_summary.csv"

    # ekfac_lvl4="RF_vgg19_1_small_imagenet_ekfac_optim_hyper_saturation_200_gc_0_0.9_filter_quality_summary.csv"
    sgd_lvl6 = "RF_resnet25_small_8_small_imagenet_sgd_100_res_224_no_ffcv_0.9_filter_quality_summary.csv"
    # sam_lvl4= "RF_vgg19_4_small_imagenet_sam_optim_saturation_200_gc_0_0.9_filter_quality_summary.csv"

    sgd_lvl7 = "RF_resnet25_small_10_small_imagenet_sgd_100_res_224_no_ffcv_0.9_filter_quality_summary.csv"
    sgd_lvl8 = "RF_resnet25_small_11_small_imagenet_sgd_100_res_224_no_ffcv_0.9_filter_quality_summary.csv"
    sgd_lvl9 = "RF_resnet25_small_12_small_imagenet_sgd_100_res_224_no_ffcv_0.9_filter_quality_summary.csv"
    sgd_lvl10 = "RF_resnet25_small_13_small_imagenet_sgd_100_res_224_no_ffcv_0.9_filter_quality_summary.csv"

    preamble = "filter_quality_results/small_imagenet_resized/"

    # df_level1_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl1}",delimiter=",")
    # df_level1_ekfac["RF"]=[vgg_rfs[1]]*len(df_level1_ekfac)
    # df_level2_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl2}",delimiter=",")
    # df_level2_ekfac["RF"]=[vgg_rfs[2]]*len(df_level2_ekfac)
    # df_level3_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl3}",delimiter=",")
    # df_level3_ekfac["RF"]=[vgg_rfs[3]]*len(df_level3_ekfac)
    # df_level4_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl4}",delimiter=",")
    # df_level4_ekfac["RF"]=[vgg_rfs[4]]*len(df_level4_ekfac)

    # all_ekfac=pd.concat([df_level1_ekfac,df_level2_ekfac,df_level3_ekfac,df_level4_ekfac])

    # df_level1_sam = pd.read_csv(f"{preamble}{sam_lvl1}",delimiter=",")
    # df_level1_sam["RF"]=[resnets_rfs[1]]*len(df_level1_sam)
    # df_level2_sam = pd.read_csv(f"{preamble}{sam_lvl2}",delimiter=",")

    # df_level2_sam["RF"]=[resnets_rfs[2]]*len(df_level2_sam)
    # df_level3_sam = pd.read_csv(f"{preamble}{sam_lvl3}",delimiter=",")
    # df_level3_sam["RF"]=[resnets_rfs[3]]*len(df_level3_sam)
    # df_level4_sam = pd.read_csv(f"{preamble}{sam_lvl4}",delimiter=",")
    # df_level4_sam["RF"]=[resnets_rfs[4]]*len(df_level4_sam)

    # all_sam=pd.concat([df_level1_sam,df_level2_sam,df_level3_sam,df_level4_sam])

    df_level3_sgd = pd.read_csv(f"{preamble}{sgd_lvl3}", delimiter=",")
    df_level3_sgd["RF"] = [resnets_rfs[5]] * len(df_level3_sgd)
    df_level4_sgd = pd.read_csv(f"{preamble}{sgd_lvl4}", delimiter=",")
    df_level4_sgd["RF"] = [resnets_rfs[6]] * len(df_level4_sgd)
    df_level5_sgd = pd.read_csv(f"{preamble}{sgd_lvl5}", delimiter=",")
    df_level5_sgd["RF"] = [resnets_rfs[7]] * len(df_level5_sgd)
    df_level6_sgd = pd.read_csv(f"{preamble}{sgd_lvl6}", delimiter=",")
    df_level6_sgd["RF"] = [resnets_rfs[8]] * len(df_level6_sgd)
    df_level7_sgd = pd.read_csv(f"{preamble}{sgd_lvl7}", delimiter=",")
    df_level7_sgd["RF"] = [resnets_rfs[10]] * len(df_level7_sgd)
    df_level8_sgd = pd.read_csv(f"{preamble}{sgd_lvl8}", delimiter=",")
    df_level8_sgd["RF"] = [resnets_rfs[11]] * len(df_level8_sgd)
    df_level9_sgd = pd.read_csv(f"{preamble}{sgd_lvl9}", delimiter=",")
    df_level9_sgd["RF"] = [resnets_rfs[12]] * len(df_level9_sgd)
    df_level10_sgd = pd.read_csv(f"{preamble}{sgd_lvl10}", delimiter=",")
    df_level10_sgd["RF"] = [resnets_rfs[13]] * len(df_level10_sgd)

    all_sgd = pd.concat(
        [df_level3_sgd, df_level4_sgd, df_level5_sgd, df_level6_sgd, df_level7_sgd, df_level8_sgd, df_level9_sgd,
         df_level10_sgd])

    all_sgd["optimiser"] = ["SGD"] * len(all_sgd)

    import matplotlib.pyplot as plt
    import seaborn as sns

    fig, ax = plt.subplots(1, 1, figsize=(15, 10), layout="compressed")

    optimisers = ["SGD", "ASAM", "EKFAC"]
    rf_unique = all_sgd["RF"].unique()

    # for i,ax in enumerate(axs.flat):

    #   current_df=all_df[all_df["RF"]==rf_unique[i]]

    #   # sns.boxplot(ax=ax,
    #   #     data=current_df, x="layer_name", y="variance_entropy",hue="optimiser",
    #   # )
    #   sns.scatterplot(ax=ax,
    #       data=current_df, x="layer_name", y="variance_entropy",hue="RF",style="RF"
    #   )
    #   ax.tick_params(labelrotation=90)
    #   ax.set_xlabel('Layer Name')
    #   ax.set_ylabel('Etropy Varince (Filter Diversity)')
    #   ax.set_title(f"RF={rf_unique[i]}")

    sns.boxplot(ax=ax,
                data=all_sgd, x="layer_name", y="variance_entropy", hue="RF", legend="full", palette="deep"
                )
    ax.tick_params(labelrotation=90)
    ax.set_xlabel('Layer Name')
    ax.set_ylabel('Entropy Varince (Filter Diversity)')
    # ax.set_title(f"RF={rf_unique[i]}")
    # plt.tight_layout()
    plt.close()

    """## Small resnet x Small ImageNet"""

    # ekfac_lvl1="RF_vgg19_1_small_imagenet_ekfac_optim_hyper_saturation_200_gc_0_0.9_filter_quality_summary.csv"
    sgd_lvl3 = "RF_resnet_small_3_small_imagenet_recording_200_0.9_filter_quality_summary.csv"
    # sam_lvl1="RF_vgg19_1_small_imagenet_sam_optim_saturation_200_gc_0_0.9_filter_quality_summary.csv"

    # ekfac_lvl2="RF_vgg19_2_small_imagenet_ekfac_optim_hyper_saturation_200_gc_0_0.9_filter_quality_summary.csv"
    sgd_lvl4 = "RF_resnet_small_4_small_imagenet_recording_200_0.9_filter_quality_summary.csv"
    # sam_lvl2= "RF_vgg19_2_small_imagenet_sam_optim_saturation_200_gc_0_0.9_filter_quality_summary.csv"

    # ekfac_lvl3="RF_vgg19_3_small_imagenet_ekfac_optim_hyper_saturation_200_gc_0_0.9_filter_quality_summary.csv"
    sgd_lvl5 = "RF_resnet_small_5_small_imagenet_recording_200_0.9_filter_quality_summary.csv"
    # sam_lvl3= "RF_vgg19_3_small_imagenet_sam_optim_saturation_200_gc_0_0.9_filter_quality_summary.csv"

    # ekfac_lvl4="RF_vgg19_1_small_imagenet_ekfac_optim_hyper_saturation_200_gc_0_0.9_filter_quality_summary.csv"
    sgd_lvl6 = "RF_resnet_small_6_small_imagenet_recording_200_0.9_filter_quality_summary.csv"
    # sam_lvl4= "RF_vgg19_4_small_imagenet_sam_optim_saturation_200_gc_0_0.9_filter_quality_summary.csv"

    sgd_lvl7 = "RF_resnet_small_7_small_imagenet_recording_200_0.9_filter_quality_summary.csv"
    sgd_lvl8 = "RF_resnet_small_8_small_imagenet_recording_200_0.9_filter_quality_summary.csv"
    sgd_lvl9 = "RF_resnet_small_9_small_imagenet_recording_200_0.9_filter_quality_summary.csv"
    sgd_lvl10 = "RF_resnet_small_10_small_imagenet_recording_200_0.9_filter_quality_summary.csv"

    preamble = "inter_layer_pruning_results/"

    # df_level1_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl1}",delimiter=",")
    # df_level1_ekfac["RF"]=[vgg_rfs[1]]*len(df_level1_ekfac)
    # df_level2_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl2}",delimiter=",")
    # df_level2_ekfac["RF"]=[vgg_rfs[2]]*len(df_level2_ekfac)
    # df_level3_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl3}",delimiter=",")
    # df_level3_ekfac["RF"]=[vgg_rfs[3]]*len(df_level3_ekfac)
    # df_level4_ekfac = pd.read_csv(f"{preamble}{ekfac_lvl4}",delimiter=",")
    # df_level4_ekfac["RF"]=[vgg_rfs[4]]*len(df_level4_ekfac)

    # all_ekfac=pd.concat([df_level1_ekfac,df_level2_ekfac,df_level3_ekfac,df_level4_ekfac])

    # df_level1_sam = pd.read_csv(f"{preamble}{sam_lvl1}",delimiter=",")
    # df_level1_sam["RF"]=[small_resnets_rfs[1]]*len(df_level1_sam)
    # df_level2_sam = pd.read_csv(f"{preamble}{sam_lvl2}",delimiter=",")

    # df_level2_sam["RF"]=[small_resnets_rfs[2]]*len(df_level2_sam)
    # df_level3_sam = pd.read_csv(f"{preamble}{sam_lvl3}",delimiter=",")
    # df_level3_sam["RF"]=[small_resnets_rfs[3]]*len(df_level3_sam)
    # df_level4_sam = pd.read_csv(f"{preamble}{sam_lvl4}",delimiter=",")
    # df_level4_sam["RF"]=[small_resnets_rfs[4]]*len(df_level4_sam)

    # all_sam=pd.concat([df_level1_sam,df_level2_sam,df_level3_sam,df_level4_sam])

    df_level3_sgd = pd.read_csv(f"{preamble}{sgd_lvl3}", delimiter=",")
    df_level3_sgd["RF"] = [small_resnets_rfs[3]] * len(df_level3_sgd)
    df_level4_sgd = pd.read_csv(f"{preamble}{sgd_lvl4}", delimiter=",")
    df_level4_sgd["RF"] = [small_resnets_rfs[4]] * len(df_level4_sgd)
    df_level5_sgd = pd.read_csv(f"{preamble}{sgd_lvl5}", delimiter=",")
    df_level5_sgd["RF"] = [small_resnets_rfs[5]] * len(df_level5_sgd)
    df_level6_sgd = pd.read_csv(f"{preamble}{sgd_lvl6}", delimiter=",")
    df_level6_sgd["RF"] = [small_resnets_rfs[6]] * len(df_level6_sgd)
    df_level7_sgd = pd.read_csv(f"{preamble}{sgd_lvl7}", delimiter=",")
    df_level7_sgd["RF"] = [small_resnets_rfs[7]] * len(df_level7_sgd)
    df_level8_sgd = pd.read_csv(f"{preamble}{sgd_lvl8}", delimiter=",")
    df_level8_sgd["RF"] = [small_resnets_rfs[8]] * len(df_level8_sgd)
    df_level9_sgd = pd.read_csv(f"{preamble}{sgd_lvl9}", delimiter=",")
    df_level9_sgd["RF"] = [small_resnets_rfs[9]] * len(df_level9_sgd)
    df_level10_sgd = pd.read_csv(f"{preamble}{sgd_lvl10}", delimiter=",")
    df_level10_sgd["RF"] = [small_resnets_rfs[10]] * len(df_level10_sgd)

    all_sgd = pd.concat(
        [df_level3_sgd, df_level4_sgd, df_level5_sgd, df_level6_sgd, df_level7_sgd, df_level8_sgd, df_level9_sgd,
         df_level10_sgd])

    all_sgd["optimiser"] = ["SGD"] * len(all_sgd)

    import matplotlib.pyplot as plt
    import seaborn as sns

    fig, ax = plt.subplots(1, 1, figsize=(15, 10), layout="compressed")

    optimisers = ["SGD", "ASAM", "EKFAC"]
    rf_unique = all_sgd["RF"].unique()

    # for i,ax in enumerate(axs.flat):

    #   current_df=all_df[all_df["RF"]==rf_unique[i]]

    #   # sns.boxplot(ax=ax,
    #   #     data=current_df, x="layer_name", y="variance_entropy",hue="optimiser",
    #   # )
    #   sns.scatterplot(ax=ax,
    #       data=current_df, x="layer_name", y="variance_entropy",hue="RF",style="RF"
    #   )
    #   ax.tick_params(labelrotation=90)
    #   ax.set_xlabel('Layer Name')
    #   ax.set_ylabel('Etropy Varince (Filter Diversity)')
    #   ax.set_title(f"RF={rf_unique[i]}")

    sns.boxplot(ax=ax,
                data=all_sgd, x="layer_name", y="variance_entropy", hue="RF", legend="full", palette="deep"
                )
    ax.tick_params(labelrotation=90)
    ax.set_xlabel('Layer Name')
    ax.set_ylabel('Entropy Varince (Filter Diversity)')
    # ax.set_title(f"RF={rf_unique[i]}")
    # plt.tight_layout()
    plt.close()


def saturation_large_input_size():
    """# TODO: Saturation large input size

    ## pr 0.9
    """

    fig, axs = plt.subplots(2, 4, figsize=fig_size, layout="compressed")

    saturation_df_1 = pd.read_csv(
        "saturation_results/small_imagenet/resnet_small/SGD/resnet_small_3_small_imagenet_no_recording_200_pr_0.9_saturation_seed_0.csv",
        delimiter=";")
    saturation_df_1["RF"] = [1] * len(saturation_df_1)

    saturation_df_2 = pd.read_csv(
        "saturation_results/small_imagenet/resnet_small/SGD/resnet_small_4_small_imagenet_no_recording_200_pr_0.9_saturation_seed_0.csv",
        delimiter=";")
    saturation_df_2["RF"] = [2] * len(saturation_df_2)

    saturation_df_3 = pd.read_csv(
        "saturation_results/small_imagenet/resnet_small/SGD/resnet_small_5_small_imagenet_no_recording_200_pr_0.9_saturation_seed_0.csv",
        delimiter=";")
    saturation_df_3["RF"] = [3] * len(saturation_df_3)
    saturation_df_4 = pd.read_csv(
        "saturation_results/small_imagenet/resnet_small/SGD/resnet_small_6_small_imagenet_no_recording_200_pr_0.9_saturation_seed_0.csv",
        delimiter=";")
    saturation_df_4["RF"] = [4] * len(saturation_df_4)
    saturation_df_5 = pd.read_csv(
        "saturation_results/small_imagenet/resnet_small/SGD/resnet_small_7_small_imagenet_no_recording_200_pr_0.9_saturation_seed_0.csv",
        delimiter=";")
    saturation_df_5["RF"] = [5] * len(saturation_df_5)
    saturation_df_6 = pd.read_csv(
        "saturation_results/small_imagenet/resnet_small/SGD/resnet_small_8_small_imagenet_no_recording_200_pr_0.9_saturation_seed_0.csv",
        delimiter=";")
    saturation_df_6["RF"] = [6] * len(saturation_df_6)
    saturation_df_7 = pd.read_csv(
        "saturation_results/small_imagenet/resnet_small/SGD/resnet_small_9_small_imagenet_no_recording_200_pr_0.9_saturation_seed_0.csv",
        delimiter=";")
    saturation_df_7["RF"] = [7] * len(saturation_df_7)
    saturation_df_8 = pd.read_csv(
        "saturation_results/small_imagenet/resnet_small/SGD/resnet_small_10_small_imagenet_no_recording_200_pr_0.9_saturation_seed_0.csv",
        delimiter=";")
    saturation_df_8["RF"] = [8] * len(saturation_df_8)

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)
    saturation_df_list = [saturation_df_1, saturation_df_2, saturation_df_3, saturation_df_4, saturation_df_5,
                          saturation_df_6, saturation_df_7, saturation_df_8]

    saturation_df_dense_1 = pd.read_csv(
        "saturation_results/small_imagenet/resnet_small/SGD/resnet_small_3_small_imagenet_no_recording_200_pr_0.0_saturation_seed_0.csv",
        delimiter=";")
    saturation_df_dense_1["RF"] = [1] * len(saturation_df_dense_1)

    saturation_df_dense_2 = pd.read_csv(
        "saturation_results/small_imagenet/resnet_small/SGD/resnet_small_4_small_imagenet_no_recording_200_pr_0.0_saturation_seed_0.csv",
        delimiter=";")
    saturation_df_dense_2["RF"] = [2] * len(saturation_df_dense_2)

    saturation_df_dense_3 = pd.read_csv(
        "saturation_results/small_imagenet/resnet_small/SGD/resnet_small_5_small_imagenet_no_recording_200_pr_0.0_saturation_seed_0.csv",
        delimiter=";")
    saturation_df_dense_3["RF"] = [3] * len(saturation_df_dense_3)
    saturation_df_dense_4 = pd.read_csv(
        "saturation_results/small_imagenet/resnet_small/SGD/resnet_small_6_small_imagenet_no_recording_200_pr_0.0_saturation_seed_0.csv",
        delimiter=";")
    saturation_df_dense_4["RF"] = [4] * len(saturation_df_dense_4)
    saturation_df_dense_5 = pd.read_csv(
        "saturation_results/small_imagenet/resnet_small/SGD/resnet_small_7_small_imagenet_no_recording_200_pr_0.0_saturation_seed_0.csv",
        delimiter=";")
    saturation_df_dense_5["RF"] = [5] * len(saturation_df_dense_5)
    saturation_df_dense_6 = pd.read_csv(
        "saturation_results/small_imagenet/resnet_small/SGD/resnet_small_8_small_imagenet_no_recording_200_pr_0.0_saturation_seed_0.csv",
        delimiter=";")
    saturation_df_dense_6["RF"] = [6] * len(saturation_df_dense_6)
    saturation_df_dense_7 = pd.read_csv(
        "saturation_results/small_imagenet/resnet_small/SGD/resnet_small_9_small_imagenet_no_recording_200_pr_0.0_saturation_seed_0.csv",
        delimiter=";")
    saturation_df_dense_7["RF"] = [7] * len(saturation_df_dense_7)
    saturation_df_dense_8 = pd.read_csv(
        "saturation_results/small_imagenet/resnet_small/SGD/resnet_small_10_small_imagenet_no_recording_200_pr_0.0_saturation_seed_0.csv",
        delimiter=";")
    saturation_df_dense_8["RF"] = [8] * len(saturation_df_dense_8)

    # ax1=plot_stat_level_from_results("saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",199, "lsat",stat_mode="train",save=False)

    saturation_df_dense_list = [saturation_df_dense_1, saturation_df_dense_2, saturation_df_dense_3,
                                saturation_df_dense_4, saturation_df_dense_5, saturation_df_dense_6,
                                saturation_df_dense_7, saturation_df_dense_8]

    for i, ax in enumerate(axs.flat):
        saturation_df_pruned = saturation_df_list[i]

        saturation_df_dense = saturation_df_dense_list[i]

        epoch_df_pruned, pm = extract_layer_stat(saturation_df_pruned,
                                                 epoch=0,
                                                 primary_metric=None,
                                                 stat='saturation',
                                                 state_mode="train")

        epoch_df_dense, pm = extract_layer_stat(saturation_df_dense,
                                                epoch=0,
                                                primary_metric=None,
                                                stat='saturation',
                                                state_mode="train")

        # print("epoch_df: {}".format(epoch_df))
        plot_saturation(epoch_df=epoch_df_pruned, ax=ax, color="red", label="Pruned")
        plot_saturation(epoch_df=epoch_df_dense, ax=ax, color="blue", label="Dense")

        # h,l=ax.legend(["Pruned","Dense"])
        ax.legend()
        # h, l = ax.get_legend_handles_labels()
        # new_h=[h[0],h[2]]
        # new_l=[l[0],l[1]]
        # ax.legend(h, l)
        ax.set_title(f"RF={i + 1}")

    plt.close()


def saturation_resnet25_smal_imagenet():
    """## ResNet2t5 z Small ImageNet RESIZED

    # Saturation

    ## Resnet25 x Small ImageNet
    """

    import pandas as pd
    import matplotlib.pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnet_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # preamble = "drive/MyDrive/PhD/solutions_small_imagenet/saturation_resnet25/resnet25_small"
    preamble = "/home/luisaam/Documents/PhD/data/solutions_small_imagenet/saturation_resnet25/resnet25_small"
    #         drive/MyDrive/PhD/solutions_small_imagenet/saturation_resnet25/resnet25_small/resnet25_small_10_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv
    sat_lvl_5_seed_0 = "resnet25_small_5_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_5_seed_1 = "resnet25_small_5_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_5_seed_2 = "resnet25_small_5_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    sat_lvl_6_seed_0 = "resnet25_small_6_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_6_seed_1 = "resnet25_small_6_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_6_seed_2 = "resnet25_small_6_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    sat_lvl_7_seed_0 = "resnet25_small_7_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_7_seed_1 = "resnet25_small_7_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_7_seed_2 = "resnet25_small_7_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    sat_lvl_8_seed_0 = "resnet25_small_8_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_8_seed_1 = "resnet25_small_8_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_8_seed_2 = "resnet25_small_8_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    sat_lvl_10_seed_0 = "resnet25_small_10_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_10_seed_1 = "resnet25_small_10_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_10_seed_2 = "resnet25_small_10_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    sat_lvl_11_seed_0 = "resnet25_small_11_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_11_seed_1 = "resnet25_small_11_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_11_seed_2 = "resnet25_small_11_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    sat_lvl_12_seed_0 = "resnet25_small_12_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_12_seed_1 = "resnet25_small_12_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_12_seed_2 = "resnet25_small_12_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    sat_lvl_13_seed_0 = "resnet25_small_13_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_13_seed_1 = "resnet25_small_13_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_13_seed_2 = "resnet25_small_13_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    level5_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_5_seed_0}", delimiter=";")
    level5_seed1 = pd.read_csv(f"{preamble}/{sat_lvl_5_seed_1}", delimiter=";")
    level5_seed2 = pd.read_csv(f"{preamble}/{sat_lvl_5_seed_2}", delimiter=";")

    lvl5 = pd.concat([level5_seed0, level5_seed1, level5_seed2])

    epoch_df_train, pm = extract_layer_stat(lvl5,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl5,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    lvl5["average-train-sat"] = epoch_df_train.mean(axis=1)
    lvl5["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl5["RF"] = len(lvl5) * [resnet_rfs[5]]

    level6_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_6_seed_0}", delimiter=";")
    level6_seed1 = pd.read_csv(f"{preamble}/{sat_lvl_6_seed_1}", delimiter=";")
    level6_seed2 = pd.read_csv(f"{preamble}/{sat_lvl_6_seed_2}", delimiter=";")

    lvl6 = pd.concat([level6_seed0, level6_seed1, level6_seed2])
    epoch_df_train, pm = extract_layer_stat(lvl6,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl6,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    lvl6["average-train-sat"] = epoch_df_train.mean(axis=1)
    lvl6["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl6["RF"] = len(lvl6) * [resnet_rfs[6]]

    level7_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_7_seed_0}", delimiter=";")
    level7_seed1 = pd.read_csv(f"{preamble}/{sat_lvl_7_seed_1}", delimiter=";")
    level7_seed2 = pd.read_csv(f"{preamble}/{sat_lvl_7_seed_2}", delimiter=";")

    lvl7 = pd.concat([level7_seed0, level7_seed1, level7_seed2])
    epoch_df_train, pm = extract_layer_stat(lvl7,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl7,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    lvl7["average-train-sat"] = epoch_df_train.mean(axis=1)
    lvl7["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl7["RF"] = len(lvl7) * [resnet_rfs[7]]

    level8_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_8_seed_0}", delimiter=";")
    level8_seed1 = pd.read_csv(f"{preamble}/{sat_lvl_8_seed_1}", delimiter=";")
    level8_seed2 = pd.read_csv(f"{preamble}/{sat_lvl_8_seed_2}", delimiter=";")

    lvl8 = pd.concat([level8_seed0, level8_seed1, level8_seed2])
    epoch_df_train, pm = extract_layer_stat(lvl8,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl8,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    lvl8["average-train-sat"] = epoch_df_train.mean(axis=1)
    lvl8["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl8["RF"] = len(lvl8) * [resnet_rfs[8]]

    level10_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_10_seed_0}", delimiter=";")
    level10_seed1 = pd.read_csv(f"{preamble}/{sat_lvl_10_seed_1}", delimiter=";")
    level10_seed2 = pd.read_csv(f"{preamble}/{sat_lvl_10_seed_2}", delimiter=";")

    lvl10 = pd.concat([level10_seed0, level10_seed1, level10_seed2])

    epoch_df_train, pm = extract_layer_stat(lvl10,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl10,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    lvl10["average-train-sat"] = epoch_df_train.mean(axis=1)
    lvl10["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl10["RF"] = len(lvl10) * [resnet_rfs[10]]

    level11_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_11_seed_0}", delimiter=";")
    level11_seed1 = pd.read_csv(f"{preamble}/{sat_lvl_11_seed_1}", delimiter=";")
    level11_seed2 = pd.read_csv(f"{preamble}/{sat_lvl_11_seed_2}", delimiter=";")

    lvl11 = pd.concat([level11_seed0, level11_seed1, level11_seed2])
    epoch_df_train, pm = extract_layer_stat(lvl11,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl11,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    lvl11["average-train-sat"] = epoch_df_train.mean(axis=1)
    lvl11["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl11["RF"] = len(lvl11) * [resnet_rfs[11]]

    level12_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_12_seed_0}", delimiter=";")
    level12_seed1 = pd.read_csv(f"{preamble}/{sat_lvl_12_seed_1}", delimiter=";")
    level12_seed2 = pd.read_csv(f"{preamble}/{sat_lvl_12_seed_2}", delimiter=";")

    lvl12 = pd.concat([level12_seed0, level12_seed1, level12_seed2])
    epoch_df_train, pm = extract_layer_stat(lvl12,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl12,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    lvl12["average-train-sat"] = epoch_df_train.mean(axis=1)
    lvl12["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl12["RF"] = len(lvl12) * [resnet_rfs[12]]

    level13_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_13_seed_0}", delimiter=";")
    level13_seed1 = pd.read_csv(f"{preamble}/{sat_lvl_13_seed_1}", delimiter=";")
    level13_seed2 = pd.read_csv(f"{preamble}/{sat_lvl_13_seed_2}", delimiter=";")

    lvl13 = pd.concat([level13_seed0, level13_seed1, level13_seed2])
    epoch_df_train, pm = extract_layer_stat(lvl13,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl13,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    lvl13["average-train-sat"] = epoch_df_train.mean(axis=1)
    lvl13["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl13["RF"] = len(lvl13) * [resnet_rfs[13]]

    all_df = pd.concat([lvl5, lvl6, lvl7, lvl8, lvl10, lvl11, lvl12, lvl13], ignore_index=True)

    fig, axs = plt.subplots(1, 2, figsize=fig_size, sharex="all", sharey=True, layout="compressed")

    # fig, axes = plt.subplots(3, 2, figsize=fig_size, sharex="all", sharey="all", layout="compressed")

    sns.barplot(data=all_df, x="RF", y="average-train-sat", ax=axs[0])
    sns.barplot(data=all_df, x="RF", y="average-eval-sat", ax=axs[1])

    sns.stripplot(
        x="RF",
        y="average-train-sat",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)

    sns.stripplot(
        x="RF",
        y="average-eval-sat",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    axs[0].set_ylabel('Average Train Saturation', labelsize=fs * labels_multiplier)
    axs[1].set_ylabel('Average Test Saturation', labelsize=fs * labels_multiplier)

    axs[0].set_xlabel("")
    axs[1].set_xlabel("")

    axs[0].grid(ls="--")
    axs[1].grid(ls="--")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        # ax.tick_params(axis='x', which='major', labelrotation=90)

    fig_multiplier = 1.7
    fig.text(0.55, -0.019, 'Receptive Field', ha='center', size=fs * labels_multiplier)
    # fig.text(0.25, 0.5, 'Receptive Field', va='center', rotation="vertical", size=fs * fig_multiplier)

    # plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_saturation_resnet25_small_imagenet_detailed.pdf")
    plt.close()

    level8_seed0.sum(axis=1)

    """## Resnet25 x Small ImageNet Resized"""

    import pandas as pd
    import matplotlib.pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnet_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    preamble = "drive/MyDrive/PhD/solutions_small_imagenet/saturation_resnet25/resnet25_small_resized"
    #         drive/MyDrive/PhD/solutions_small_imagenet/saturation_resnet25/resnet25_small_resized/resnet25_small_10_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv
    #         drive/MyDrive/PhD/solutions_small_imagenet/saturation_resnet25/resnet25_small/resnet25_small_10_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv
    sat_lvl_5_seed_0 = "resnet25_small_5_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_5_seed_1 = "resnet25_small_5_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_5_seed_2 = "resnet25_small_5_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    sat_lvl_6_seed_0 = "resnet25_small_6_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_6_seed_1 = "resnet25_small_6_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_6_seed_2 = "resnet25_small_6_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    sat_lvl_7_seed_0 = "resnet25_small_7_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_7_seed_1 = "resnet25_small_7_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_7_seed_2 = "resnet25_small_7_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    sat_lvl_8_seed_0 = "resnet25_small_8_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_8_seed_1 = "resnet25_small_8_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_8_seed_2 = "resnet25_small_8_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    sat_lvl_10_seed_0 = "resnet25_small_10_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_10_seed_1 = "resnet25_small_10_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_10_seed_2 = "resnet25_small_10_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    sat_lvl_11_seed_0 = "resnet25_small_11_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_11_seed_1 = "resnet25_small_11_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_11_seed_2 = "resnet25_small_11_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    sat_lvl_12_seed_0 = "resnet25_small_12_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_12_seed_1 = "resnet25_small_12_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_12_seed_2 = "resnet25_small_12_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    sat_lvl_13_seed_0 = "resnet25_small_13_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_13_seed_1 = "resnet25_small_13_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_13_seed_2 = "resnet25_small_13_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    level5_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_5_seed_0}", delimiter=";")
    level5_seed1 = pd.read_csv(f"{preamble}/{sat_lvl_5_seed_1}", delimiter=";")
    level5_seed2 = pd.read_csv(f"{preamble}/{sat_lvl_5_seed_2}", delimiter=";")

    lvl5 = pd.concat([level5_seed0, level5_seed1, level5_seed2])

    epoch_df_train, pm = extract_layer_stat(lvl5,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl5,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    lvl5["average-train-sat"] = epoch_df_train.mean(axis=1)
    lvl5["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl5["RF"] = len(lvl5) * [resnet_rfs[5]]

    level6_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_6_seed_0}", delimiter=";")
    level6_seed1 = pd.read_csv(f"{preamble}/{sat_lvl_6_seed_1}", delimiter=";")
    # level6_seed2 =pd.read_csv(f"{preamble}/{sat_lvl_6_seed_2}",delimiter=";")

    lvl6 = pd.concat([level6_seed0, level6_seed1])
    epoch_df_train, pm = extract_layer_stat(lvl6,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl6,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    lvl6["average-train-sat"] = epoch_df_train.mean(axis=1)
    lvl6["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl6["RF"] = len(lvl6) * [resnet_rfs[6]]

    level7_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_7_seed_0}", delimiter=";")
    level7_seed1 = pd.read_csv(f"{preamble}/{sat_lvl_7_seed_1}", delimiter=";")
    level7_seed2 = pd.read_csv(f"{preamble}/{sat_lvl_7_seed_2}", delimiter=";")

    lvl7 = pd.concat([level7_seed0, level7_seed1, level7_seed2])
    epoch_df_train, pm = extract_layer_stat(lvl7,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl7,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    lvl7["average-train-sat"] = epoch_df_train.mean(axis=1)
    lvl7["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl7["RF"] = len(lvl7) * [resnet_rfs[7]]

    level8_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_8_seed_0}", delimiter=";")
    level8_seed1 = pd.read_csv(f"{preamble}/{sat_lvl_8_seed_1}", delimiter=";")
    level8_seed2 = pd.read_csv(f"{preamble}/{sat_lvl_8_seed_2}", delimiter=";")

    lvl8 = pd.concat([level8_seed0, level8_seed1, level8_seed2])
    epoch_df_train, pm = extract_layer_stat(lvl8,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl8,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    lvl8["average-train-sat"] = epoch_df_train.mean(axis=1)
    lvl8["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl8["RF"] = len(lvl8) * [resnet_rfs[8]]

    level10_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_10_seed_0}", delimiter=";")
    level10_seed1 = pd.read_csv(f"{preamble}/{sat_lvl_10_seed_1}", delimiter=";")
    level10_seed2 = pd.read_csv(f"{preamble}/{sat_lvl_10_seed_2}", delimiter=";")

    lvl10 = pd.concat([level10_seed0, level10_seed1, level10_seed2])

    epoch_df_train, pm = extract_layer_stat(lvl10,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl10,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    lvl10["average-train-sat"] = epoch_df_train.mean(axis=1)
    lvl10["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl10["RF"] = len(lvl10) * [resnet_rfs[10]]

    level11_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_11_seed_0}", delimiter=";")
    level11_seed1 = pd.read_csv(f"{preamble}/{sat_lvl_11_seed_1}", delimiter=";")
    # level11_seed2 =pd.read_csv(f"{preamble}/{sat_lvl_11_seed_2}",delimiter=";")

    lvl11 = pd.concat([level11_seed0, level11_seed1])
    epoch_df_train, pm = extract_layer_stat(lvl11,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl11,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    lvl11["average-train-sat"] = epoch_df_train.mean(axis=1)
    lvl11["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl11["RF"] = len(lvl11) * [resnet_rfs[11]]

    level12_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_12_seed_0}", delimiter=";")
    level12_seed1 = pd.read_csv(f"{preamble}/{sat_lvl_12_seed_1}", delimiter=";")
    level12_seed2 = pd.read_csv(f"{preamble}/{sat_lvl_12_seed_2}", delimiter=";")

    lvl12 = pd.concat([level12_seed0, level12_seed1, level12_seed2])
    epoch_df_train, pm = extract_layer_stat(lvl12,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl12,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    lvl12["average-train-sat"] = epoch_df_train.mean(axis=1)
    lvl12["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl12["RF"] = len(lvl12) * [resnet_rfs[12]]

    level13_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_13_seed_0}", delimiter=";")
    # level13_seed1 =pd.read_csv(f"{preamble}/{sat_lvl_13_seed_1}",delimiter=";")
    # level13_seed2 =pd.read_csv(f"{preamble}/{sat_lvl_13_seed_2}",delimiter=";")

    # lvl13=pd.concat([level13_seed0,level13_seed1,level13_seed2])
    lvl13 = level13_seed0
    epoch_df_train, pm = extract_layer_stat(lvl13,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl13,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    lvl13["average-train-sat"] = epoch_df_train.mean(axis=1)
    lvl13["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl13["RF"] = len(lvl13) * [resnet_rfs[13]]

    all_df = pd.concat([lvl5, lvl6, lvl7, lvl8, lvl10, lvl11, lvl12, lvl13], ignore_index=True)
    fig, axs = plt.subplots(1, 2, figsize=fig_size, sharex=True, layout="compressed")

    sns.barplot(data=all_df, x="RF", y="average-train-sat", ax=axs[0])
    sns.barplot(data=all_df, x="RF", y="average-eval-sat", ax=axs[1])

    sns.stripplot(
        x="RF",
        y="average-train-sat",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)

    sns.stripplot(
        x="RF",
        y="average-eval-sat",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)
    # plt.grid(ls="--")
    axs[0].set_ylabel('Average Train Saturation', label_size=fs * labels_multiplier)
    axs[1].set_ylabel('Average Test Saturation', labels_size=fs * labels_multiplier)
    axs[0].set_xlabel("")
    axs[1].set_xlabel("")
    axs[0].grid(ls='--')
    axs[1].grid(ls='--')

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        # ax.tick_params(axis='x', which='major', labelrotation=90)

    fig_multiplier = 1.7
    fig.text(0.55, -0.019, 'Receptive Field', ha='center', size=fs * labels_multiplier)

    plt.savefig(
        "/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_saturation_resnet25_small_imagenet_resized.pdf")
    plt.close()

    level8_seed0.sum(axis=1)


def vgg19_cifar10_saturation():
    """#VGG19 cifar10 saturation for different RF"""

    vgg_ekfac_saturation_df_1 = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    vgg_ekfac_saturation_df_1["RF"] = [vgg_rfs[1]] * len(vgg_ekfac_saturation_df_1)
    vgg_ekfac_saturation_df_2 = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_2_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    vgg_ekfac_saturation_df_2["RF"] = [vgg_rfs[2]] * len(vgg_ekfac_saturation_df_2)
    vgg_ekfac_saturation_df_3 = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_3_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    vgg_ekfac_saturation_df_3["RF"] = [vgg_rfs[3]] * len(vgg_ekfac_saturation_df_3)
    vgg_ekfac_saturation_df_4 = pd.read_csv(
        "saturation_results/cifar10/vgg19/EKFAC/vgg19_normal_cifar10_rf_level_4_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    vgg_ekfac_saturation_df_4["RF"] = [vgg_rfs[4]] * len(vgg_ekfac_saturation_df_4)

    vgg_asam_saturation_df_1 = pd.read_csv(
        "saturation_results/cifar10/vgg19/ASAM/vgg19_normal_cifar10_rf_level_1_sam_optim_saturation_200_gc_0.csv",
        delimiter=";")
    vgg_asam_saturation_df_1["RF"] = [vgg_rfs[1]] * len(vgg_asam_saturation_df_1)
    vgg_asam_saturation_df_2 = pd.read_csv(
        "saturation_results/cifar10/vgg19/ASAM/vgg19_normal_cifar10_rf_level_2_sam_optim_saturation_200_gc_0.csv",
        delimiter=";")
    vgg_asam_saturation_df_2["RF"] = [vgg_rfs[2]] * len(vgg_asam_saturation_df_2)
    vgg_asam_saturation_df_3 = pd.read_csv(
        "saturation_results/cifar10/vgg19/ASAM/vgg19_normal_cifar10_rf_level_3_sam_optim_saturation_200_gc_0.csv",
        delimiter=";")
    vgg_asam_saturation_df_3["RF"] = [vgg_rfs[3]] * len(vgg_asam_saturation_df_3)
    vgg_asam_saturation_df_4 = pd.read_csv(
        "saturation_results/cifar10/vgg19/ASAM/vgg19_normal_cifar10_rf_level_4_sam_optim_saturation_200_gc_0.csv",
        delimiter=";")
    vgg_asam_saturation_df_4["RF"] = [vgg_rfs[4]] * len(vgg_asam_saturation_df_4)

    vgg_sgd_saturation_df_1 = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726772593.4515305_rf_level_1_recording_200_no_ffcv.csv",
        delimiter=";")
    vgg_sgd_saturation_df_1["RF"] = [vgg_rfs[1]] * len(vgg_sgd_saturation_df_1)
    vgg_sgd_saturation_df_2 = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1726773380.2706754_rf_level_2_recording_200_no_ffcv.csv",
        delimiter=";")
    vgg_sgd_saturation_df_2["RF"] = [vgg_rfs[2]] * len(vgg_sgd_saturation_df_2)
    vgg_sgd_saturation_df_3 = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1725639932.8630962_rf_level_3_recording_200_no_ffcv.csv",
        delimiter=";")
    vgg_sgd_saturation_df_3["RF"] = [vgg_rfs[3]] * len(vgg_sgd_saturation_df_3)
    vgg_sgd_saturation_df_4 = pd.read_csv(
        "saturation_results/cifar10/vgg19/SGD/vgg19_normal_cifar10_1725640015.7435527_rf_level_4_recording_200_no_ffcv.csv",
        delimiter=";")
    vgg_sgd_saturation_df_4["RF"] = [vgg_rfs[4]] * len(vgg_sgd_saturation_df_4)

    all_saturation_ekfac_df = pd.concat(
        [vgg_ekfac_saturation_df_1, vgg_ekfac_saturation_df_2, vgg_ekfac_saturation_df_3, vgg_ekfac_saturation_df_4])
    all_saturation_ekfac_df["optimiser"] = ["EKFAC"] * len(all_saturation_ekfac_df)
    all_saturation_sam_df = pd.concat(
        [vgg_asam_saturation_df_1, vgg_asam_saturation_df_2, vgg_asam_saturation_df_3, vgg_asam_saturation_df_4])
    all_saturation_sam_df["optimiser"] = ["ASAM"] * len(all_saturation_sam_df)
    all_saturation_sgd_df = pd.concat(
        [vgg_sgd_saturation_df_1, vgg_sgd_saturation_df_2, vgg_sgd_saturation_df_3, vgg_sgd_saturation_df_4])
    all_saturation_sgd_df["optimiser"] = ["SGD"] * len(all_saturation_sgd_df)

    all_df = pd.concat([all_saturation_ekfac_df, all_saturation_sam_df, all_saturation_sgd_df])

    # fig_size = (7, 5)
    # ticks_multiplier = 1.3
    # labels_multiplier = 1.8
    fig, axs = plt.subplots(2, 2, figsize=fig_size, sharey=True, sharex=True, layout="tight")

    unique_RF = all_df["RF"].unique()

    # colors=["red","blue","green"]
    # optimisers=["SGD","ASAM","EKFAC"]
    colors = ["blue"]
    optimisers = ["SGD"]

    for i, ax in enumerate(axs.flat):
        saturation_df_rf = all_df[all_df["RF"] == unique_RF[i]]

        for j, opt in enumerate(optimisers):
            current_df = saturation_df_rf[saturation_df_rf["optimiser"] == opt]

            epoch_df_dense, pm = extract_layer_stat(current_df,
                                                    epoch=199,
                                                    primary_metric=None,
                                                    stat='saturation',
                                                    state_mode="train")

            plot_saturation(epoch_df=epoch_df_dense, ax=ax, color=colors[j], label=opt)
        ax.set_title(f"{unique_RF[i]}")
        ax.grid(ls="--", alpha=0.5)
        ax.set_xlabel("")
        ax.set_ylabel("")
        ax.set_xticks(range(len(epoch_df_dense.columns)), range(len(epoch_df_dense.columns)), color="k")
        # ax.set_yticks([])
        # ax.tick_params(axis="x",color="w")
        ax.tick_params(axis="both", labelsize=fs * ticks_multiplier)

    # ax.legend()

    # Y axis

    fig.text(-0.015, 0.5, 'Saturation', va='center', rotation="vertical", size=fs * labels_multiplier
             )

    # X axis
    fig.text(0.5, -0.04, 'Layer', ha='center', size=fs * labels_multiplier)

    fig.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/vgg19_cifar10_saturation.pdf", bbox_inches="tight")
    plt.close()

    ##################################################################
    ############################# Version 2 ##########################
    ##################################################################

    fig, ax = plt.subplots(1, 1, figsize=fig_size, sharey=True, sharex=True, layout="tight")

    unique_RF = all_df["RF"].unique()
    num_colors = len(unique_RF)
    cm = mpl.cm.get_cmap(name='magma')
    currentColors = [cm(1. * i / num_colors) for i in range(num_colors)]

    # colors = ["blue","red","green","yellow"]
    colors = ["blue", "red", "green", "orange", "yellow"]
    # optimisers = ["SGD"]

    # for i, ax in enumerate(axs.flat):
    for i, color in enumerate(currentColors):
        current_df = all_df[all_df["RF"] == unique_RF[i]]
        current_df = current_df[current_df["optimiser"] == opt]
        current_df = current_df.mean(axis=0).to_frame().T

        epoch_df_dense, pm = extract_layer_stat(current_df,
                                                epoch=0,
                                                primary_metric=None,
                                                stat='saturation',
                                                state_mode="train")

        # plot_saturation(epoch_df=epoch_df_dense, ax=ax, log=False, color=color, label=f"{unique_RF[i]}", ewma=False,
        #                 window=5)
        ax.scatter(x=range(len(epoch_df_dense.values[0])), y=epoch_df_dense.values[0], color=color, marker="o",label=f"{unique_RF[i]}")
    # ax.set_title(f"{unique_RF[i]}")
    ax.grid(ls="--", alpha=0.5)
    ax.set_xlabel("Layer",fontsize=fs*labels_multiplier)
    ax.set_ylabel("Saturation",fontsize=fs*labels_multiplier)
    ax.set_xticks(range(len(epoch_df_dense.columns)), range(len(epoch_df_dense.columns)), color="k")
    ax.set_yticks([0,0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8], [0,0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8], color="k")
    ax.legend(loc="lower left",bbox_to_anchor=(0.5,0.5))
    # ax.set_yticks([-3, -2.5, -2, -1.5, -1], [-3, -2.5, -2, -1.5, -1], color="k")
    # ax.set_xticks([])
    # ax.tick_params(axis="x",color="w")
    ax.tick_params(axis="both", labelsize=fs * ticks_multiplier)
    fig.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/vgg19_cifar10_saturation_v2.pdf", bbox_inches="tight")

    """### Whole model SGD Only"""

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    unique_RF = all_df["RF"].unique()

    colors = ["red", "blue", "green"]
    optimisers = ["SGD", "ASAM", "EKFAC"]

    # for i, ax in  enumerate(axs.flat):

    #   saturation_df_rf = all_df[all_df["RF"]==unique_RF[i]]

    #   for j, opt in enumerate(optimisers):

    #     current_df=saturation_df_rf[saturation_df_rf["optimiser"]==opt]

    #     epoch_df_dense, pm = extract_layer_stat(current_df,
    #                        epoch=0,
    #                        primary_metric=None,
    #                        stat='saturation',
    #                        state_mode="train")

    #     plot_saturation(epoch_df=epoch_df_dense,ax=ax,color=colors[j],label=opt)
    #   ax.set_title(f"RF={unique_RF[i]}")

    # ax.legend()

    # # plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/vgg19_optim_saturation.pdf")
    plt.close()

    all_sgd = all_df[all_df["optimiser"] == "SGD"]

    epoch_df_dense, pm = extract_layer_stat(all_sgd,
                                            epoch=199,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    # for i, ax in  enumerate(axs.flat):

    #   saturation_df_rf = all_sgd[all_sgd["RF"]==unique_RF[i]]

    #   for j, opt in enumerate(optimisers):

    #     current_df=saturation_df_rf[saturation_df_rf["optimiser"]==opt]

    #     epoch_df_dense, pm = extract_layer_stat(current_df,
    #                        epoch=199,
    #                        primary_metric=None,
    #                        stat='saturation',
    #                        state_mode="train")

    #     plot_saturation(epoch_df=epoch_df_dense,ax=ax,color=colors[j],label=opt)
    #   ax.set_title(f"RF={unique_RF[i]}")

    # ax.legend()

    # # plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/vgg19_optim_saturation.pdf")
    plt.close()
    # ax.set_title(f"RF={rf_unique[i]}")
    # plt.tight_layout()

    mean_epoch_df_dense = pd.DataFrame(
        {"Mean model Saturation": epoch_df_dense.mean(axis=1).to_list(), "RF": all_sgd["RF"].unique()})
    print("Mean DF")
    print(mean_epoch_df_dense)
    # mean_epoch_df_dense["RF"]= all_sgd["RF"].unique()
    ax.bar(range(1, len(mean_epoch_df_dense["RF"]) + 1), mean_epoch_df_dense["Mean model Saturation"])
    ax.set_xticks(range(1, len(mean_epoch_df_dense["RF"]) + 1), mean_epoch_df_dense["RF"])
    ax.tick_params(axis="both", labelsize=fs * ticks_multiplier)
    ax.tick_params(labelrotation=90)
    ax.set_xlabel('Receptive Field', fontsize=fs * labels_multiplier)
    # ax.set_ylabel('Entropy Variance (Filter Diversity)')
    ax.set_ylabel('Saturation', fontsize=fs * labels_multiplier)
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/vgg19_cifar10_saturation_whole_model.pdf")



def numpy_ewma_vectorized_v2(data, window):
    alpha = 2 / (window + 1.0)
    alpha_rev = 1 - alpha
    n = data.shape[0]

    pows = alpha_rev ** (np.arange(n + 1))

    scale_arr = 1 / pows[:-1]
    offset = data[0] * pows[1:]
    pw0 = alpha * alpha_rev ** (n - 1)

    mult = data * pw0 * scale_arr
    cumsums = mult.cumsum()
    out = offset + cumsums * scale_arr[::-1]
    return out


def resnet50_cifar10_saturation_different_rf():
    """# TODO: resnet50 cifar10 saturation for different RF"""

    resnet_all_layers = ["conv1","layer1.0.conv1", "layer1.0.conv2", "layer1.0.conv3", "layer1.0.shortcut.0",
                         "layer1.1.conv1", "layer1.1.conv2", "layer1.1.conv3", "layer1.2.conv1", "layer1.2.conv2",
                         "layer1.2.conv3", "layer2.0.conv1", "layer2.0.conv2", "layer2.0.conv3",
                         "layer2.0.shortcut.0", "layer2.1.conv1", "layer2.1.conv2", "layer2.1.conv3",
                         "layer2.2.conv1", "layer2.2.conv2", "layer2.2.conv3", "layer2.3.conv1", "layer2.3.conv2",
                         "layer2.3.conv3", "layer3.0.conv1", "layer3.0.conv2", "layer3.0.conv3",
                         "layer3.0.shortcut.0", "layer3.1.conv1", "layer3.1.conv2", "layer3.1.conv3",
                         "layer3.2.conv1", "layer3.2.conv2", "layer3.2.conv3", "layer3.3.conv1", "layer3.3.conv2",
                         "layer3.3.conv3", "layer3.4.conv1", "layer3.4.conv2", "layer3.4.conv3", "layer3.5.conv1",
                         "layer3.5.conv2", "layer3.5.conv3", "layer4.0.conv1", "layer4.0.conv2", "layer4.0.conv3",
                         "layer4.0.shortcut.0", "layer4.1.conv1", "layer4.1.conv2", "layer4.1.conv3",
                         "layer4.2.conv1", "layer4.2.conv2", "layer4.2.conv3","linear"]
    in_block_layers_index = [resnet_all_layers.index(l) for l in resnet_all_layers if ".conv1" in l or ".conv2" in l]
    out_of_block_layer_index = [resnet_all_layers.index(l) for l in resnet_all_layers if ".conv3" in l or ".shortcut" in l or "conv1"==l]

    resnets_rfs = [108, 110, 213, 318, 423, 1415, 1920, 3100]
    vgg_ekfac_saturation_df_1 = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_1_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    vgg_ekfac_saturation_df_1["RF"] = [resnets_rfs[1]] * len(vgg_ekfac_saturation_df_1)
    vgg_ekfac_saturation_df_2 = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_2_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    vgg_ekfac_saturation_df_2["RF"] = [resnets_rfs[2]] * len(vgg_ekfac_saturation_df_2)
    vgg_ekfac_saturation_df_3 = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_3_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    vgg_ekfac_saturation_df_3["RF"] = [resnets_rfs[3]] * len(vgg_ekfac_saturation_df_3)
    vgg_ekfac_saturation_df_4 = pd.read_csv(
        "saturation_results/cifar10/resnet50/EKFAC/resnet50_normal_cifar10_rf_level_4_ekfac_optim_hyper_saturation_200_gc_0.csv",
        delimiter=";")
    vgg_ekfac_saturation_df_4["RF"] = [resnets_rfs[4]] * len(vgg_ekfac_saturation_df_4)

    vgg_asam_saturation_df_1 = pd.read_csv(
        "saturation_results/cifar10/resnet50/ASAM/resnet50_normal_cifar10_rf_level_1_sam_optim_saturation_200_gc_0.csv",
        delimiter=";")
    vgg_asam_saturation_df_1["RF"] = [resnets_rfs[1]] * len(vgg_asam_saturation_df_1)
    vgg_asam_saturation_df_2 = pd.read_csv(
        "saturation_results/cifar10/resnet50/ASAM/resnet50_normal_cifar10_rf_level_2_sam_optim_saturation_200_gc_0.csv",
        delimiter=";")
    vgg_asam_saturation_df_2["RF"] = [resnets_rfs[2]] * len(vgg_asam_saturation_df_2)
    vgg_asam_saturation_df_3 = pd.read_csv(
        "saturation_results/cifar10/resnet50/ASAM/resnet50_normal_cifar10_rf_level_3_sam_optim_saturation_200_gc_0.csv",
        delimiter=";")
    vgg_asam_saturation_df_3["RF"] = [resnets_rfs[3]] * len(vgg_asam_saturation_df_3)
    vgg_asam_saturation_df_4 = pd.read_csv(
        "saturation_results/cifar10/resnet50/ASAM/resnet50_normal_cifar10_rf_level_4_sam_optim_saturation_200_gc_0.csv",
        delimiter=";")
    vgg_asam_saturation_df_4["RF"] = [resnets_rfs[4]] * len(vgg_asam_saturation_df_4)

    vgg_sgd_saturation_df_1 = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1726773378.6547081_rf_level_1_recording_200_no_ffcv.csv",
        delimiter=";")
    vgg_sgd_saturation_df_1["RF"] = [resnets_rfs[1]] * len(vgg_sgd_saturation_df_1)
    vgg_sgd_saturation_df_2 = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1727020462.50258_rf_level_2_recording_200_no_ffcv.csv",
        delimiter=";")
    vgg_sgd_saturation_df_2["RF"] = [resnets_rfs[2]] * len(vgg_sgd_saturation_df_2)
    vgg_sgd_saturation_df_3 = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1726248344.7113843_rf_level_3_recording_200_no_ffcv.csv",
        delimiter=";")
    vgg_sgd_saturation_df_3["RF"] = [resnets_rfs[3]] * len(vgg_sgd_saturation_df_3)
    vgg_sgd_saturation_df_4 = pd.read_csv(
        "saturation_results/cifar10/resnet50/SGD/resnet50_normal_cifar10_1726248344.4095678_rf_level_4_recording_200_no_ffcv.csv",
        delimiter=";")
    vgg_sgd_saturation_df_4["RF"] = [resnets_rfs[4]] * len(vgg_sgd_saturation_df_4)

    all_saturation_ekfac_df = pd.concat(
        [vgg_ekfac_saturation_df_1, vgg_ekfac_saturation_df_2, vgg_ekfac_saturation_df_3, vgg_ekfac_saturation_df_4])
    all_saturation_ekfac_df["optimiser"] = ["EKFAC"] * len(all_saturation_ekfac_df)
    all_saturation_sam_df = pd.concat(
        [vgg_asam_saturation_df_1, vgg_asam_saturation_df_2, vgg_asam_saturation_df_3, vgg_asam_saturation_df_4])
    all_saturation_sam_df["optimiser"] = ["ASAM"] * len(all_saturation_sam_df)
    all_saturation_sgd_df = pd.concat(
        [vgg_sgd_saturation_df_1, vgg_sgd_saturation_df_2, vgg_sgd_saturation_df_3, vgg_sgd_saturation_df_4])
    all_saturation_sgd_df["optimiser"] = ["SGD"] * len(all_saturation_sgd_df)

    # all_df=pd.concat([all_saturation_ekfac_df,all_saturation_sam_df,all_saturation_sgd_df])
    all_df = all_saturation_sgd_df

    # fig_size = (7, 5)

    # ticks_multiplier = 1.3
    #
    # labels_multiplier = 1.8

    fig, axs = plt.subplots(2, 2, figsize=fig_size, sharex=True, sharey=True, layout="compressed")

    unique_RF = all_df["RF"].unique()

    # colors=["red","blue","green"]
    # optimisers=["SGD","ASAM","EKFAC"]

    colors = ["blue"]

    optimisers = ["SGD"]

    for i, ax in enumerate(axs.flat):

        saturation_df_rf = all_df[all_df["RF"] == unique_RF[i]]

        for j, opt in enumerate(optimisers):
            current_df = saturation_df_rf[saturation_df_rf["optimiser"] == opt]

            epoch_df_dense, pm = extract_layer_stat(current_df,
                                                    epoch=199,
                                                    primary_metric=None,
                                                    stat='saturation',
                                                    state_mode="train")

            plot_saturation(epoch_df=epoch_df_dense, ax=ax, color=colors[j], label=opt)
            # ax.set_xticks(range(len(epoch_df_dense.columns)),range(len(epoch_df_dense.columns)))
            # ax.set_xticks([],[])
            # ax.set_xlabel("")
        ax.set_title(f"{unique_RF[i]}")
        ax.grid(ls="--", alpha=0.5)
        ax.set_xlabel("")
        ax.set_ylabel("")
        ax.set_xticks(range(len(epoch_df_dense.columns)), range(len(epoch_df_dense.columns)), color="w")
        # ax.set_xticks([])
        # ax.tick_params(axis="x",color="w")
        ax.tick_params(axis="y", labelsize=fs * ticks_multiplier)
        # ax.set_xticks([])

        ax.set_title(f"{unique_RF[i]}")

    fig.text(-0.03, 0.5, 'Saturation', va='center', rotation="vertical", size=fs * labels_multiplier)

    # X axis
    fig.text(0.5, -0.0, 'Layer', ha='center', size=fs * labels_multiplier)

    # fig.text(-0.015, 0.5, 'Saturation', va='center', rotation="vertical", size=fs * labels_multiplier
    #          )
    #
    # # X axis
    # fig.text(0.5, -0.04, 'Layer', ha='center', size=fs * labels_multiplier)
    # ax.legend(loc="upper right")
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet50_cifar10_saturation.pdf", bbox_inches="tight")

    ##################################################################
    ############################# Version 2 ##########################
    ##################################################################

    ##################################
    #       Inside of block
    ##################################
    fig, ax = plt.subplots(1, 1, figsize=fig_size, sharey=True, sharex=True, layout="tight")

    unique_RF = all_df["RF"].unique()
    num_colors = len(unique_RF)
    cm = mpl.cm.get_cmap(name='magma')
    currentColors = [cm(1. * i / num_colors) for i in range(num_colors)]

    # colors = ["blue","red","green","yellow"]
    colors = ["blue", "red", "green", "orange", "yellow"]
    # optimisers = ["SGD"]

    # for i, ax in enumerate(axs.flat):
    for i, color in enumerate(currentColors):
        current_df = all_df[all_df["RF"] == unique_RF[i]]
        current_df = current_df[current_df["optimiser"] == opt]
        current_df = current_df.mean(axis=0).to_frame().T

        epoch_df_dense, pm = extract_layer_stat(current_df,
                                                epoch=0,
                                                primary_metric=None,
                                                stat='saturation',
                                                state_mode="train")

        # plot_saturation(epoch_df=epoch_df_dense, ax=ax, log=False, color=color, label=f"{unique_RF[i]}", ewma=False,
        #                 window=5,index_to_keep=in_block_layers_index)
        ax.scatter(x=range(len(in_block_layers_index)), y=epoch_df_dense.values[0][in_block_layers_index], color=color, marker="o",label=f"{unique_RF[i]}")
    # ax.set_title(f"{unique_RF[i]}")
    ax.grid(ls="--", alpha=0.5)
    # ax.set_xlabel("")
    # ax.set_ylabel("")
    ax.set_xticks(range(len(in_block_layers_index)), in_block_layers_index, color="k")
    ax.set_yticks([0,0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8], [0,0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8], color="k")
    # ax.set_yticks([-3, -2.5, -2, -1.5, -1], [-3, -2.5, -2, -1.5, -1], color="k")
    # ax.set_xticks([])
    ax.set_xlabel("Layer",fontsize=fs*labels_multiplier)
    ax.set_ylabel("Saturation",fontsize=fs*labels_multiplier)
    ax.xaxis.set_major_locator(ticker.MultipleLocator(10))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(5))

    ax.tick_params(axis="both", labelsize=fs * ticks_multiplier)
    # ax.tick_params(axis="x", labelcolor="w")
    ax.legend()
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet50_cifar10_saturation_inblock_v2.pdf",
                bbox_inches="tight")

    plt.close()
    ##################################
    #       Out of block
    ##################################
    fig, ax = plt.subplots(1, 1, figsize=fig_size, sharey=True, sharex=True, layout="tight")
    unique_RF = all_df["RF"].unique()
    num_colors = len(unique_RF)
    cm = mpl.cm.get_cmap(name='magma')
    currentColors = [cm(1. * i / num_colors) for i in range(num_colors)]

    # colors = ["blue","red","green","yellow"]
    colors = ["blue", "red", "green", "orange", "yellow"]
    # optimisers = ["SGD"]

    # for i, ax in enumerate(axs.flat):
    for i, color in enumerate(currentColors):
        current_df = all_df[all_df["RF"] == unique_RF[i]]
        current_df = current_df[current_df["optimiser"] == opt]
        current_df = current_df.mean(axis=0).to_frame().T

        epoch_df_dense, pm = extract_layer_stat(current_df,
                                                epoch=0,
                                                primary_metric=None,
                                                stat='saturation',
                                                state_mode="train")

        # plot_saturation(epoch_df=epoch_df_dense, ax=ax, log=False, color=color, label=f"{unique_RF[i]}", ewma=False,
        #                 window=5,index_to_keep=out_of_block_layer_index)
        ax.scatter(x=range(len(out_of_block_layer_index)), y=epoch_df_dense.values[0][out_of_block_layer_index], color=color, marker="o",label=f"{unique_RF[i]}")
    # ax.set_title(f"{unique_RF[i]}")
    ax.grid(ls="--", alpha=0.5)
    # ax.set_xlabel("")
    # ax.set_ylabel("")
    ax.set_xticks(range(len(out_of_block_layer_index)),out_of_block_layer_index, color="k")
    ax.set_yticks([0,0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8], [0,0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8], color="k")
    # ax.set_yticks([-3, -2.5, -2, -1.5, -1], [-3, -2.5, -2, -1.5, -1], color="k")
    ax.set_xlabel("Layer",fontsize=fs*labels_multiplier)
    ax.set_ylabel("Saturation",fontsize=fs*labels_multiplier)
    ax.xaxis.set_major_locator(ticker.MultipleLocator(5))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(3))
    # ax.set_xticks([])
    ax.tick_params(axis="both", labelsize=fs * ticks_multiplier)
    ax.legend()
    # ax.tick_params(axis="x", labelcolor="w")
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet50_cifar10_saturation_outblock_v2.pdf",
                bbox_inches="tight")

    plt.close()
















    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed")

    unique_RF = all_df["RF"].unique()

    colors = ["red", "blue", "green"]
    optimisers = ["SGD", "ASAM", "EKFAC"]

    # for i, ax in  enumerate(axs.flat):

    #   saturation_df_rf = all_df[all_df["RF"]==unique_RF[i]]

    #   for j, opt in enumerate(optimisers):

    #     current_df=saturation_df_rf[saturation_df_rf["optimiser"]==opt]

    #     epoch_df_dense, pm = extract_layer_stat(current_df,
    #                        epoch=0,
    #                        primary_metric=None,
    #                        stat='saturation',
    #                        state_mode="train")

    #     plot_saturation(epoch_df=epoch_df_dense,ax=ax,color=colors[j],label=opt)
    #   ax.set_title(f"RF={unique_RF[i]}")

    # ax.legend()

    # # plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/vgg19_optim_saturation.pdf")

    all_sgd = all_df[all_df["optimiser"] == "SGD"]

    epoch_df_dense, pm = extract_layer_stat(all_sgd,
                                            epoch=199,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    # for i, ax in  enumerate(axs.flat):

    #   saturation_df_rf = all_sgd[all_sgd["RF"]==unique_RF[i]]

    #   for j, opt in enumerate(optimisers):

    #     current_df=saturation_df_rf[saturation_df_rf["optimiser"]==opt]

    #     epoch_df_dense, pm = extract_layer_stat(current_df,
    #                        epoch=199,
    #                        primary_metric=None,
    #                        stat='saturation',
    #                        state_mode="train")

    #     plot_saturation(epoch_df=epoch_df_dense,ax=ax,color=colors[j],label=opt)
    #   ax.set_title(f"RF={unique_RF[i]}")

    # ax.legend()

    # ax.set_title(f"RF={rf_unique[i]}")
    # plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/vgg19_optim_saturation.pdf")
    # plt.close()

    mean_epoch_df_dense = pd.DataFrame(
        {"Mean model Saturation": epoch_df_dense.mean(axis=1).to_list(), "RF": all_sgd["RF"].unique()})
    print("Mean DF")
    print(mean_epoch_df_dense)
    # mean_epoch_df_dense["RF"]= all_sgd["RF"].unique()
    ax.bar(range(1, len(mean_epoch_df_dense["RF"]) + 1), mean_epoch_df_dense["Mean model Saturation"])
    ax.set_xticks(range(1, len(mean_epoch_df_dense["RF"]) + 1), mean_epoch_df_dense["RF"])
    ax.tick_params(labelrotation=90)
    ax.set_xlabel('Receptive Field', fontsize=fs * labels_multiplier)
    ax.tick_params(axis="both", labelsize=fs * ticks_multiplier)
    # ax.set_ylabel('Entropy Variance (Filter Diversity)')
    ax.set_ylabel('Saturation', fontsize=fs * labels_multiplier)
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne50_cifar10_saturation_whole_model.pdf")
    plt.close()


def sharpness_plots():
    """# TODO: Sharpness

    ## Resnet50 x CIFAR10
    """

    resnets_rfs_values = [108, 110, 213, 318, 423, 538, 645, 752, 859, 1415, 1920, 3100]

    resnet_rfs_keys = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]

    resnets_rfs = dict(zip(resnet_rfs_keys, resnets_rfs_values))

    vgg_ekfac_sharpness_df_1 = pd.read_csv(
        "sharpness_results/resnet50_1_cifar10_ekfac_optim_hyper_saturation_200_gc_0_sharpness_summary.csv",
        delimiter=",")
    vgg_ekfac_sharpness_df_1["RF"] = [resnets_rfs[1]] * len(vgg_ekfac_sharpness_df_1)
    vgg_ekfac_sharpness_df_2 = pd.read_csv(
        "sharpness_results/resnet50_2_cifar10_ekfac_optim_hyper_saturation_200_gc_0_sharpness_summary.csv",
        delimiter=",")
    vgg_ekfac_sharpness_df_2["RF"] = [resnets_rfs[2]] * len(vgg_ekfac_sharpness_df_2)
    vgg_ekfac_sharpness_df_3 = pd.read_csv(
        "sharpness_results/resnet50_3_cifar10_ekfac_optim_hyper_saturation_200_gc_0_sharpness_summary.csv",
        delimiter=",")
    vgg_ekfac_sharpness_df_3["RF"] = [resnets_rfs[3]] * len(vgg_ekfac_sharpness_df_3)
    vgg_ekfac_sharpness_df_4 = pd.read_csv(
        "sharpness_results/resnet50_4_cifar10_ekfac_optim_hyper_saturation_200_gc_0_sharpness_summary.csv",
        delimiter=",")
    vgg_ekfac_sharpness_df_4["RF"] = [resnets_rfs[4]] * len(vgg_ekfac_sharpness_df_4)

    vgg_asam_sharpness_df_1 = pd.read_csv(
        "sharpness_results/resnet50_1_cifar10_sam_optim_saturation_200_gc_0_sharpness_summary.csv", delimiter=",")
    vgg_asam_sharpness_df_1["RF"] = [resnets_rfs[1]] * len(vgg_asam_sharpness_df_1)
    vgg_asam_sharpness_df_2 = pd.read_csv(
        "sharpness_results/resnet50_2_cifar10_sam_optim_saturation_200_gc_0_sharpness_summary.csv", delimiter=",")
    vgg_asam_sharpness_df_2["RF"] = [resnets_rfs[2]] * len(vgg_asam_sharpness_df_2)
    vgg_asam_sharpness_df_3 = pd.read_csv(
        "sharpness_results/resnet50_3_cifar10_sam_optim_saturation_200_gc_0_sharpness_summary.csv", delimiter=",")
    vgg_asam_sharpness_df_3["RF"] = [resnets_rfs[3]] * len(vgg_asam_sharpness_df_3)
    vgg_asam_sharpness_df_4 = pd.read_csv(
        "sharpness_results/resnet50_4_cifar10_sam_optim_saturation_200_gc_0_sharpness_summary.csv", delimiter=",")
    vgg_asam_sharpness_df_4["RF"] = [resnets_rfs[4]] * len(vgg_asam_sharpness_df_4)

    vgg_sgd_sharpness_df_1 = pd.read_csv(
        "sharpness_results/resnet50_1_cifar10_recording_200_no_ffcv_sharpness_summary.csv", delimiter=",")
    vgg_sgd_sharpness_df_1["RF"] = [resnets_rfs[1]] * len(vgg_sgd_sharpness_df_1)
    vgg_sgd_sharpness_df_2 = pd.read_csv(
        "sharpness_results/resnet50_2_cifar10_recording_200_no_ffcv_sharpness_summary.csv", delimiter=",")
    vgg_sgd_sharpness_df_2["RF"] = [resnets_rfs[2]] * len(vgg_sgd_sharpness_df_2)
    vgg_sgd_sharpness_df_3 = pd.read_csv(
        "sharpness_results/resnet50_3_cifar10_recording_200_no_ffcv_sharpness_summary.csv", delimiter=",")
    vgg_sgd_sharpness_df_3["RF"] = [resnets_rfs[3]] * len(vgg_sgd_sharpness_df_3)
    vgg_sgd_sharpness_df_4 = pd.read_csv(
        "sharpness_results/resnet50_4_cifar10_recording_200_no_ffcv_sharpness_summary.csv", delimiter=",")
    vgg_sgd_sharpness_df_4["RF"] = [resnets_rfs[4]] * len(vgg_sgd_sharpness_df_4)

    all_saturation_ekfac_df = pd.concat(
        [vgg_ekfac_sharpness_df_1, vgg_ekfac_sharpness_df_2, vgg_ekfac_sharpness_df_3, vgg_ekfac_sharpness_df_4])
    all_saturation_ekfac_df["optimiser"] = ["EKFAC"] * len(all_saturation_ekfac_df)
    all_saturation_sam_df = pd.concat(
        [vgg_asam_sharpness_df_1, vgg_asam_sharpness_df_2, vgg_asam_sharpness_df_3, vgg_asam_sharpness_df_4])
    all_saturation_sam_df["optimiser"] = ["ASAM"] * len(all_saturation_sam_df)
    all_saturation_sgd_df = pd.concat(
        [vgg_sgd_sharpness_df_1, vgg_sgd_sharpness_df_2, vgg_sgd_sharpness_df_3, vgg_sgd_sharpness_df_4])
    all_saturation_sgd_df["optimiser"] = ["SGD"] * len(all_saturation_sgd_df)

    all_df = pd.concat([all_saturation_ekfac_df, all_saturation_sam_df, all_saturation_sgd_df])

    fig, axs = plt.subplots(2, 2, figsize=fig_size, layout="compressed")

    unique_RF = all_df["RF"].unique()

    colors = ["red", "blue", "green"]
    optimisers = ["SGD", "ASAM", "EKFAC"]

    # for i, ax in  enumerate(axs.flat):

    #   sharpness_df_rf = all_df[all_df["RF"]==unique_RF[i]]

    #   for j, opt in enumerate(optimisers):

    #     current_df=sharpness_df_rf[sharpness_df_rf["optimiser"]==opt]

    #     epoch_df_dense, pm = extract_layer_stat(current_df,
    #                        epoch=0,
    #                        primary_metric=None,
    #                        stat='saturation',
    #                        state_mode="train")

    #     plot_saturation(epoch_df=epoch_df_dense,ax=ax,color=colors[j],label=opt)
    #     # ax.set_xticks(range(len(epoch_df_dense.columns)),range(len(epoch_df_dense.columns)))
    #     ax.set_xticks([],[])
    #     ax.set_xlabel("")

    #   ax.set_title(f"RF={unique_RF[i]}")

    # ax.legend(loc="upper right")
    # plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet50__cifar10_adaptative_sharpness_optim_saturation.pdf")
    plt.close()

    sns.pairplot(all_df, hue="optimiser", markers=["o", "s", "D"])
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet50_cifar10_adaptative_sharpness_optim_full.pdf")
    plt.close()

    sharpness_df = all_df.filter(items=["sharpness_obj", "sharpness_err", "RF", "optimiser"])

    sharpness_df = sharpness_df.rename(
        columns={"sharpness_obj": "$l_{\infty}$-Worst case Sharpness", "sharpness_err": "$\sigma_{l_{\infty}}$",
                 "optimiser": "Optimiser"})
    sns.pairplot(sharpness_df, hue="Optimiser", markers=["o", "s", "D"])
    # plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet50__cifar10_adaptative_sharpness_optim_short.pdf")
    plt.close()

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    sns.scatterplot(data=sharpness_df, x="RF", y="$l_{\infty}$-Worst case Sharpness", hue="Optimiser")
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.set_ylabel("
    # secay.tick_params(axis='x',labelrotation=90)

    axs.set_xlabel("Receptive Field", fontsize=25)
    axs.set_ylabel("$l_{\infty}$-Worst case Sharpness", fontsize=25)

    # axs.legend(prop={"size": fs*1.7})
    axs.legend(prop={"size": fs * 1.7}, bbox_to_anchor=(0.78, 0.7), loc='upper left', borderaxespad=0.1)
    # plt.legend(bbox_to_anchor=(1.005, 1), loc='upper left', borderaxespad=0.1)
    plt.savefig(
        "/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet50_cifar10_worst_case_l_infty_sharpness_vs_RF_optim.pdf")
    plt.close()

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    sns.scatterplot(data=sharpness_df, x="RF", y="$\sigma_{l_{\infty}}$", hue="Optimiser")
    # plt.legend(bbox_to_anchor=(1.005, 1), loc='upper left', borderaxespad=0.1)
    plt.savefig(
        "/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet50_cifar10_worst_case_sharpness_err_vs_RF_optim.pdf")
    plt.close()

    """## VGG19 x CIFAR10"""

    vgg_ekfac_sharpness_df_1 = pd.read_csv(
        "sharpness_results/vgg19_1_cifar10_ekfac_optim_hyper_saturation_200_gc_0_sharpness_summary.csv", delimiter=",")
    vgg_ekfac_sharpness_df_1["RF"] = [vgg_rfs[1]] * len(vgg_ekfac_sharpness_df_1)
    vgg_ekfac_sharpness_df_2 = pd.read_csv(
        "sharpness_results/vgg19_2_cifar10_ekfac_optim_hyper_saturation_200_gc_0_sharpness_summary.csv", delimiter=",")
    vgg_ekfac_sharpness_df_2["RF"] = [vgg_rfs[2]] * len(vgg_ekfac_sharpness_df_2)
    vgg_ekfac_sharpness_df_3 = pd.read_csv(
        "sharpness_results/vgg19_3_cifar10_ekfac_optim_hyper_saturation_200_gc_0_sharpness_summary.csv", delimiter=",")
    vgg_ekfac_sharpness_df_3["RF"] = [vgg_rfs[3]] * len(vgg_ekfac_sharpness_df_3)
    vgg_ekfac_sharpness_df_4 = pd.read_csv(
        "sharpness_results/vgg19_4_cifar10_ekfac_optim_hyper_saturation_200_gc_0_sharpness_summary.csv", delimiter=",")
    vgg_ekfac_sharpness_df_4["RF"] = [vgg_rfs[4]] * len(vgg_ekfac_sharpness_df_4)

    vgg_asam_sharpness_df_1 = pd.read_csv(
        "sharpness_results/vgg19_1_cifar10_sam_optim_saturation_200_gc_0_sharpness_summary.csv", delimiter=",")
    vgg_asam_sharpness_df_1["RF"] = [vgg_rfs[1]] * len(vgg_asam_sharpness_df_1)
    vgg_asam_sharpness_df_2 = pd.read_csv(
        "sharpness_results/vgg19_2_cifar10_sam_optim_saturation_200_gc_0_sharpness_summary.csv", delimiter=",")
    vgg_asam_sharpness_df_2["RF"] = [vgg_rfs[2]] * len(vgg_asam_sharpness_df_2)
    vgg_asam_sharpness_df_3 = pd.read_csv(
        "sharpness_results/vgg19_3_cifar10_sam_optim_saturation_200_gc_0_sharpness_summary.csv", delimiter=",")
    vgg_asam_sharpness_df_3["RF"] = [vgg_rfs[3]] * len(vgg_asam_sharpness_df_3)
    vgg_asam_sharpness_df_4 = pd.read_csv(
        "sharpness_results/vgg19_4_cifar10_sam_optim_saturation_200_gc_0_sharpness_summary.csv", delimiter=",")
    vgg_asam_sharpness_df_4["RF"] = [vgg_rfs[4]] * len(vgg_asam_sharpness_df_4)

    vgg_sgd_sharpness_df_1 = pd.read_csv(
        "sharpness_results/vgg19_1_cifar10_recording_200_no_ffcv_sharpness_summary.csv", delimiter=",")
    vgg_sgd_sharpness_df_1["RF"] = [vgg_rfs[1]] * len(vgg_sgd_sharpness_df_1)
    vgg_sgd_sharpness_df_2 = pd.read_csv(
        "sharpness_results/vgg19_2_cifar10_recording_200_no_ffcv_sharpness_summary.csv", delimiter=",")
    vgg_sgd_sharpness_df_2["RF"] = [vgg_rfs[2]] * len(vgg_sgd_sharpness_df_2)
    vgg_sgd_sharpness_df_3 = pd.read_csv(
        "sharpness_results/vgg19_3_cifar10_recording_200_no_ffcv_sharpness_summary.csv", delimiter=",")
    vgg_sgd_sharpness_df_3["RF"] = [vgg_rfs[3]] * len(vgg_sgd_sharpness_df_3)
    vgg_sgd_sharpness_df_4 = pd.read_csv(
        "sharpness_results/vgg19_4_cifar10_recording_200_no_ffcv_sharpness_summary.csv", delimiter=",")
    vgg_sgd_sharpness_df_4["RF"] = [vgg_rfs[4]] * len(vgg_sgd_sharpness_df_4)

    all_saturation_ekfac_df = pd.concat(
        [vgg_ekfac_sharpness_df_1, vgg_ekfac_sharpness_df_2, vgg_ekfac_sharpness_df_3, vgg_ekfac_sharpness_df_4])
    all_saturation_ekfac_df["optimiser"] = ["EKFAC"] * len(all_saturation_ekfac_df)
    all_saturation_sam_df = pd.concat(
        [vgg_asam_sharpness_df_1, vgg_asam_sharpness_df_2, vgg_asam_sharpness_df_3, vgg_asam_sharpness_df_4])
    all_saturation_sam_df["optimiser"] = ["ASAM"] * len(all_saturation_sam_df)
    all_saturation_sgd_df = pd.concat(
        [vgg_sgd_sharpness_df_1, vgg_sgd_sharpness_df_2, vgg_sgd_sharpness_df_3, vgg_sgd_sharpness_df_4])
    all_saturation_sgd_df["optimiser"] = ["SGD"] * len(all_saturation_sgd_df)

    all_df = pd.concat([all_saturation_ekfac_df, all_saturation_sam_df, all_saturation_sgd_df])

    # fig,axs=plt.subplots(2,2,figsize=(10,10),layout="compressed")

    unique_RF = all_df["RF"].unique()

    colors = ["red", "blue", "green"]
    optimisers = ["SGD", "ASAM", "EKFAC"]

    # for i, ax in  enumerate(axs.flat):

    #   sharpness_df_rf = all_df[all_df["RF"]==unique_RF[i]]

    #   for j, opt in enumerate(optimisers):

    #     current_df=sharpness_df_rf[sharpness_df_rf["optimiser"]==opt]

    #     epoch_df_dense, pm = extract_layer_stat(current_df,
    #                        epoch=0,
    #                        primary_metric=None,
    #                        stat='saturation',
    #                        state_mode="train")

    #     plot_saturation(epoch_df=epoch_df_dense,ax=ax,color=colors[j],label=opt)
    #     # ax.set_xticks(range(len(epoch_df_dense.columns)),range(len(epoch_df_dense.columns)))
    #     ax.set_xticks([],[])
    #     ax.set_xlabel("")

    #   ax.set_title(f"RF={unique_RF[i]}")

    # ax.legend(loc="upper right")
    # plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/vgg19__cifar10_adaptative_sharpness_optim_saturation.pdf")
    plt.close()

    sns.pairplot(all_df, hue="optimiser", markers=["o", "s", "D"])
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/vgg19_cifar10_adaptative_sharpness_optim_full.pdf")
    plt.close()

    sharpness_df = all_df.filter(items=["sharpness_obj", "RF", "optimiser"])
    # sharpness_df = sharpness_df.rename(columns={"sharpness_obj":"$l_{\infty}$-Sharpness","sharpness_err":"$\sigma_{l_{\infty}}$","optimiser":"Optimiser"})
    sharpness_df = sharpness_df.rename(
        columns={"sharpness_obj": "$l_{\infty}$-Worst case Sharpness", "sharpness_err": "$\sigma_{l_{\infty}}$",
                 "optimiser": "Optimiser"})
    sns.pairplot(sharpness_df, hue="Optimiser", markers=["o", "s", "D"])
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/vgg19_cifar10_adaptative_sharpness_optim_short.pdf")
    plt.close()

    # plt.legend(bbox_to_anchor=(1.005, 1), loc='upper left', borderaxespad=0.1)

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed")
    sns.scatterplot(data=sharpness_df, x="RF", y="$l_{\infty}$-Worst case Sharpness", hue="Optimiser")
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.set_ylabel("
    # secay.tick_params(axis='x',labelrotation=90)

    axs.set_xlabel("Receptive Field", fontsize=25)
    axs.set_ylabel("$l_{\infty}$-Worst case Sharpness", fontsize=25)

    # axs.legend(prop={"size": fs*1.7})
    axs.legend(prop={"size": fs * 1.7}, bbox_to_anchor=(0.78, 0.7), loc='upper left', borderaxespad=0.1)
    # plt.legend(bbox_to_anchor=(1.005, 1), loc='upper left', borderaxespad=0.1)
    plt.savefig(
        "/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/vgg19_cifar10_worst_case_l_infty_sharpness_vs_RF_optim.pdf")

    plt.close()


def large_input_experiments():
    """# TODO: Large input experiments

    Here we repeat the experiments of cifar10 but now with models that have a small receptive field adn the size of the images interpolated to 224.

    ## CIFAR10 (interpolated)

    ### ReseNet25 (mod)
    This is not the original resnet25 is just a version that I did for this particular experiment.

    #### PR = 0.7
    """

    from matplotlib import pyplot as plt
    import seaborn as sns
    import pandas as pd
    from matplotlib.patches import Patch

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    dense1_color = "crimson"
    dense2_color = "palevioletred"
    pruned1_color = "royalblue "
    pruned2_color = "cornflowrblue "
    accuracy_ticks =range(0,110,10)
    # level 5 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.7_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.7_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.7_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.7_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.7_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.7_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.7_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.7_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.7_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.7_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.7_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.7_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.7_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim

    df_level5_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.7_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_asam))
    df_level5_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level5_asam))
    df_level5_asam["optimiser"] = optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.7_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])
    df_level5 = pd.concat([df_level5_ekfac, df_level5_asam, df_level5_sgd])

    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4, df_level5])

    fig_size = (6, 5)
    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser")
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser")





    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))
    secay.set_ylabel('Absolute Pruned Accuracy')
    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)
    plt.close()

    #

    """#### PR = 0.8"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim

    df_level5_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_asam))
    df_level5_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level5_asam))
    df_level5_asam["optimiser"] = optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])
    df_level5 = pd.concat([df_level5_ekfac, df_level5_asam, df_level5_sgd])

    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4, df_level5])
    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])
    all_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])

    fig_size = (6, 5)
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    # sns.barplot(ax=axs[0],data=all_df,x="RF",y="Scaled Pruned Accuracy",hue="optimiser",alpha=0.5)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Dense Accuracy", color="red", alpha=0.3)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Pruned Accuracy", alpha=0.5, color="blue")

    # sns.stripplot(
    #     x="RF",
    #     y="Scaled Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0],legend=False)

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        # hue="optimiser",
        color="red",
        data=all_df, dodge=True, alpha=0.4, ax=ax, legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        # hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=ax, legend=False, color="blue")

    def f(x):
        return x

    def invf(x):
        return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Absolute Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    species = ["Pruned SGD", "Dense SGD"]
    colors = ["cornflowerblue", "red"]

    handles = [
        Patch(facecolor="red", alpha=0.4, label="Dense"),
        Patch(facecolor="cornflowerblue", label="Pruned")
        # for label, color in zip(species,colors)
    ]

    ax.legend(handles=handles, prop={"size": fs * 1.3}, loc="upper right")

    # for ax in axs.flat:
    ax.tick_params(axis='both', which='major', labelsize=fs * 1.5)
    ax.tick_params(axis='x', which='major')
    # ax.set_xlabel("")
    ax.set_ylabel("Accuracy in Test Set", fontsize=fs * 1.7)
    ax.set_xlabel("Receptive Field", fontsize=fs * 1.7)

    fig_multiplier = 1.7

    # fig.text(0.5, -0.019, 'Receptive Field', ha='center', size=fs * fig_multiplier)
    # plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne25_small_cifar10_interpolated_res_224_pr_0.9.pdf")
    plt.close()

    from matplotlib import pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim

    df_level5_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_asam))
    df_level5_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level5_asam))
    df_level5_asam["optimiser"] = optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])
    df_level5 = pd.concat([df_level5_ekfac, df_level5_asam, df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])
    all_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])

    fig_size = (6, 5)

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    all_df["Scaled $\Delta$"] = -(
            (all_df["Pruned Accuracy"] - all_df["Dense Accuracy"]) / all_df["Dense Accuracy"]) * 100
    all_df["Absolute $\Delta$"] = -((all_df["Pruned Accuracy"] - all_df["Dense Accuracy"]))

    # sns.barplot(ax=axs[0],data=all_df,x="RF",y="Scaled Pruned Accuracy",hue="optimiser",alpha=0.5)
    means = []
    stds = []
    raw = []
    for rf in all_df["RF"].unique():
        rf_df = all_df[all_df["RF"] == rf]
        means.append(rf_df["RF"].dropna().mean())
        stds.append(rf_df["RF"].dropna().std())
        raw.append(rf_df["RF"].dropna().values)
    raw.reverse()
    means.reverse()
    stds.reverse()

    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")
    ax.errorbar(x=range(len(means)), y=means, yerr=stds, ecolor="c", marker='o', mfc='red', capsize=2,
                markeredgewidth=1, markeredgecolor="k", ls="none")

    sns.barplot(ax=ax, data=all_df, x="RF", y="Dense Accuracy", color="red", alpha=0.3)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Pruned Accuracy", alpha=0.5, color="blue")

    # sns.stripplot(
    #     x="RF",
    #     y="Scaled Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0],legend=False)

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        # hue="optimiser",
        color="red",
        data=all_df, dodge=True, alpha=0.4, ax=ax, legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        # hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=ax, legend=False, color="blue")

    def f(x):
        return x

    def invf(x):
        return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Absolute Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    species = ["Pruned SGD", "Dense SGD"]
    colors = ["cornflowerblue", "red"]

    handles = [
        Patch(facecolor="red", alpha=0.4, label="Dense"),
        Patch(facecolor="cornflowerblue", label="Pruned")
        # for label, color in zip(species,colors)
    ]

    ax.legend(handles=handles, prop={"size": fs * 1.3}, loc="upper right")

    # for ax in axs.flat:
    ax.tick_params(axis='both', which='major', labelsize=fs * 1.5)
    ax.tick_params(axis='x', which='major')
    # ax.set_xlabel("")
    ax.set_ylabel("Accuracy in Test Set", fontsize=fs * 1.7)
    ax.set_xlabel("Receptive Field", fontsize=fs * 1.7)

    fig_multiplier = 1.7

    # fig.text(0.5, -0.019, 'Receptive Field', ha='center', size=fs * fig_multiplier)
    plt.savefig(
        f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne25_small_cifar10_interpolated_res_224_pr_0.8_SGD.pdf")
    plt.close()

    """###### $\Delta$"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim

    df_level5_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_asam))
    df_level5_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level5_asam))
    df_level5_asam["optimiser"] = optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])
    df_level5 = pd.concat([df_level5_ekfac, df_level5_asam, df_level5_sgd])

    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4, df_level5])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    all_df["Scaled $\Delta$"] = -(
            (all_df["Pruned Accuracy"] - all_df["Dense Accuracy"]) / all_df["Dense Accuracy"]) * 100
    all_df["Absolute $\Delta$"] = -((all_df["Pruned Accuracy"] - all_df["Dense Accuracy"]))

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled $\Delta$", hue="optimiser", alpha=0.5)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Absolute $\Delta$", hue="optimiser", alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Scaled $\Delta$",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)
    sns.stripplot(
        x="RF",
        y="Absolute $\Delta$",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))

    secay.set_ylabel('Absolute $\Delta$')

    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    plt.close()

    """Here it appears that for every optimiser there is a behaviour of increasing prunability then decreasing and finally, increasing again. The exact receptive field for which this happens are different for each optimiser. This might be due to the different sensibility of the models to pruning due to the representations learned."""

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)
    sns.barplot(
        x="RF",
        y="Dense Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.5, ax=axs)
    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs, legend=False)

    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelrotation=90)
    plt.title("Dense Accuracy")
    plt.close()

    """#### PR = 0.9"""

    from matplotlib import pyplot as plt
    from matplotlib.patches import Patch
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim

    df_level5_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_asam))
    df_level5_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level5_asam))
    df_level5_asam["optimiser"] = optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])
    df_level5 = pd.concat([df_level5_ekfac, df_level5_asam, df_level5_sgd])

    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4, df_level5])
    # all_df=pd.concat([df_level1_sgd,df_level2_sgd,df_level3_sgd,df_level4_sgd,df_level5_sgd])

    # fig_size=(6,4)
    fig_size = (6, 6)
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    # sns.barplot(ax=axs[0],data=all_df,x="RF",y="Scaled Pruned Accuracy",hue="optimiser",alpha=0.5)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Dense Accuracy", color="red", alpha=0.3)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Pruned Accuracy", alpha=0.5, color="blue")

    # sns.stripplot(
    #     x="RF",
    #     y="Scaled Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0],legend=False)

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        # hue="optimiser",
        color="red",
        data=all_df, dodge=True, alpha=0.4, ax=ax, legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        # hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=ax, legend=False, color="blue")

    def f(x):
        return x

    def invf(x):
        return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Absolute Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    species = ["Pruned SGD", "Dense SGD"]
    colors = ["cornflowerblue", "red"]

    handles = [
        Patch(facecolor="red", alpha=0.4, label="Dense"),
        Patch(facecolor="cornflowerblue", label="Pruned")
        # for label, color in zip(species,colors)
    ]

    ax.legend(handles=handles, prop={"size": fs * 1.3}, loc="center right")

    # for ax in axs.flat:
    ax.tick_params(axis='both', which='major', labelsize=fs * 1.5)
    ax.tick_params(axis='x', which='major')
    # ax.set_xlabel("")
    ax.set_ylabel("Accuracy in Test Set", fontsize=fs * 1.7)
    ax.set_xlabel("Receptive Field", fontsize=fs * 1.7)
    ax.grid(ls="--", alpha=0.5)
    plt.savefig(
        f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne25_small_cifar10_interpolated_res_224_pr_0.9.pdf")
    plt.close()

    from matplotlib import pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim

    df_level5_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_asam))
    df_level5_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level5_asam))
    df_level5_asam["optimiser"] = optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])
    df_level5 = pd.concat([df_level5_ekfac, df_level5_asam, df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])
    all_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])

    fig_size = (6, 5)
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    # sns.barplot(ax=axs[0],data=all_df,x="RF",y="Scaled Pruned Accuracy",hue="optimiser",alpha=0.5)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Dense Accuracy", color="red", alpha=0.3)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Pruned Accuracy", alpha=0.5, color="blue")

    # sns.stripplot(
    #     x="RF",
    #     y="Scaled Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0],legend=False)

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        # hue="optimiser",
        color="red",
        data=all_df, dodge=True, alpha=0.4, ax=ax, legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        # hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=ax, legend=False, color="blue")

    def f(x):
        return x

    def invf(x):
        return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Absolute Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    species = ["Pruned SGD", "Dense SGD"]
    colors = ["cornflowerblue", "red"]

    handles = [
        Patch(facecolor="red", alpha=0.4, label="Dense"),
        Patch(facecolor="cornflowerblue", label="Pruned")
        # for label, color in zip(species,colors)
    ]

    ax.legend(handles=handles, prop={"size": fs * 1.3}, loc="upper right")

    # for ax in axs.flat:
    ax.tick_params(axis='both', which='major', labelsize=fs * 1.5)
    ax.tick_params(axis='x', which='major')
    # ax.set_xlabel("")
    ax.set_ylabel("Accuracy in Test Set", fontsize=fs * 1.7)
    ax.set_xlabel("Receptive Field", fontsize=fs * 1.7)

    fig_multiplier = 1.7

    # fig.text(0.5, -0.019, 'Receptive Field', ha='center', size=fs * fig_multiplier)
    # plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne25_small_cifar10_interpolated_res_224_pr_0.9.pdf")
    plt.close()

    """### Only SGD"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim

    df_level5_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_asam))
    df_level5_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level5_asam))
    df_level5_asam["optimiser"] = optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])
    df_level5 = pd.concat([df_level5_ekfac, df_level5_asam, df_level5_sgd])

    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4, df_level5])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser", alpha=0.5)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False, alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Scaled Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)
    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))
    secay.set_ylabel('Absolute Pruned Accuracy')
    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)
    plt.close()

    """#### PR = 0.8 with batchnorm adjustment (eagle eye)"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_sgd_100_res_224_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_sgd_100_res_224_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_sgd_100_res_224_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_sgd_100_res_224_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim

    df_level5_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_asam))
    df_level5_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level5_asam))
    df_level5_asam["optimiser"] = optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_sgd_100_res_224_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])
    df_level5 = pd.concat([df_level5_ekfac, df_level5_asam, df_level5_sgd])

    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4, df_level5])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    all_df["Scaled $\Delta$"] = -(
            (all_df["Pruned Accuracy"] - all_df["Dense Accuracy"]) / all_df["Dense Accuracy"]) * 100
    all_df["Absolute $\Delta$"] = -((all_df["Pruned Accuracy"] - all_df["Dense Accuracy"]))

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser", alpha=0.5)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False, alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Scaled Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)
    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))

    secay.set_ylabel('Absolute Accuracy')

    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    plt.close()

    """#### PR = 0.9 with batchnorm adjustment (eagle eye)"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_sgd_100_res_224_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_sgd_100_res_224_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_sgd_100_res_224_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_sgd_100_res_224_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim

    df_level5_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_asam))
    df_level5_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level5_asam))
    df_level5_asam["optimiser"] = optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_sgd_100_res_224_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])
    df_level5 = pd.concat([df_level5_ekfac, df_level5_asam, df_level5_sgd])

    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4, df_level5])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    all_df["Scaled $\Delta$"] = -(
            (all_df["Pruned Accuracy"] - all_df["Dense Accuracy"]) / all_df["Dense Accuracy"]) * 100
    all_df["Absolute $\Delta$"] = -((all_df["Pruned Accuracy"] - all_df["Dense Accuracy"]))

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser", alpha=0.5)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False, alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Scaled Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)
    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))

    secay.set_ylabel('Absolute Accuracy')

    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=15)
        ax.tick_params(axis='x', which='major')
        ax._set_xlabel("")

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    plt.close()

    """###### $\Delta$"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim

    df_level5_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_asam))
    df_level5_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level5_asam))
    df_level5_asam["optimiser"] = optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])
    df_level5 = pd.concat([df_level5_ekfac, df_level5_asam, df_level5_sgd])

    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4, df_level5])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    all_df["Scaled $\Delta$"] = -(
            (all_df["Pruned Accuracy"] - all_df["Dense Accuracy"]) / all_df["Dense Accuracy"]) * 100
    all_df["Absolute $\Delta$"] = -((all_df["Pruned Accuracy"] - all_df["Dense Accuracy"]))

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled $\Delta$", hue="optimiser", alpha=0.5)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Absolute $\Delta$", hue="optimiser", legend=False, alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Scaled $\Delta$",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)
    sns.stripplot(
        x="RF",
        y="Absolute $\Delta$",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))

    secay.set_ylabel('Absolute $\Delta$')

    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    plt.close()

    """Here it appears that for every optimiser there is a behaviour of increasing prunability then decreasing and finally, increasing again. The exact receptive field for which this happens are different for each optimiser. This might be due to the different sensibility of the models to pruning due to the representations learned."""

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)
    sns.barplot(
        x="RF",
        y="Dense Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.5, ax=axs)
    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs, legend=False)

    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelrotation=90)
    plt.title("Dense Accuracy")
    plt.close()

    """#### PR = 0.95 with batchnorm adjustment (eagle eye)"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.95_ekfac_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.95_sam_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.95_sgd_100_res_224_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.95_ekfac_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.95_sam_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.95_sgd_100_res_224_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.95_ekfac_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.95_sam_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.95_sgd_100_res_224_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.95_ekfac_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.95_sam_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.95_sgd_100_res_224_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.95_ekfac_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim

    df_level5_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.95_sam_cifar10_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_asam))
    df_level5_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level5_asam))
    df_level5_asam["optimiser"] = optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.95_sgd_100_res_224_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])
    df_level5 = pd.concat([df_level5_ekfac, df_level5_asam, df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])
    all_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])

    fig_size = (6, 5)
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    sns.barplot(ax=ax, data=all_df, x="RF", y="Dense Accuracy", color="red", legend=False, alpha=0.3)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Pruned Accuracy", legend=False, alpha=0.5, color="blue")

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        color="red",
        data=all_df, dodge=True, alpha=0.4, ax=ax, legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        data=all_df, dodge=True, alpha=0.6, ax=ax, legend=False, color="blue")

    def f(x):
        return x

    def invf(x):
        return x

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    species = ["Pruned SGD", "Dense SGD"]
    colors = ["cornflowerblue", "red"]

    handles = [
        Patch(facecolor="red", alpha=0.4, label="Dense"),
        Patch(facecolor="cornflowerblue", label="Pruned")
        # for label, color in zip(species,colors)
    ]

    # ax.legend(handles=handles,prop={"size": fs*1.3}, loc="lower right")

    # for ax in axs.flat:
    ax.tick_params(axis='both', which='major', labelsize=fs * 1.5)
    ax.tick_params(axis='x', which='major')
    # ax.set_xlabel("")
    ax.set_ylabel("Accuracy in Test Set", fontsize=fs * 1.7)
    ax.set_xlabel("Receptive Field", fontsize=fs * 1.7)

    plt.close()

    """###### $\Delta$"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim

    df_level5_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_asam))
    df_level5_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level5_asam))
    df_level5_asam["optimiser"] = optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])
    df_level5 = pd.concat([df_level5_ekfac, df_level5_asam, df_level5_sgd])

    all_df = pd.concat([df_level1, df_level2, df_level3, df_level4, df_level5])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    all_df["Scaled $\Delta$"] = -(
            (all_df["Pruned Accuracy"] - all_df["Dense Accuracy"]) / all_df["Dense Accuracy"]) * 100
    all_df["Absolute $\Delta$"] = -((all_df["Pruned Accuracy"] - all_df["Dense Accuracy"]))

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled $\Delta$", hue="optimiser", alpha=0.5)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Absolute $\Delta$", hue="optimiser", legend=False, alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Scaled $\Delta$",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)
    sns.stripplot(
        x="RF",
        y="Absolute $\Delta$",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))

    secay.set_ylabel('Absolute $\Delta$')

    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    plt.close()

    """Here it appears that for every optimiser there is a behaviour of increasing prunability then decreasing and finally, increasing again. The exact receptive field for which this happens are different for each optimiser. This might be due to the different sensibility of the models to pruning due to the representations learned."""

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)
    sns.barplot(
        x="RF",
        y="Dense Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.5, ax=axs)
    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs, legend=False)

    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelrotation=90)
    plt.title("Dense Accuracy")
    plt.close()

    """## CIFAR10 32x32

    ### Resenet25 (mod)

    #### PR = 0.8
    """

    from matplotlib import pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    all_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])
    fig_size = (6, 5)
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    # all_df["Scaled $\Delta$"]=-((all_df["Pruned Accuracy"]-all_df["Dense Accuracy"])/all_df["Dense Accuracy"])*100
    # all_df["Absolute $\Delta$"]=-((all_df["Pruned Accuracy"]-all_df["Dense Accuracy"]))

    # sns.barplot(ax=axs[0],data=all_df,x="RF",y="Scaled Pruned Accuracy",hue="optimiser",alpha=0.5)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Dense Accuracy", color="red", legend=False, alpha=0.3)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Pruned Accuracy", legend=False, alpha=0.5, color="blue")

    # sns.stripplot(
    #     x="RF",
    #     y="Scaled Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0],legend=False)

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        # hue="optimiser",
        color="red",
        data=all_df, dodge=True, alpha=0.4, ax=ax, legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        # hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=ax, legend=False, color="blue")

    def f(x):
        return x

    def invf(x):
        return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Absolute Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    species = ["Pruned SGD", "Dense SGD"]
    colors = ["cornflowerblue", "red"]

    handles = [
        Patch(facecolor="red", alpha=0.4, label="Dense"),
        Patch(facecolor="cornflowerblue", label="Pruned")
        # for label, color in zip(species,colors)
    ]

    ax.legend(handles=handles, prop={"size": fs * 1.3}, loc="lower right")

    # for ax in axs.flat:
    ax.tick_params(axis='both', which='major', labelsize=fs * 1.5)
    ax.tick_params(axis='x', which='major')
    # ax.set_xlabel("")
    ax.set_ylabel("Accuracy in Test Set", fontsize=fs * 1.7)
    ax.set_xlabel("Receptive Field", fontsize=fs * 1.7)

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')
    fig_multiplier = 1.5
    # fig.text(0.5, -0.019, 'Receptive Field', ha='center', size=fs * fig_multiplier)
    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    plt.savefig(
        f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet25_small_cifar10_interpolated_res_32_pr_0.8.pdf")
    plt.close()

    """##### $Δ$"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    all_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    all_df["Scaled $\Delta$"] = -(
            (all_df["Pruned Accuracy"] - all_df["Dense Accuracy"]) / all_df["Dense Accuracy"]) * 100
    all_df["Absolute $\Delta$"] = -((all_df["Pruned Accuracy"] - all_df["Dense Accuracy"]))

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled $\Delta$", hue="optimiser", alpha=0.5)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Absolute $\Delta$", hue="optimiser", legend=False, alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Scaled $\Delta$",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)
    sns.stripplot(
        x="RF",
        y="Absolute $\Delta$",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))

    secay.set_ylabel('Absolute $\Delta$')

    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    plt.close()

    """Here it appears that for every optimiser there is a behaviour of increasing prunability then decreasing and finally, increasing again. The exact receptive field for which this happens are different for each optimiser. This might be due to the different sensibility of the models to pruning due to the representations learned."""

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)
    sns.barplot(
        x="RF",
        y="Dense Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.5, ax=axs)
    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs, legend=False)

    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelrotation=90)
    plt.title("Dense Accuracy")
    plt.close()

    """#### PR = 0.9"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    all_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])

    # fig_size=(6,5)

    fig_size = (6, 6)

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    # all_df["Scaled $\Delta$"]=-((all_df["Pruned Accuracy"]-all_df["Dense Accuracy"])/all_df["Dense Accuracy"])*100
    # all_df["Absolute $\Delta$"]=-((all_df["Pruned Accuracy"]-all_df["Dense Accuracy"]))

    # sns.barplot(ax=axs[0],data=all_df,x="RF",y="Scaled Pruned Accuracy",hue="optimiser",alpha=0.5)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Dense Accuracy", color="red", legend=False, alpha=0.3)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Pruned Accuracy", legend=False, alpha=0.5, color="blue")

    # sns.stripplot(
    #     x="RF",
    #     y="Scaled Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0],legend=False)

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        # hue="optimiser",
        color="red",
        data=all_df, dodge=True, alpha=0.4, ax=ax, legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        # hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=ax, legend=False, color="blue")

    def f(x):
        return x

    def invf(x):
        return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Absolute Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    species = ["Pruned SGD", "Dense SGD"]
    colors = ["cornflowerblue", "red"]

    handles = [
        Patch(facecolor="red", alpha=0.4, label="Dense"),
        Patch(facecolor="cornflowerblue", label="Pruned")
        # for label, color in zip(species,colors)
    ]

    # ax.legend(handles=handles,prop={"size": fs*1.3}, loc="lower right")

    # for ax in axs.flat:
    ax.tick_params(axis='both', which='major', labelsize=fs * 1.5)
    ax.tick_params(axis='x', which='major')
    # ax.set_xlabel("")
    ax.set_ylabel("Accuracy in Test Set", fontsize=fs * 1.7)
    ax.set_xlabel("Receptive Field", fontsize=fs * 1.7)

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')
    fig_multiplier = 1.5
    # fig.text(0.5, -0.019, 'Receptive Field', ha='center', size=fs * fig_multiplier)

    ax.grid(ls="--", alpha=0.5)
    plt.savefig(
        f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet25_small_cifar10_interpolated_res_32_pr_0.9.pdf")
    plt.close()

    """##### $Δ$"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    all_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    all_df["Scaled $\Delta$"] = -(
            (all_df["Pruned Accuracy"] - all_df["Dense Accuracy"]) / all_df["Dense Accuracy"]) * 100
    all_df["Absolute $\Delta$"] = -((all_df["Pruned Accuracy"] - all_df["Dense Accuracy"]))

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled $\Delta$", hue="optimiser", alpha=0.5)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Absolute $\Delta$", hue="optimiser", legend=False, alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Scaled $\Delta$",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)
    sns.stripplot(
        x="RF",
        y="Absolute $\Delta$",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))

    secay.set_ylabel('Absolute $\Delta$')

    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    plt.close()

    """Here it appears that for every optimiser there is a behaviour of increasing prunability then decreasing and finally, increasing again. The exact receptive field for which this happens are different for each optimiser. This might be due to the different sensibility of the models to pruning due to the representations learned."""

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)
    sns.barplot(
        x="RF",
        y="Dense Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.5, ax=axs)
    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs, legend=False)

    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelrotation=90)
    plt.title("Dense Accuracy")
    plt.close()

    """### BN Adjusted

    #### PR = 0.8
    """

    from matplotlib import pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_ekfac_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_sam_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.8_sgd_200_res_32_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_ekfac_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_sam_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.8_sgd_200_res_32_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_ekfac_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_sam_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.8_sgd_200_res_32_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_ekfac_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_sam_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.8_sgd_200_res_32_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_ekfac_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_sam_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.8_sgd_200_res_32_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    all_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    # all_df["Scaled $\Delta$"]=-((all_df["Pruned Accuracy"]-all_df["Dense Accuracy"])/all_df["Dense Accuracy"])*100
    # all_df["Absolute $\Delta$"]=-((all_df["Pruned Accuracy"]-all_df["Dense Accuracy"]))

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser", alpha=0.5)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False, alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Scaled Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)
    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))

    secay.set_ylabel('Absolute Pruned Accuracy')

    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    plt.close()

    """##### $Δ$"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    all_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    all_df["Scaled $\Delta$"] = -(
            (all_df["Pruned Accuracy"] - all_df["Dense Accuracy"]) / all_df["Dense Accuracy"]) * 100
    all_df["Absolute $\Delta$"] = -((all_df["Pruned Accuracy"] - all_df["Dense Accuracy"]))

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled $\Delta$", hue="optimiser", alpha=0.5)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Absolute $\Delta$", hue="optimiser", legend=False, alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Scaled $\Delta$",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)
    sns.stripplot(
        x="RF",
        y="Absolute $\Delta$",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))

    secay.set_ylabel('Absolute $\Delta$')

    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    plt.close()

    """Here it appears that for every optimiser there is a behaviour of increasing prunability then decreasing and finally, increasing again. The exact receptive field for which this happens are different for each optimiser. This might be due to the different sensibility of the models to pruning due to the representations learned."""

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)
    sns.barplot(
        x="RF",
        y="Dense Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.5, ax=axs)
    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs, legend=False)

    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelrotation=90)
    plt.title("Dense Accuracy")
    plt.close()

    """#### PR = 0.9"""

    from matplotlib import pyplot as plt
    import seaborn as sns
    from matplotlib.patches import Patch

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_sgd_200_res_32_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_sgd_200_res_32_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_sgd_200_res_32_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_sgd_200_res_32_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_sgd_200_res_32_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    all_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])

    fig_size = (6, 5)
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    sns.barplot(ax=ax, data=all_df, x="RF", y="Dense Accuracy", color="red", legend=False, alpha=0.3)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Pruned Accuracy", legend=False, alpha=0.5, color="blue")

    # sns.stripplot(
    #     x="RF",
    #     y="Scaled Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0],legend=False)

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        # hue="optimiser",
        color="red",
        data=all_df, dodge=True, alpha=0.4, ax=ax, legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        # hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=ax, legend=False, color="blue")

    def f(x):
        return x

    def invf(x):
        return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Absolute Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    species = ["Pruned SGD", "Dense SGD"]
    colors = ["cornflowerblue", "red"]

    handles = [
        Patch(facecolor="red", alpha=0.4, label="Dense"),
        Patch(facecolor="cornflowerblue", label="Pruned")
        # for label, color in zip(species,colors)
    ]

    # ax.legend(handles=handles,prop={"size": fs*1.3}, loc="lower right")

    # for ax in axs.flat:
    ax.tick_params(axis='both', which='major', labelsize=fs * 1.5)
    ax.tick_params(axis='x', which='major')
    # ax.set_xlabel("")
    ax.set_ylabel("Accuracy in Test Set", fontsize=fs * 1.7)
    ax.set_xlabel("Receptive Field", fontsize=fs * 1.7)
    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    plt.close()

    """##### $Δ$"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_ekfac_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_sam_cifar10_200_res_32_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    all_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    all_df["Scaled $\Delta$"] = -(
            (all_df["Pruned Accuracy"] - all_df["Dense Accuracy"]) / all_df["Dense Accuracy"]) * 100
    all_df["Absolute $\Delta$"] = -((all_df["Pruned Accuracy"] - all_df["Dense Accuracy"]))

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled $\Delta$", hue="optimiser", alpha=0.5)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Absolute $\Delta$", hue="optimiser", legend=False, alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Scaled $\Delta$",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)
    sns.stripplot(
        x="RF",
        y="Absolute $\Delta$",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))

    secay.set_ylabel('Absolute $\Delta$')

    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    plt.close()

    """Here it appears that for every optimiser there is a behaviour of increasing prunability then decreasing and finally, increasing again. The exact receptive field for which this happens are different for each optimiser. This might be due to the different sensibility of the models to pruning due to the representations learned."""

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)
    sns.barplot(
        x="RF",
        y="Dense Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.5, ax=axs)
    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs, legend=False)

    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelrotation=90)
    plt.title("Dense Accuracy")
    plt.close()

    """#### PR = 0.95"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_cifar10_0.95_ekfac_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_cifar10_0.95_sam_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.95_sgd_200_res_32_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_cifar10_0.95_ekfac_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_cifar10_0.95_sam_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.95_sgd_200_res_32_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_cifar10_0.95_ekfac_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_cifar10_0.95_sam_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.95_sgd_200_res_32_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_cifar10_0.95_ekfac_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_cifar10_0.95_sam_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.95_sgd_200_res_32_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_cifar10_0.95_ekfac_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_cifar10_0.95_sam_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.95_sgd_200_res_32_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    all_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])
    fig_size = (6, 5)
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    sns.barplot(ax=ax, data=all_df, x="RF", y="Dense Accuracy", color="red", legend=False, alpha=0.3)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Pruned Accuracy", legend=False, alpha=0.5, color="blue")

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        color="red",
        data=all_df, dodge=True, alpha=0.4, ax=ax, legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        data=all_df, dodge=True, alpha=0.6, ax=ax, legend=False, color="blue")

    def f(x):
        return x

    def invf(x):
        return x

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    species = ["Pruned SGD", "Dense SGD"]
    colors = ["cornflowerblue", "red"]

    handles = [
        Patch(facecolor="red", alpha=0.4, label="Dense"),
        Patch(facecolor="cornflowerblue", label="Pruned")
        # for label, color in zip(species,colors)
    ]

    # ax.legend(handles=handles,prop={"size": fs*1.3}, loc="lower right")

    # for ax in axs.flat:
    ax.tick_params(axis='both', which='major', labelsize=fs * 1.5)
    ax.tick_params(axis='x', which='major')
    # ax.set_xlabel("")
    ax.set_ylabel("Accuracy in Test Set", fontsize=fs * 1.7)
    ax.set_xlabel("Receptive Field", fontsize=fs * 1.7)

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    plt.close()

    """#### PR = 0.99"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_cifar10_0.99_ekfac_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_cifar10_0.99_sam_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.99_sgd_200_res_32_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_cifar10_0.99_ekfac_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_cifar10_0.99_sam_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.99_sgd_200_res_32_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_cifar10_0.99_ekfac_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_cifar10_0.99_sam_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.99_sgd_200_res_32_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_cifar10_0.99_ekfac_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_cifar10_0.99_sam_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.99_sgd_200_res_32_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_cifar10_0.99_ekfac_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_cifar10_0.99_sam_cifar10_200_res_32_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.99_sgd_200_res_32_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim \
 \
        # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    all_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])

    fig_size = (6, 5)
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    sns.barplot(ax=ax, data=all_df, x="RF", y="Dense Accuracy", color="red", legend=False, alpha=0.3)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Pruned Accuracy", legend=False, alpha=0.5, color="blue")

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        color="red",
        data=all_df, dodge=True, alpha=0.4, ax=ax, legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        data=all_df, dodge=True, alpha=0.6, ax=ax, legend=False, color="blue")

    def f(x):
        return x

    def invf(x):
        return x

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    species = ["Pruned SGD", "Dense SGD"]
    colors = ["cornflowerblue", "red"]

    handles = [
        Patch(facecolor="red", alpha=0.4, label="Dense"),
        Patch(facecolor="cornflowerblue", label="Pruned")
        # for label, color in zip(species,colors)
    ]

    # ax.legend(handles=handles,prop={"size": fs*1.3}, loc="lower right")

    # for ax in axs.flat:
    ax.tick_params(axis='both', which='major', labelsize=fs * 1.5)
    ax.tick_params(axis='x', which='major')
    # ax.set_xlabel("")
    ax.set_ylabel("Accuracy in Test Set", fontsize=fs * 1.7)
    ax.set_xlabel("Receptive Field", fontsize=fs * 1.7)

    plt.close()

    """# TODO: Small ImageNet

    ## ResNet25

    ## Dense
    """

    from matplotlib import pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.8_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.8_sgd_100_res_224_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.8_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.8_sgd_100_res_224_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.8_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.8_sgd_100_res_224_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.8_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.8_sgd_100_res_224_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.8_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.8_sgd_100_res_224_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level6_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_11_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[11]] * len(df_level6_sgd))
    df_level6_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level6_sgd))
    df_level6_sgd["optimiser"] = optim

    df_level7_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_12_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[12]] * len(df_level7_sgd))
    df_level7_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level7_sgd))
    df_level7_sgd["optimiser"] = optim

    df_level8_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_13_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[13]] * len(df_level8_sgd))
    df_level8_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level8_sgd))
    df_level8_sgd["optimiser"] = optim

    # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    # all_df=pd.concat([df_level1_sgd,df_level2_sgd,df_level3_sgd,df_level4_sgd,df_level5_sgd])

    all_df = pd.concat(
        [df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd, df_level6_sgd, df_level7_sgd,
         df_level8_sgd])

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)
    sns.barplot(
        x="RF",
        y="Dense Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.5, ax=axs)
    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs, legend=False)

    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    axs.tick_params(axis='x', which='major', labelrotation=90)
    plt.title("Dense Accuracy")
    plt.close()

    """### PR=0.7"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.7_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.7_sam_small_imagenet_100_res_224_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.7_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.7_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.7_sam_small_imagenet_100_res_224_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.7_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.7_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.7_sam_small_imagenet_100_res_224_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.7_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.7_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.7_sam_small_imagenet_100_res_224_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.7_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.7_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.7_sam_small_imagenet_100_res_224_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.7_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    all_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    # all_df["Scaled $\Delta$"]=-((all_df["Pruned Accuracy"]-all_df["Dense Accuracy"])/all_df["Dense Accuracy"])*100
    # all_df["Absolute $\Delta$"]=-((all_df["Pruned Accuracy"]-all_df["Dense Accuracy"]))

    # sns.barplot(ax=axs[0],data=all_df,x="RF",y="Scaled Pruned Accuracy",hue="optimiser",alpha=0.5)
    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)

    # sns.stripplot(
    #     x="RF",
    #     y="Scaled Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0],legend=False)
    # sns.stripplot(
    #     x="RF",
    #     y="Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[1],legend=False)

    # def f(x):
    #   return x

    # def invf(x):
    #   return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Absolute Pruned Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    # # secay.tick_params(axis='x',labelrotation=90)

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    # for ax in axs.flat:
    #   ax.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    #   ax.tick_params(axis='x', which='major', labelrotation=90)

    # # remove extra legend handles
    # # handles, labels = ax.get_legend_handles_labels()
    # # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')
    # # plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne25_small_small_imagenet_ress_2224_pr_0.7.pdf")

    # plt.close()

    ###############################
    #         New plots
    ###############################

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser", alpha=0.5)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Dense Accuracy", color="red", legend=False, alpha=0.3)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False, alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Scaled Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        # hue="optimiser",
        color="red",
        data=all_df, dodge=True, alpha=0.4, ax=axs[1], legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))

    secay.set_ylabel('Absolute Accuracy')

    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    species = ["Pruned SGD", "Dense SGD"]
    colors = ["cornflowerblue", "red"]

    handles = [
        Patch(facecolor=color, label=label)
        for label, color in zip(species, colors)
    ]

    axs[1].legend(handles=handles)

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
        ax.tick_params(axis='x', which='major', labelrotation=90)

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    plt.close()

    """### PR=0.8"""

    from matplotlib import pyplot as plt
    from matplotlib.patches import Patch
    import seaborn as sns
    import pandas as pd

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.8_sam_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.8_sam_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.8_sam_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.8_sam_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.8_sam_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    # df_level6_sgd = pd.read_csv("large_input_pruning_results/RF_resnet25_small_11_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[11]]*len(df_level6_sgd))
    # df_level6_sgd["RF"]=RF
    # optim=[]
    # optim.extend(["SGD"]*len(df_level6_sgd))
    # df_level6_sgd["optimiser"]=optim

    # df_level7_sgd = pd.read_csv("large_input_pruning_results/RF_resnet25_small_12_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[12]]*len(df_level7_sgd))
    # df_level7_sgd["RF"]=RF
    # optim=[]
    # optim.extend(["SGD"]*len(df_level7_sgd))
    # df_level7_sgd["optimiser"]=optim

    # df_level8_sgd = pd.read_csv("large_input_pruning_results/RF_resnet25_small_13_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[13]]*len(df_level8_sgd))
    # df_level8_sgd["RF"]=RF
    # optim=[]
    # optim.extend(["SGD"]*len(df_level8_sgd))
    # df_level8_sgd["optimiser"]=optim

    # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    all_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])
    fig_size = (6, 5)
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    all_df["Scaled $\Delta$"] = -(
            (all_df["Pruned Accuracy"] - all_df["Dense Accuracy"]) / all_df["Dense Accuracy"]) * 100
    all_df["Absolute $\Delta$"] = -((all_df["Pruned Accuracy"] - all_df["Dense Accuracy"]))

    ###############################
    #         New plots
    ###############################

    # sns.barplot(ax=axs[0],data=all_df,x="RF",y="Scaled Pruned Accuracy",hue="optimiser",alpha=0.5)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Dense Accuracy", color="red", legend=False, alpha=0.3)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Pruned Accuracy", legend=False, alpha=0.5, color="blue")

    # sns.stripplot(
    #     x="RF",
    #     y="Scaled Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0],legend=False)

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        # hue="optimiser",
        color="red",
        data=all_df, dodge=True, alpha=0.4, ax=ax, legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        # hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=ax, legend=False, color="blue")

    def f(x):
        return x

    def invf(x):
        return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Absolute Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    species = ["Pruned SGD", "Dense SGD"]
    colors = ["cornflowerblue", "red"]

    handles = [
        Patch(facecolor="red", alpha=0.4, label="Dense"),
        Patch(facecolor="cornflowerblue", label="Pruned")
        # for label, color in zip(species,colors)
    ]

    ax.legend(handles=handles, prop={"size": fs * 1.3}, loc="lower left")

    # for ax in axs.flat:
    ax.tick_params(axis='both', which='major', labelsize=fs * 1.5)
    ax.tick_params(axis='x', which='major')
    # ax.set_xlabel("")
    ax.set_ylabel("Accuracy in Test Set", fontsize=fs * 1.7)
    ax.set_xlabel("Receptive Field", fontsize=fs * 1.7)
    ax.grid(ls="--", alpha=0.5)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet25_small_small_imagenet_ress_224_pr_0.8.pdf")
    plt.close()

    """### PR=0.9"""

    from matplotlib import pyplot as plt
    from matplotlib.patches import Patch
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.9_ekfac_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.9_sam_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.9_ekfac_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.9_sam_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.9_ekfac_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.9_sam_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.9_ekfac_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.9_sam_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.9_ekfac_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.9_sam_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    all_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    # all_df["Scaled $\Delta$"]=-((all_df["Pruned Accuracy"]-all_df["Dense Accuracy"])/all_df["Dense Accuracy"])*100
    # all_df["Absolute $\Delta$"]=-((all_df["Pruned Accuracy"]-all_df["Dense Accuracy"]))

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser", alpha=0.5)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Dense Accuracy", color="red", legend=False, alpha=0.3)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False, alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Scaled Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        # hue="optimiser",
        color="red",
        data=all_df, dodge=True, alpha=0.4, ax=axs[1], legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1])

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))

    secay.set_ylabel('Absolute Accuracy')

    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    # species=["Pruned","Dense"]
    # colors=["cornflowerblue","red"]

    # handles = [
    #     Patch(facecolor=color, label=label)
    #     for label, color in zip(species,colors)
    # ]

    # axs[1].legend(handles=handles)

    # axs[1]

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=15)
        ax.tick_params(axis='x', which='major')
        ax.set_xlabel("")

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')
    fig_multiplier = 1.7
    fig.text(0.5, -0.019, 'Receptive Field', ha='center', size=fs * fig_multiplier)

    # plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne25_small_small_imagenet_ress_224_pr_0.9.pdf")
    # plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne25_small_small_imagenet_ress_2224_pr_0.9.pdf")
    plt.close()

    """### PR=0.95"""

    from matplotlib import pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10]
    resnets_rfs_values = [128, 153, 178, 203, 253]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.95_ekfac_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.95_sam_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.95_ekfac_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.95_sam_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.95_ekfac_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.95_sam_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.95_ekfac_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.95_sam_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.95_ekfac_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.95_sam_small_imagenet_100_res_224_no_ffcv_gc_0_global_one_shot_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    all_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    # all_df["Scaled $\Delta$"]=-((all_df["Pruned Accuracy"]-all_df["Dense Accuracy"])/all_df["Dense Accuracy"])*100
    # all_df["Absolute $\Delta$"]=-((all_df["Pruned Accuracy"]-all_df["Dense Accuracy"]))

    # sns.barplot(ax=axs[0],data=all_df,x="RF",y="Scaled Pruned Accuracy",hue="optimiser",alpha=0.5)
    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)

    # sns.stripplot(
    #     x="RF",
    #     y="Scaled Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0],legend=False)
    # sns.stripplot(
    #     x="RF",
    #     y="Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[1],legend=False)

    # def f(x):
    #   return x

    # def invf(x):
    #   return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Absolute Pruned Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    # # secay.tick_params(axis='x',labelrotation=90)

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    # for ax in axs.flat:
    #   ax.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    #   ax.tick_params(axis='x', which='major', labelrotation=90)

    # # remove extra legend handles
    # # handles, labels = ax.get_legend_handles_labels()
    # # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    # # plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne25_small_small_imagenet_ress_2224_pr_0.9.pdf")
    plt.close()

    #######################
    #       New Plot
    #######################

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser", alpha=0.5)
    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Dense Accuracy",color="red",legend=False,alpha=0.3)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False, alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Scaled Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)

    # sns.stripplot(
    #     x="RF",
    #     y="Dense Accuracy",
    #     # hue="optimiser",
    #     color="red",
    #     data=all_df, dodge=True, alpha=0.4, ax=axs[1],legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))

    secay.set_ylabel('Absolute Accuracy')

    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    # species=["Pruned SGD","Dense SGD"]
    # colors=["cornflowerblue","red"]

    # handles = [
    #     Patch(facecolor=color, label=label)
    #     for label, color in zip(species,colors)
    # ]

    # axs[1].legend(handles=handles,prop={"size": fs*1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=15)
        ax.tick_params(axis='x', which='major')
        ax.set_xlabel("")

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    fig.text(0.5, -0.019, 'Receptive Field', ha='center', size=fs * fig_multiplier)

    # plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne25_small_small_imagenet_res_224_pr_0.95.pdf")
    plt.close()
    """### PR=0.8  with batchnorm adjustment (eagle eye)"""

    from matplotlib import pyplot as plt
    from matplotlib.patches import Patch
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.8_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.8_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.8_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.8_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.8_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level6_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_11_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[11]] * len(df_level6_sgd))
    df_level6_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level6_sgd))
    df_level6_sgd["optimiser"] = optim

    df_level7_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_12_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[12]] * len(df_level7_sgd))
    df_level7_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level7_sgd))
    df_level7_sgd["optimiser"] = optim

    df_level8_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_13_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[13]] * len(df_level8_sgd))
    df_level8_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level8_sgd))
    df_level8_sgd["optimiser"] = optim

    # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    # all_df=pd.concat([df_level1_sgd,df_level2_sgd,df_level3_sgd,df_level4_sgd,df_level5_sgd])

    all_df = pd.concat(
        [df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd, df_level6_sgd, df_level7_sgd,
         df_level8_sgd])

    fig_size = (6, 5)
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    #######################
    #       New Plot
    #######################

    sns.barplot(ax=ax, data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser", alpha=0.5)
    # sns.barplot(ax=ax,data=all_df,x="RF",y="Dense Accuracy",color="red",legend=False,alpha=0.3)
    # sns.barplot(ax=ax,data=all_df,x="RF",y="Pruned Accuracy",legend=False,alpha=0.5,color="blue")

    # sns.stripplot(
    #     x="RF",
    #     y="Scaled Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0],legend=False)

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        # hue="optimiser",
        color="red",
        data=all_df, dodge=True, alpha=0.4, ax=ax, legend=False)

    # sns.stripplot(
    #     x="RF",
    #     y="Pruned Accuracy",
    #     # hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=ax,legend=False,color="blue")

    sns.stripplot(
        x="RF",
        y="Scaled Pruned Accuracy",
        # hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=ax, legend=False, color="blue")

    def f(x):
        return x

    def invf(x):
        return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Absolute Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90) \
    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    species = ["Pruned SGD", "Dense SGD"]
    colors = ["cornflowerblue", "red"]

    handles = [
        # Patch(facecolor="red",alpha=0.4, label="Dense"),
        # Patch(facecolor="cornflowerblue", label="Pruned")
        Patch(facecolor="blue", alpha=0.4, label="Scaled Performance"),
        # Patch(facecolor="cornflowerblue", label="Pruned")
        # for label, color in zip(species,colors)
    ]

    ax.legend(handles=handles, prop={"size": fs * 1.3}, loc="center right")

    # for ax in axs.flat:
    ax.tick_params(axis='both', which='major', labelsize=fs * 1.5)
    ax.tick_params(axis='x', which='major')
    # ax.set_xlabel("")
    ax.set_ylabel("Accuracy in Test Set", fontsize=fs * 1.7)
    ax.set_xlabel("Receptive Field", fontsize=fs * 1.7)

    ax.grid(ls="--", alpha=0.5)

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    plt.savefig(
        f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne25_small_small_imagenet_ress_224_pr_0.8_adjust_bn.pdf")
    # plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne25_small_small_imagenet_bn_adjusted_ress_224_pr_0.9.pdf")
    plt.close()

    """### PR=0.9  with batchnorm adjustment (eagle eye)"""

    from matplotlib import pyplot as plt
    from matplotlib.patches import Patch
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.9_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.9_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.9_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.9_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.9_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.9_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.9_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.9_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.9_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.9_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level6_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_11_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[11]] * len(df_level6_sgd))
    df_level6_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level6_sgd))
    df_level6_sgd["optimiser"] = optim

    df_level7_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_12_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[12]] * len(df_level7_sgd))
    df_level7_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level7_sgd))
    df_level7_sgd["optimiser"] = optim

    df_level8_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_13_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[13]] * len(df_level8_sgd))
    df_level8_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level8_sgd))
    df_level8_sgd["optimiser"] = optim

    # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    # all_df=pd.concat([df_level1_sgd,df_level2_sgd,df_level3_sgd,df_level4_sgd,df_level5_sgd])

    all_df = pd.concat(
        [df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd, df_level6_sgd, df_level7_sgd,
         df_level8_sgd])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    # all_df["Scaled $\Delta$"]=-((all_df["Pruned Accuracy"]-all_df["Dense Accuracy"])/all_df["Dense Accuracy"])*100
    # all_df["Absolute $\Delta$"]=-((all_df["Pruned Accuracy"]-all_df["Dense Accuracy"]))

    sns.barplot(ax=axs[0], data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser", alpha=0.5)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Dense Accuracy", color="red", legend=False, alpha=0.3)
    sns.barplot(ax=axs[1], data=all_df, x="RF", y="Pruned Accuracy", hue="optimiser", legend=False, alpha=0.5)

    sns.stripplot(
        x="RF",
        y="Scaled Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        # hue="optimiser",
        color="red",
        data=all_df, dodge=True, alpha=0.4, ax=axs[1], legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)

    def f(x):
        return x

    def invf(x):
        return x

    secay = axs[1].secondary_yaxis('right', functions=(f, invf))

    secay.set_ylabel('Absolute Accuracy')

    secay.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    axs[0].legend(prop={"size": fs * 1.7}, loc="upper left")

    species = ["Pruned SGD", "Dense SGD"]
    colors = ["cornflowerblue", "red"]

    handles = [
        Patch(facecolor=color, label=label)
        for label, color in zip(species, colors)
    ]

    axs[1].legend(handles=handles, prop={"size": fs * 1.7}, loc="upper left")

    for ax in axs.flat:
        ax.tick_params(axis='both', which='major', labelsize=15)
        ax.tick_params(axis='x', which='major')
        ax.set_xlabel("")

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    fig.text(0.55, -0.019, 'Receptive Field', ha='center', size=fs * fig_multiplier)

    plt.savefig(
        f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne25_small_small_imagenet_ress_224_pr_0.9_adjusted_bn.pdf")
    # plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne25_small_small_imagenet_bn_adjusted_ress_224_pr_0.9.pdf")
    plt.close()

    df_level4_sgd

    """### PR=0.95  with batchnorm adjustment (eagle eye)"""

    from matplotlib.patches import Patch
    from matplotlib import pyplot as plt
    import seaborn as sns
    import pandas as pd

    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.95_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.95_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.95_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.95_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.95_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.95_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.95_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.95_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.95_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.95_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level6_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_11_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[11]] * len(df_level6_sgd))
    df_level6_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level6_sgd))
    df_level6_sgd["optimiser"] = optim

    df_level7_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_12_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[12]] * len(df_level7_sgd))
    df_level7_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level7_sgd))
    df_level7_sgd["optimiser"] = optim

    df_level8_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_13_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[13]] * len(df_level8_sgd))
    df_level8_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level8_sgd))
    df_level8_sgd["optimiser"] = optim

    # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    # all_df=pd.concat([df_level1_sgd,df_level2_sgd,df_level3_sgd,df_level4_sgd,df_level5_sgd,df_level6_sgd, df_level7_sgd,df_level8_sgd])
    all_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])

    fig_size = (6, 5)
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    #######################
    #       New Plot
    #######################

    sns.barplot(ax=ax, data=all_df, x="RF", y="Scaled Pruned Accuracy", hue="optimiser", alpha=0.5)
    # sns.barplot(ax=ax,data=all_df,x="RF",y="Dense Accuracy",color="red",legend=False,alpha=0.3)
    # sns.barplot(ax=ax,data=all_df,x="RF",y="Pruned Accuracy",legend=False,alpha=0.5,color="blue")

    # sns.stripplot(
    #     x="RF",
    #     y="Scaled Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0],legend=False)

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        # hue="optimiser",
        color="red",
        data=all_df, dodge=True, alpha=0.4, ax=ax, legend=False)

    # sns.stripplot(
    #     x="RF",
    #     y="Pruned Accuracy",
    #     # hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=ax,legend=False,color="blue")

    sns.stripplot(
        x="RF",
        y="Scaled Pruned Accuracy",
        # hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=ax, legend=False, color="blue")

    def f(x):
        return x

    def invf(x):
        return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Absolute Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90) \
    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    species = ["Pruned SGD", "Dense SGD"]
    colors = ["cornflowerblue", "red"]

    handles = [
        # Patch(facecolor="red",alpha=0.4, label="Dense"),
        # Patch(facecolor="cornflowerblue", label="Pruned")
        Patch(facecolor="blue", alpha=0.4, label="Scaled Performance"),
        # Patch(facecolor="cornflowerblue", label="Pruned")
        # for label, color in zip(species,colors)
    ]

    ax.legend(handles=handles, prop={"size": fs * 1.3}, loc="center right")

    # for ax in axs.flat:
    ax.tick_params(axis='both', which='major', labelsize=fs * 1.5)
    ax.tick_params(axis='x', which='major')
    # ax.set_xlabel("")
    ax.set_ylabel("Accuracy in Test Set", fontsize=fs * 1.7)
    ax.set_xlabel("Receptive Field", fontsize=fs * 1.7)

    ax.grid(ls="--", alpha=0.5)

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')
    fig_multiplier = 1.5
    # fig.text(0.5, -0.019, 'Receptive Field', ha='center', size=fs * fig_multiplier)

    plt.savefig(
        f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet25_small_small_imagenet_ress_224_pr_0.95_adjusted_bn_first_5_only_scaled.pdf")
    # plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne25_small_small_imagenet_bn_adjusted_ress_224_pr_0.9.pdf")
    plt.close()

    df_level5_sgd["Name"][0]

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.95_sgd_100_res_224_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    df_level2_sgd

    """## Resized from 32x32 to 224 No batch norm

#### PR=0.8
"""

    from matplotlib import pyplot as plt
    from matplotlib.patches import Patch
    import seaborn as sns
    import pandas as pd

    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_5_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_5_small_imagenet_0.8_sam_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_5_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_6_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_6_small_imagenet_0.8_sam_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_6_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_7_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_7_small_imagenet_0.8_sam_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_7_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_8_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_8_small_imagenet_0.8_sam_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_8_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_10_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_10_small_imagenet_0.8_sam_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_10_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level6_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_11_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[11]] * len(df_level6_sgd))
    df_level6_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level6_sgd))
    df_level6_sgd["optimiser"] = optim

    df_level7_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_12_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[12]] * len(df_level7_sgd))
    df_level7_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level7_sgd))
    df_level7_sgd["optimiser"] = optim

    df_level8_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_13_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[13]] * len(df_level8_sgd))
    df_level8_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level8_sgd))
    df_level8_sgd["optimiser"] = optim

    # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    # all_df=pd.concat([df_level1_sgd,df_level2_sgd,df_level3_sgd,df_level4_sgd,df_level5_sgd])

    all_df = pd.concat(
        [df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd, df_level6_sgd, df_level7_sgd,
         df_level8_sgd])

    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100
    all_df
    # all_df["Scaled $\Delta$"]=-((all_df["Pruned Accuracy"]-all_df["Dense Accuracy"])/all_df["Dense Accuracy"])*100
    # all_df["Absolute $\Delta$"]=-((all_df["Pruned Accuracy"]-all_df["Dense Accuracy"]))

    #######################
    #       Old Plot
    #######################
    # sns.barplot(ax=axs[0],data=all_df,x="RF",y="Scaled Pruned Accuracy",hue="optimiser",alpha=0.5)
    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)

    # sns.stripplot(
    #     x="RF",
    #     y="Scaled Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0],legend=False)
    # sns.stripplot(
    #     x="RF",
    #     y="Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[1],legend=False)

    # def f(x):
    #   return x

    # def invf(x):
    #   return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Absolute Pruned Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    # # secay.tick_params(axis='x',labelrotation=90)

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    # for ax in axs.flat:
    #   ax.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    #   ax.tick_params(axis='x', which='major', labelrotation=90)

    # # remove extra legend handles
    # # handles, labels = ax.get_legend_handles_labels()
    # # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    # # plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne25_small_small_imagenetress_224_pr_0.8.pdf")
    plt.close()
    # # all_df

    #######################
    #       New Plot
    #######################

    # sns.barplot(ax=axs[0],data=all_df,x="RF",y="Scaled Pruned Accuracy",hue="optimiser",alpha=0.5)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Dense Accuracy", color="red", legend=False, alpha=0.3)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Pruned Accuracy", legend=False, alpha=0.5, color="blue")

    # sns.stripplot(
    #     x="RF",
    #     y="Scaled Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0],legend=False)

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        # hue="optimiser",
        color="red",
        data=all_df, dodge=True, alpha=0.4, ax=ax, legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        # hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=ax, legend=False, color="blue")

    def f(x):
        return x

    def invf(x):
        return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Absolute Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    species = ["Pruned SGD", "Dense SGD"]
    colors = ["cornflowerblue", "red"]

    handles = [
        Patch(facecolor="red", alpha=0.4, label="Dense"),
        Patch(facecolor="cornflowerblue", label="Pruned")
        # for label, color in zip(species,colors)
    ]

    ax.legend(handles=handles, prop={"size": fs * 1.3}, loc="upper right")

    # for ax in axs.flat:
    ax.tick_params(axis='both', which='major', labelsize=fs * 1.5)
    ax.tick_params(axis='x', which='major')
    # ax.set_xlabel("")
    ax.set_ylabel("Accuracy in Test Set", fontsize=fs * 1.7)
    ax.set_xlabel("Receptive Field", fontsize=fs * 1.7)

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    # plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne25_small_small_imagenet_ress_224_pr_0.9.pdf")
    plt.close()

    """#### PR=0.9"""

    from matplotlib import pyplot as plt
    from matplotlib.patches import Patch
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_5_small_imagenet_0.9_ekfac_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_5_small_imagenet_0.9_sam_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_5_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_6_small_imagenet_0.9_ekfac_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_6_small_imagenet_0.9_sam_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_6_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_7_small_imagenet_0.9_ekfac_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_7_small_imagenet_0.9_sam_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_7_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_8_small_imagenet_0.9_ekfac_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_8_small_imagenet_0.9_sam_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_8_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_10_small_imagenet_0.9_ekfac_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_10_small_imagenet_0.9_sam_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_10_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level6_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_11_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[11]] * len(df_level6_sgd))
    df_level6_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level6_sgd))
    df_level6_sgd["optimiser"] = optim

    df_level7_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_12_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[12]] * len(df_level7_sgd))
    df_level7_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level7_sgd))
    df_level7_sgd["optimiser"] = optim

    df_level8_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_13_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[13]] * len(df_level8_sgd))
    df_level8_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level8_sgd))
    df_level8_sgd["optimiser"] = optim

    # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    # all_df=pd.concat([df_level1_sgd,df_level2_sgd,df_level3_sgd,df_level4_sgd,df_level5_sgd])

    all_df = pd.concat(
        [df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd, df_level6_sgd, df_level7_sgd,
         df_level8_sgd])

    fig_size = (6, 5)
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    # all_df["Scaled $\Delta$"]=-((all_df["Pruned Accuracy"]-all_df["Dense Accuracy"])/all_df["Dense Accuracy"])*100
    # all_df["Absolute $\Delta$"]=-((all_df["Pruned Accuracy"]-all_df["Dense Accuracy"]))

    # sns.barplot(ax=axs[0],data=all_df,x="RF",y="Scaled Pruned Accuracy",hue="optimiser",alpha=0.5)
    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)

    #######################
    #       Old Plot
    #######################

    # sns.stripplot(
    #     x="RF",
    #     y="Scaled Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0],legend=False)
    # sns.stripplot(
    #     x="RF",
    #     y="Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[1],legend=False)

    # def f(x):
    #   return x

    # def invf(x):
    #   return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Absolute Pruned Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    # # secay.tick_params(axis='x',labelrotation=90)

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    # for ax in axs.flat:
    #   ax.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    #   ax.tick_params(axis='x', which='major', labelrotation=90)

    # # remove extra legend handles
    # # handles, labels = ax.get_legend_handles_labels()
    # # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    # # plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne25_small_small_imagenetress_224_pr_0.9.pdf")
    plt.close()

    #######################
    #       New Plot
    #######################

    # sns.barplot(ax=axs[0],data=all_df,x="RF",y="Scaled Pruned Accuracy",hue="optimiser",alpha=0.5)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Dense Accuracy", color="red", legend=False, alpha=0.3)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Pruned Accuracy", legend=False, alpha=0.5, color="blue")

    # sns.stripplot(
    #     x="RF",
    #     y="Scaled Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0],legend=False)

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        # hue="optimiser",
        color="red",
        data=all_df, dodge=True, alpha=0.4, ax=ax, legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        # hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=ax, legend=False, color="blue")

    def f(x):
        return x

    def invf(x):
        return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Absolute Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    species = ["Pruned SGD", "Dense SGD"]
    colors = ["cornflowerblue", "red"]

    handles = [
        Patch(facecolor="red", alpha=0.4, label="Dense"),
        Patch(facecolor="cornflowerblue", label="Pruned")
        # for label, color in zip(species,colors)
    ]

    ax.legend(handles=handles, prop={"size": fs * 1.3}, loc="upper right")

    # for ax in axs.flat:
    ax.tick_params(axis='both', which='major', labelsize=fs * 1.5)
    ax.tick_params(axis='x', which='major')
    # ax.set_xlabel("")
    ax.set_ylabel("Accuracy in Test Set", fontsize=fs * 1.7)
    ax.set_xlabel("Receptive Field", fontsize=fs * 1.7)

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    # plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne25_small_small_imagenet_ress_224_pr_0.9.pdf")
    plt.close()

    """#### PR=0.95  """

    from matplotlib import pyplot as plt
    from matplotlib.patches import Patch
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_5_small_imagenet_0.95_ekfac_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_5_small_imagenet_0.95_sam_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_5_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_6_small_imagenet_0.95_ekfac_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_6_small_imagenet_0.95_sam_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_6_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_7_small_imagenet_0.95_ekfac_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_7_small_imagenet_0.95_sam_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_7_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_8_small_imagenet_0.95_ekfac_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_8_small_imagenet_0.95_sam_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_8_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_10_small_imagenet_0.95_ekfac_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_10_small_imagenet_0.95_sam_small_imagenet_100_res_224_gc_0_global_one_shotsummary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_10_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level6_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_11_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[11]] * len(df_level6_sgd))
    df_level6_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level6_sgd))
    df_level6_sgd["optimiser"] = optim

    df_level7_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_12_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[12]] * len(df_level7_sgd))
    df_level7_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level7_sgd))
    df_level7_sgd["optimiser"] = optim

    df_level8_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_13_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shotsummary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[13]] * len(df_level8_sgd))
    df_level8_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level8_sgd))
    df_level8_sgd["optimiser"] = optim

    # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    # all_df=pd.concat([df_level1_sgd,df_level2_sgd,df_level3_sgd,df_level4_sgd,df_level5_sgd,df_level6_sgd, df_level7_sgd,df_level8_sgd])

    all_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])
    fig_size = (6, 5)
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    #######################
    #       New Plot
    #######################

    # sns.barplot(ax=axs[0],data=all_df,x="RF",y="Scaled Pruned Accuracy",hue="optimiser",alpha=0.5)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Dense Accuracy", color="red", legend=False, alpha=0.3)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Pruned Accuracy", legend=False, alpha=0.5, color="blue")

    # sns.stripplot(
    #     x="RF",
    #     y="Scaled Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0],legend=False)

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        # hue="optimiser",
        color="red",
        data=all_df, dodge=True, alpha=0.4, ax=ax, legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        # hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=ax, legend=False, color="blue")

    def f(x):
        return x

    def invf(x):
        return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Absolute Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    species = ["Pruned SGD", "Dense SGD"]
    colors = ["cornflowerblue", "red"]

    handles = [
        Patch(facecolor="red", alpha=0.4, label="Dense"),
        Patch(facecolor="cornflowerblue", label="Pruned")
        # for label, color in zip(species,colors)
    ]

    # ax.legend(handles=handles,prop={"size": fs*1.3}, loc="center right")

    # for ax in axs.flat:
    ax.tick_params(axis='both', which='major', labelsize=fs * 1.5)
    ax.tick_params(axis='x', which='major')
    # ax.set_xlabel("")
    ax.set_ylabel("Accuracy in Test Set", fontsize=fs * 1.7)
    ax.set_xlabel("Receptive Field", fontsize=fs * 1.7)
    ax.grid(ls="--", alpha=0.5)

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    plt.savefig(
        f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet25_small_small_imagenet_resize_32_224_pr_0.9_only_first_5.pdf")

    plt.close()

    """## Resized from 32x32 to 224

#### PR=0.8  with batchnorm adjustment (eagle eye)
"""

    from matplotlib import pyplot as plt
    from matplotlib.patches import Patch
    import seaborn as sns
    import pandas as pd

    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_5_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_5_small_imagenet_0.8_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_5_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_6_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_6_small_imagenet_0.8_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_6_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_7_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_7_small_imagenet_0.8_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_7_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_8_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_8_small_imagenet_0.8_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_8_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_10_small_imagenet_0.8_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_10_small_imagenet_0.8_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_10_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level6_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_11_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[11]] * len(df_level6_sgd))
    df_level6_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level6_sgd))
    df_level6_sgd["optimiser"] = optim

    df_level7_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_12_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[12]] * len(df_level7_sgd))
    df_level7_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level7_sgd))
    df_level7_sgd["optimiser"] = optim

    df_level8_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_13_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[13]] * len(df_level8_sgd))
    df_level8_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level8_sgd))
    df_level8_sgd["optimiser"] = optim

    # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    # all_df=pd.concat([df_level1_sgd,df_level2_sgd,df_level3_sgd,df_level4_sgd,df_level5_sgd])

    all_df = pd.concat(
        [df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd, df_level6_sgd, df_level7_sgd,
         df_level8_sgd])

    fig, axs = plt.subplots(1, 2, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100
    all_df
    # all_df["Scaled $\Delta$"]=-((all_df["Pruned Accuracy"]-all_df["Dense Accuracy"])/all_df["Dense Accuracy"])*100
    # all_df["Absolute $\Delta$"]=-((all_df["Pruned Accuracy"]-all_df["Dense Accuracy"]))

    #######################
    #       Old Plot
    #######################
    # sns.barplot(ax=axs[0],data=all_df,x="RF",y="Scaled Pruned Accuracy",hue="optimiser",alpha=0.5)
    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)

    # sns.stripplot(
    #     x="RF",
    #     y="Scaled Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0],legend=False)
    # sns.stripplot(
    #     x="RF",
    #     y="Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[1],legend=False)

    # def f(x):
    #   return x

    # def invf(x):
    #   return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Absolute Pruned Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    # # secay.tick_params(axis='x',labelrotation=90)

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    # for ax in axs.flat:
    #   ax.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    #   ax.tick_params(axis='x', which='major', labelrotation=90)

    # # remove extra legend handles
    # # handles, labels = ax.get_legend_handles_labels()
    # # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    # # plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne25_small_small_imagenet_bn_adjusted_ress_224_pr_0.8.pdf")
    plt.close()
    # # all_df

    #######################
    #       New Plot
    #######################

    # sns.barplot(ax=axs[0],data=all_df,x="RF",y="Scaled Pruned Accuracy",hue="optimiser",alpha=0.5)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Dense Accuracy", color="red", legend=False, alpha=0.3)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Pruned Accuracy", legend=False, alpha=0.5, color="blue")

    # sns.stripplot(
    #     x="RF",
    #     y="Scaled Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0],legend=False)

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        # hue="optimiser",
        color="red",
        data=all_df, dodge=True, alpha=0.4, ax=ax, legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        # hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=ax, legend=False, color="blue")

    def f(x):
        return x

    def invf(x):
        return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Absolute Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    species = ["Pruned SGD", "Dense SGD"]
    colors = ["cornflowerblue", "red"]

    handles = [
        Patch(facecolor="red", alpha=0.4, label="Dense"),
        Patch(facecolor="cornflowerblue", label="Pruned")
        # for label, color in zip(species,colors)
    ]

    ax.legend(handles=handles, prop={"size": fs * 1.3}, loc="upper right")

    # for ax in axs.flat:
    ax.tick_params(axis='both', which='major', labelsize=fs * 1.5)
    ax.tick_params(axis='x', which='major')
    # ax.set_xlabel("")
    ax.set_ylabel("Accuracy in Test Set", fontsize=fs * 1.7)
    ax.set_xlabel("Receptive Field", fontsize=fs * 1.7)

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    # plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne25_small_small_imagenet_bn_adjusted_ress_224_pr_0.9.pdf")
    plt.close()

    """#### PR=0.9  with batchnorm adjustment (eagle eye)"""

    from matplotlib import pyplot as plt
    from matplotlib.patches import Patch
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_5_small_imagenet_0.9_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_5_small_imagenet_0.9_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_5_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_6_small_imagenet_0.9_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_6_small_imagenet_0.9_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_6_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_7_small_imagenet_0.9_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_7_small_imagenet_0.9_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_7_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_8_small_imagenet_0.9_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_8_small_imagenet_0.9_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_8_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_10_small_imagenet_0.9_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_10_small_imagenet_0.9_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_10_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level6_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_11_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[11]] * len(df_level6_sgd))
    df_level6_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level6_sgd))
    df_level6_sgd["optimiser"] = optim

    df_level7_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_12_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[12]] * len(df_level7_sgd))
    df_level7_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level7_sgd))
    df_level7_sgd["optimiser"] = optim

    df_level8_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_13_small_imagenet_0.9_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[13]] * len(df_level8_sgd))
    df_level8_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level8_sgd))
    df_level8_sgd["optimiser"] = optim

    # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    # all_df=pd.concat([df_level1_sgd,df_level2_sgd,df_level3_sgd,df_level4_sgd,df_level5_sgd])

    all_df = pd.concat(
        [df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd, df_level6_sgd, df_level7_sgd,
         df_level8_sgd])

    fig_size = (6, 5)
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    # all_df["Scaled $\Delta$"]=-((all_df["Pruned Accuracy"]-all_df["Dense Accuracy"])/all_df["Dense Accuracy"])*100
    # all_df["Absolute $\Delta$"]=-((all_df["Pruned Accuracy"]-all_df["Dense Accuracy"]))

    # sns.barplot(ax=axs[0],data=all_df,x="RF",y="Scaled Pruned Accuracy",hue="optimiser",alpha=0.5)
    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)

    #######################
    #       Old Plot
    #######################

    # sns.stripplot(
    #     x="RF",
    #     y="Scaled Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0],legend=False)
    # sns.stripplot(
    #     x="RF",
    #     y="Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[1],legend=False)

    # def f(x):
    #   return x

    # def invf(x):
    #   return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Absolute Pruned Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    # # secay.tick_params(axis='x',labelrotation=90)

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    # for ax in axs.flat:
    #   ax.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    #   ax.tick_params(axis='x', which='major', labelrotation=90)

    # # remove extra legend handles
    # # handles, labels = ax.get_legend_handles_labels()
    # # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    # # plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne25_small_small_imagenet_bn_adjusted_ress_224_pr_0.9.pdf")
    plt.close()

    #######################
    #       New Plot
    #######################

    # sns.barplot(ax=axs[0],data=all_df,x="RF",y="Scaled Pruned Accuracy",hue="optimiser",alpha=0.5)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Dense Accuracy", color="red", legend=False, alpha=0.3)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Pruned Accuracy", legend=False, alpha=0.5, color="blue")

    # sns.stripplot(
    #     x="RF",
    #     y="Scaled Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0],legend=False)

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        # hue="optimiser",
        color="red",
        data=all_df, dodge=True, alpha=0.4, ax=ax, legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        # hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=ax, legend=False, color="blue")

    def f(x):
        return x

    def invf(x):
        return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Absolute Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    species = ["Pruned SGD", "Dense SGD"]
    colors = ["cornflowerblue", "red"]

    handles = [
        Patch(facecolor="red", alpha=0.4, label="Dense"),
        Patch(facecolor="cornflowerblue", label="Pruned")
        # for label, color in zip(species,colors)
    ]

    ax.legend(handles=handles, prop={"size": fs * 1.3}, loc="upper right")

    # for ax in axs.flat:
    ax.tick_params(axis='both', which='major', labelsize=fs * 1.5)
    ax.tick_params(axis='x', which='major')
    # ax.set_xlabel("")
    ax.set_ylabel("Accuracy in Test Set", fontsize=fs * 1.7)
    ax.set_xlabel("Receptive Field", fontsize=fs * 1.7)

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    # plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne25_small_small_imagenet_bn_adjusted_ress_224_pr_0.9.pdf")
    plt.close()

    """#### PR=0.95  with batchnorm adjustment (eagle eye)"""

    from matplotlib import pyplot as plt
    from matplotlib.patches import Patch
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # level 5 ############################ ############################ ############################ ############################ ############################

    # df_level1_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_5_small_imagenet_0.95_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_ekfac))
    # df_level1_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level1_ekfac))
    # df_level1_ekfac["optimiser"]=optim

    # df_level1_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_5_small_imagenet_0.95_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[5]]*len(df_level1_asam))
    # df_level1_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level1_asam))
    # df_level1_asam["optimiser"]=optim

    df_level1_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_5_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    # df_level2_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_6_small_imagenet_0.95_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_ekfac))
    # df_level2_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level2_ekfac))
    # df_level2_ekfac["optimiser"]=optim

    # df_level2_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_6_small_imagenet_0.95_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[6]]*len(df_level2_asam))
    # df_level2_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level2_asam))
    # df_level2_asam["optimiser"]=optim

    df_level2_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_6_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level3_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_7_small_imagenet_0.95_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_ekfac))
    # df_level3_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level3_ekfac))
    # df_level3_ekfac["optimiser"]=optim

    # df_level3_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_7_small_imagenet_0.95_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[7]]*len(df_level3_asam))
    # df_level3_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level3_asam))
    # df_level3_asam["optimiser"]=optim

    df_level3_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_7_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level4_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_8_small_imagenet_0.95_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_ekfac))
    # df_level4_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level4_ekfac))
    # df_level4_ekfac["optimiser"]=optim

    # df_level4_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_8_small_imagenet_0.95_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[8]]*len(df_level4_asam))
    # df_level4_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level4_asam))
    # df_level4_asam["optimiser"]=optim

    df_level4_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_8_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    # df_level5_ekfac = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_10_small_imagenet_0.95_ekfac_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_ekfac))
    # df_level5_ekfac["RF"]=RF
    # optim=[]
    # optim.extend(["EKFAC"]*len(df_level5_ekfac))
    # df_level5_ekfac["optimiser"]=optim

    # df_level5_asam = pd.read_csv("small_imagenet_resized_experiments_pruning/RF_resnet25_small_10_small_imagenet_0.95_sam_small_imagenet_100_res_224_gc_0_global_one_shot_bn_adjusted_summary.csv",delimiter=",")
    # RF=[]
    # RF.extend([resnets_rfs[10]]*len(df_level5_asam))
    # df_level5_asam["RF"]=RF
    # optim=[]
    # optim.extend(["ASAM"]*len(df_level5_asam))
    # df_level5_asam["optimiser"]=optim

    df_level5_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_10_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level6_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_11_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[11]] * len(df_level6_sgd))
    df_level6_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level6_sgd))
    df_level6_sgd["optimiser"] = optim

    df_level7_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_12_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[12]] * len(df_level7_sgd))
    df_level7_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level7_sgd))
    df_level7_sgd["optimiser"] = optim

    df_level8_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_13_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[13]] * len(df_level8_sgd))
    df_level8_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level8_sgd))
    df_level8_sgd["optimiser"] = optim

    # df_level1=pd.concat([df_level1_ekfac,df_level1_asam,df_level1_sgd])
    # df_level2=pd.concat([df_level2_ekfac,df_level2_asam,df_level2_sgd])
    # df_level3=pd.concat([df_level3_ekfac,df_level3_asam,df_level3_sgd])
    # df_level4=pd.concat([df_level4_ekfac,df_level4_asam,df_level4_sgd])
    # df_level5=pd.concat([df_level5_ekfac,df_level5_asam,df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])

    # all_df=pd.concat([df_level1_sgd,df_level2_sgd,df_level3_sgd,df_level4_sgd,df_level5_sgd,df_level6_sgd, df_level7_sgd,df_level8_sgd])

    all_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])
    fig_size = (6, 5)
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    all_df["Scaled Pruned Accuracy"] = (all_df["Pruned Accuracy"] / all_df["Dense Accuracy"]) * 100

    #######################
    #       New Plot
    #######################

    # sns.barplot(ax=axs[0],data=all_df,x="RF",y="Scaled Pruned Accuracy",hue="optimiser",alpha=0.5)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Dense Accuracy", color="red", legend=False, alpha=0.3)
    sns.barplot(ax=ax, data=all_df, x="RF", y="Pruned Accuracy", legend=False, alpha=0.5, color="blue")

    # sns.stripplot(
    #     x="RF",
    #     y="Scaled Pruned Accuracy",
    #     hue="optimiser",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0],legend=False)

    sns.stripplot(
        x="RF",
        y="Dense Accuracy",
        # hue="optimiser",
        color="red",
        data=all_df, dodge=True, alpha=0.4, ax=ax, legend=False)

    sns.stripplot(
        x="RF",
        y="Pruned Accuracy",
        # hue="optimiser",
        data=all_df, dodge=True, alpha=0.6, ax=ax, legend=False, color="blue")

    def f(x):
        return x

    def invf(x):
        return x

    # secay = axs[1].secondary_yaxis('right', functions=(f,invf))

    # secay.set_ylabel('Absolute Accuracy')

    # secay.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    # secay.tick_params(axis='x',labelrotation=90)

    # axs[0].legend(prop={"size": fs*1.7}, loc="upper left")

    species = ["Pruned SGD", "Dense SGD"]
    colors = ["cornflowerblue", "red"]

    handles = [
        Patch(facecolor="red", alpha=0.4, label="Dense"),
        Patch(facecolor="cornflowerblue", label="Pruned")
        # for label, color in zip(species,colors)
    ]

    # ax.legend(handles=handles,prop={"size": fs*1.3}, loc="center right")

    # for ax in axs.flat:
    ax.tick_params(axis='both', which='major', labelsize=fs * 1.5)
    ax.tick_params(axis='x', which='major')
    # ax.set_xlabel("")
    ax.set_ylabel("Accuracy in Test Set", fontsize=fs * 1.7)
    ax.set_xlabel("Receptive Field", fontsize=fs * 1.7)
    ax.grid(ls="--", alpha=0.5)

    # remove extra legend handles
    # handles, labels = ax.get_legend_handles_labels()
    # ax.legend(handles[2:], labels[2:], title='Smoker', bbox_to_anchor=(1, 1.02), loc='upper left')

    plt.savefig(
        f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet25_small_small_imagenet_bn_adjusted_resize_32_224_pr_0.9_only_first_5.pdf")

    plt.close()
def large_input_experiments_only_sgd_paper():
    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))

    dense_color1 = "crimson"
    dense_color2 = "cornflowerblue"
    pruned_color1 = "crimson"
    pruned_color2 = "cornflowerblue"
    accuracy_ticks = range(0, 110, 10)
    # level 5 ############################ ############################ ############################ ############################ ############################

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results_backup/RF_resnet25_small_5_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results_backup/RF_resnet25_small_6_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results_backup/RF_resnet25_small_7_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results_backup/RF_resnet25_small_8_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results_backup/RF_resnet25_small_10_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    all_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])

    #################################################################################################################################################################################
    #######                                               Resized
    #################################################################################################################################################################################

    df_level1_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_5_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    df_level2_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_6_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_7_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_8_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_10_small_imagenet_0.8_sgd_100_res_224_no_ffcv_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    all_df_resized = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])

    all_df_resized["Resized"] = [1] * len(all_df_resized)
    all_df["Resized"] = [0] * len(all_df)

    print("#################")
    print("all_df")
    print(all_df)
    print("#################")
    all_all_df = pd.concat([all_df, all_df_resized])
    plot_large_input_image_rf_plots(all_all_df,"resnet25_small_imagenet_pr_0.8_no_bn_combined","upper right",["224",r"224$\Rightarrow$32$\Rightarrow$224","Dense","Pruned"])

    ##############################################
    #           FIGURE 2
    ##############################################

    #################################################################################################################################################################################
    #######                                               Size 32
    #################################################################################################################################################################################


    # level 5 ############################ ############################ ############################ ############################ ############################

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_sgd_200_res_32_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    all_32_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])

    #################################################################################################################################################################################
    #######                                               Resized 224
    #################################################################################################################################################################################
    # level 5 ############################ ############################ ############################ ############################ ############################

    df_level1_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_ekfac))
    df_level1_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level1_ekfac))
    df_level1_ekfac["optimiser"] = optim

    df_level1_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_asam))
    df_level1_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level1_asam))
    df_level1_asam["optimiser"] = optim

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_cifar10_0.9_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    df_level2_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_ekfac))
    df_level2_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level2_ekfac))
    df_level2_ekfac["optimiser"] = optim

    df_level2_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_asam))
    df_level2_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level2_asam))
    df_level2_asam["optimiser"] = optim

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_cifar10_0.9_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_ekfac))
    df_level3_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level3_ekfac))
    df_level3_ekfac["optimiser"] = optim

    df_level3_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_asam))
    df_level3_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level3_asam))
    df_level3_asam["optimiser"] = optim

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_cifar10_0.9_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_ekfac))
    df_level4_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level4_ekfac))
    df_level4_ekfac["optimiser"] = optim

    df_level4_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_asam))
    df_level4_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level4_asam))
    df_level4_asam["optimiser"] = optim

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_cifar10_0.9_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_ekfac = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_ekfac_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_ekfac))
    df_level5_ekfac["RF"] = RF
    optim = []
    optim.extend(["EKFAC"] * len(df_level5_ekfac))
    df_level5_ekfac["optimiser"] = optim

    df_level5_asam = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_sam_cifar10_100_res_224_gc_0_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_asam))
    df_level5_asam["RF"] = RF
    optim = []
    optim.extend(["ASAM"] * len(df_level5_asam))
    df_level5_asam["optimiser"] = optim

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_cifar10_0.9_sgd_100_res_224_global_one_shot_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level1 = pd.concat([df_level1_ekfac, df_level1_asam, df_level1_sgd])
    df_level2 = pd.concat([df_level2_ekfac, df_level2_asam, df_level2_sgd])
    df_level3 = pd.concat([df_level3_ekfac, df_level3_asam, df_level3_sgd])
    df_level4 = pd.concat([df_level4_ekfac, df_level4_asam, df_level4_sgd])
    df_level5 = pd.concat([df_level5_ekfac, df_level5_asam, df_level5_sgd])

    # all_df=pd.concat([df_level1,df_level2,df_level3,df_level4,df_level5])
    all_224_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])
    all_224_df["Resized"] = [1] * len(all_224_df)
    all_32_df["Resized"] = [0] * len(all_32_df)
    all_df = pd.concat([all_32_df, all_224_df])

    plot_large_input_image_rf_plots(all_df,"resnet25_cifar10_pr_0.9_no_bn_combined",legends=[r"32","32$\Rightarrow$224","Dense","Pruned"])

    #####################################
    #           Figrue 3
    #####################################
    # level 5 ############################ ############################ ############################ ############################ ############################

    df_level1_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_5_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    df_level2_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_6_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_7_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_8_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_10_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level6_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_11_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[11]] * len(df_level6_sgd))
    df_level6_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level6_sgd))
    df_level6_sgd["optimiser"] = optim

    df_level7_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_12_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[12]] * len(df_level7_sgd))
    df_level7_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level7_sgd))
    df_level7_sgd["optimiser"] = optim

    df_level8_sgd = pd.read_csv(
        "large_input_pruning_results/RF_resnet25_small_13_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[13]] * len(df_level8_sgd))
    df_level8_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level8_sgd))
    df_level8_sgd["optimiser"] = optim

    all_224_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])

    #################################################################################################################################################################################
    #######                                               Resized 224
    #################################################################################################################################################################################

    # level 5 ############################ ############################ ############################ ############################ ############################

    df_level1_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_5_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[5]] * len(df_level1_sgd))
    df_level1_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level1_sgd))
    df_level1_sgd["optimiser"] = optim

    # level 6 ############################ ############################ ############################ ############################ ############################

    df_level2_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_6_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[6]] * len(df_level2_sgd))
    df_level2_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level2_sgd))
    df_level2_sgd["optimiser"] = optim

    # level 7 ############################ ############################ ############################ ############################ ############################ ############################

    df_level3_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_7_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[7]] * len(df_level3_sgd))
    df_level3_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level3_sgd))
    df_level3_sgd["optimiser"] = optim

    # level 8 ############################ ############################ ############################ ############################ ############################ ############################

    df_level4_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_8_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[8]] * len(df_level4_sgd))
    df_level4_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level4_sgd))
    df_level4_sgd["optimiser"] = optim

    # level 10 ############################ ############################ ############################ ############################ ############################ ############################

    df_level5_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_10_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[10]] * len(df_level5_sgd))
    df_level5_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level5_sgd))
    df_level5_sgd["optimiser"] = optim

    df_level6_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_11_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[11]] * len(df_level6_sgd))
    df_level6_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level6_sgd))
    df_level6_sgd["optimiser"] = optim

    df_level7_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_12_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[12]] * len(df_level7_sgd))
    df_level7_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level7_sgd))
    df_level7_sgd["optimiser"] = optim

    df_level8_sgd = pd.read_csv(
        "small_imagenet_resized_experiments_pruning/RF_resnet25_small_13_small_imagenet_0.95_sgd_100_res_224_no_ffcv_global_one_shot_bn_adjusted_summary.csv",
        delimiter=",")
    RF = []
    RF.extend([resnets_rfs[13]] * len(df_level8_sgd))
    df_level8_sgd["RF"] = RF
    optim = []
    optim.extend(["SGD"] * len(df_level8_sgd))
    df_level8_sgd["optimiser"] = optim

    all_32_224_df = pd.concat([df_level1_sgd, df_level2_sgd, df_level3_sgd, df_level4_sgd, df_level5_sgd])

    all_224_df["Resized"] = [0] * len(all_224_df)
    all_32_224_df["Resized"] = [1] * len(all_32_224_df)
    all_df = pd.concat([all_32_224_df, all_224_df])
    
    plot_large_input_image_rf_plots(all_df,"resnet25_small_imagenet_pr_0.95_yes_bn_combined","upper right",["224",r"224$\Rightarrow$32$\Rightarrow$224","Dense","Pruned"])


def plot_large_input_image_rf_plots(all_df,save_name,pos="center right",legends=[]):
    from matplotlib.patches import Patch
    from matplotlib.lines import Line2D
    dense_color1 = "crimson"
    dense_color2 = "cornflowerblue"
    pruned_color1 = "crimson"
    pruned_color2 = "cornflowerblue"
    accuracy_ticks = range(0, 110, 10)
    # fig_size = (4, 3)
    fig, ax = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    # all_224_df["Scaled Pruned Accuracy"]=(all_df["Pruned Accuracy"]/all_df["Dense Accuracy"])*100

    means_dense1 = []
    stds_dense1 = []
    means_pruned1 = []
    stds_pruned1 = []
    means_dense2 = []
    stds_dense2 = []
    means_pruned2 = []
    stds_pruned2 = []

    for rf in all_df["RF"].unique():
        rf_df = all_df[all_df["RF"] == rf]
        rf_resized_df = rf_df[rf_df["Resized"] == 1]
        rf_not_resized_df = rf_df[rf_df["Resized"] == 0]

        means_dense1.append(rf_not_resized_df["Dense Accuracy"].dropna().mean())
        stds_dense1.append(rf_not_resized_df["Dense Accuracy"].dropna().std())
        means_pruned1.append(rf_not_resized_df["Pruned Accuracy"].dropna().mean())
        stds_pruned1.append(rf_not_resized_df["Pruned Accuracy"].dropna().std())

        means_dense2.append(rf_resized_df["Dense Accuracy"].dropna().mean())
        stds_dense2.append(rf_resized_df["Dense Accuracy"].dropna().std())
        means_pruned2.append(rf_resized_df["Pruned Accuracy"].dropna().mean())
        stds_pruned2.append(rf_resized_df["Pruned Accuracy"].dropna().std())
    # means.reverse()
    # stds.reverse()
    print(stds_dense1)
    print(stds_pruned1)
    print(stds_dense2)
    print(stds_pruned2)
    # ax.bar(x=range(len(tick_index)), height=means, yerr=stds, color="red")

    ax.errorbar(x=range(len(means_dense1)), y=means_dense1, yerr=stds_dense1, ecolor=dense_color1, marker='o',
                mfc=dense_color1, capsize=2,
                markeredgewidth=0.5, markeredgecolor="k", ls="none")

    ax.errorbar(x=range(len(means_dense1)), y=means_pruned1, yerr=stds_pruned1, ecolor=pruned_color1, marker='D',
                mfc=pruned_color1, capsize=2,
                markeredgewidth=0.5, markeredgecolor="k", ls="none")

    ax.errorbar(x=range(len(means_dense1)), y=means_dense2, yerr=stds_dense2, ecolor=dense_color2, marker='o',
                mfc=dense_color2, capsize=2,
                markeredgewidth=0.5, markeredgecolor="k", ls="none")

    ax.errorbar(x=range(len(means_dense1)), y=means_pruned2, yerr=stds_pruned2, ecolor=pruned_color2, marker='D',
                mfc=pruned_color2, capsize=2,
                markeredgewidth=0.5, markeredgecolor="k", ls="none")
    if not legends:
        handles = [
            Patch(facecolor=dense_color1, label="32x32"),
            Patch(facecolor=dense_color2, label="224x224"),
            # Patch(facecolor=dense_color2, label="Dense @ 224x224"),
            # Patch(facecolor=pruned_color2, label="Pruned @ 224x224")
            # for label, color in zip(species,colors)
            Line2D([0], [0], linestyle="none", marker="o", color="k",
                   label=f'Dense'),
            Line2D([0], [0], linestyle="none", marker="D", color="k",
                   label=f'Pruned'),
        ]
    else:
        handles = [
            Patch(facecolor=dense_color1, label=legends[0]),
            Patch(facecolor=dense_color2, label=legends[1]),
            Line2D([0], [0], linestyle="none", marker="o", color="k", label=legends[2]),
            Line2D([0], [0], linestyle="none", marker="D", color="k", label=legends[3]),
        ]



    ax.legend(handles=handles, prop={"size": fs * legends_multiplier}, loc=pos)

    # for ax in axs.flat:
    ax.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    ax.tick_params(axis='x', which='major')
    ax.set_xticks(range(len(all_df["RF"].unique())))
    ax.set_xticklabels(all_df["RF"].unique())
    ax.set_yticks(accuracy_ticks)
    ax.set_yticklabels(accuracy_ticks)
    # ax.set_xlabel("")
    ax.set_ylabel("Test Set Accuracy", fontsize=fs * labels_multiplier)
    ax.set_xlabel("Receptive Field", fontsize=fs * labels_multiplier)
    ax.grid(ls="--", alpha=0.5)
    plt.savefig(f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/{save_name}.pdf")
    # plt.show()

def show_the_transformation_of_resize_effect():
    """# TODO: Show images"""

    import matplotlib.pyplot as plt
    import numpy as np
    from PIL import Image
    import torchvision.transforms as transforms
    import torchvision
    import torch
    # functions to show an image

    res = 1280

    transform = transforms.Compose([transforms.Resize((32, 32)),
                                    transforms.Resize((res, res)),
                                    transforms.ToTensor(),
                                    transforms.Normalize((0, 0, 0), (1, 1, 1))
                                    # transforms.Normalize([0.4824, 0.4495, 0.3981], [0.2301, 0.2264, 0.2261]),

                                    ])
    normalize_train = transforms.Normalize(mean=[0.4802, 0.4481, 0.3975],
                                           std=[0.2302, 0.2265, 0.2262])

    target_resolution = (res, res)
    transform_train = transforms.Compose([
        transforms.Resize((32, 32)),
        transforms.Resize(target_resolution),
        transforms.RandomResizedCrop(target_resolution),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0, 0, 0), (1, 1, 1))
    ])

    ratio = 256 / 224

    first_resize = (int(res * ratio), int(res * ratio))

    transform_test = transforms.Compose([transforms.Resize((32, 32)),
                                         transforms.Resize(first_resize),
                                         transforms.CenterCrop(target_resolution),
                                         transforms.ToTensor(),
                                         transforms.Normalize((0, 0, 0), (1, 1, 1))
                                         ])

    trainset = torchvision.datasets.ImageFolder("drive/MyDrive/PhD/small_imagenet_val_dir/small_val",
                                                transform=transform_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=False, num_workers=2)

    def imshow(img):
        # img = img / 2 + 0.5     # unnormalize
        npimg = img.numpy()
        transpose_img = np.transpose(npimg, (1, 2, 0))
        plt.imshow(transpose_img)

    # get some random training images
    dataiter = iter(trainloader)
    images, labels = next(dataiter)

    print(images.shape)

    # Convert the NumPy array to an image object
    for i in range(len(images)):
        # img = Image.fromarray(images[i,:,:,:].numpy())
        img = images[i, :, :, :].numpy()
        print(img.shape)
        # img = img / 2 + 0.5     # unnormalize
        transpose_img = np.transpose(img, (1, 2, 0))
        transpose_img = np.uint8(transpose_img * 255)
        print(transpose_img.shape)
        im = Image.fromarray(transpose_img)
        # Save the image object to a PNG file
        im.save("1280_{}.png".format(i))

    # show images
    imshow(torchvision.utils.make_grid(images))

    # print labels

    # print(' '.join('%5s' % classes[labels[j]] for j in range(4)))


def pruning_rate_layer():
    """# TODO: Pruning rate per layer

    ## Resnet 25 x Small Imagenet
    """

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker

    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnets_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))

    Level5 = pd.read_csv(
        "large_input_pruning_results/resnet25_small_level_5_seed_5_small_imagenet_sgd_100_res_224_no_ffcv_pruning_rates_global_pr_0.9.csv",
        delimiter=",")
    # large_input_pruning_results/resnet25_small_level_5_seed_5_small_imagenet_sgd_100_res_224_no_ffcv_pruning_rates_global_pr_0.9.csv
    Level5["Layer"] = range(len(Level5))
    Level5["RF"] = [resnets_rfs[5]] * len(Level5)
    Level6 = pd.read_csv(
        "large_input_pruning_results/resnet25_small_level_6_seed_6_small_imagenet_sgd_100_res_224_no_ffcv_pruning_rates_global_pr_0.9.csv",
        delimiter=",")
    Level6["Layer"] = range(len(Level6))
    Level6["RF"] = [resnets_rfs[6]] * len(Level6)
    Level7 = pd.read_csv(
        "large_input_pruning_results/resnet25_small_level_7_seed_7_small_imagenet_sgd_100_res_224_no_ffcv_pruning_rates_global_pr_0.9.csv",
        delimiter=",")
    Level7["Layer"] = range(len(Level7))
    Level7["RF"] = [resnets_rfs[7]] * len(Level7)
    Level8 = pd.read_csv(
        "large_input_pruning_results/resnet25_small_level_8_seed_8_small_imagenet_sgd_100_res_224_no_ffcv_pruning_rates_global_pr_0.9.csv",
        delimiter=",")
    Level8["Layer"] = range(len(Level8))
    Level8["RF"] = [resnets_rfs[8]] * len(Level8)
    Level10 = pd.read_csv(
        "large_input_pruning_results/resnet25_small_level_10_seed_0_small_imagenet_sgd_100_res_224_no_ffcv_pruning_rates_global_pr_0.9.csv",
        delimiter=",")
    Level10["Layer"] = range(len(Level10))
    Level10["RF"] = [resnets_rfs[10]] * len(Level10)
    Level11 = pd.read_csv(
        "large_input_pruning_results/resnet25_small_level_11_seed_0_small_imagenet_sgd_100_res_224_no_ffcv_pruning_rates_global_pr_0.9.csv",
        delimiter=",")
    Level11["Layer"] = range(len(Level11))
    Level11["RF"] = [resnets_rfs[11]] * len(Level11)
    Level12 = pd.read_csv(
        "large_input_pruning_results/resnet25_small_level_12_seed_0_small_imagenet_sgd_100_res_224_no_ffcv_pruning_rates_global_pr_0.9.csv",
        delimiter=",")
    Level12["Layer"] = range(len(Level12))
    Level12["RF"] = [resnets_rfs[12]] * len(Level12)
    Level13 = pd.read_csv(
        "large_input_pruning_results/resnet25_small_level_13_seed_3_small_imagenet_sgd_100_res_224_no_ffcv_pruning_rates_global_pr_0.9.csv",
        delimiter=",")
    Level13["Layer"] = range(len(Level13))
    Level13["RF"] = [resnets_rfs[13]] * len(Level13)

    # seed2["Layer"]= range(len(seed2))
    # seed3 = pd.read_csv("vgg19_level_1_seed_3_small_imagenet_pruning_rates_global_pr_0.9.csv",delimiter=",")
    # seed3["Layer"]= range(len(seed3))
    # seed4 = pd.read_csv("vgg19_level_1_seed_4_small_imagenet_pruning_rates_global_pr_0.9.csv",delimiter=",")
    # seed4["Layer"]= range(len(seed4))

    all_df = pd.concat([Level5, Level6, Level7, Level8, Level10, Level11, Level12, Level13], ignore_index=True)
    # all_df=pd.concat([seed1,seed2,seed3,seed4])

    # full_dataframe_and_seed0["pr2"]= seed1["pr"]
    # full_dataframe_and_seed0["pr3"]= seed2["pr"]
    # full_dataframe_and_seed0["pr4"]= seed3["pr"]
    # full_dataframe_and_seed0["pr5"]= seed4["pr"]
    # full_dataframe_and_seed0
    # index_layers=[]
    # use=[index_layers.append(num) for num in le_list for le_list in [list(range(len(seed1)))]*5]
    # print(use)

    all_df["Pruning Rate"] = all_df["pr"]

    fig, axs = plt.subplots(2, 4, figsize=(10, 15), layout="compressed", sharey=True, sharex=True)

    rfs = all_df["RF"].unique()
    for i, ax in enumerate(axs.flat):
        rf_df = all_df[all_df["RF"] == rfs[i]]
        ax = sns.barplot(data=rf_df, x="Layer", y="Pruning Rate", color="cornflowerblue", ax=ax)
        # ax.set_ylabel("Pruning Rate",fontsize=20)
        # ax.set_xlabel("Layer",fontsize=20)
        # ax.xaxis.set_major_locator(ticker.MultipleLocator(2))
        # ax.xaxis.set_minor_locator(ticker.MultipleLocator(1))

        ax.set_title("RF={}".format(rfs[i]))
        # ax.tick_params(axis='x', which='major', labelsize=6,rotation=90)
        ax.set_xticklabels([])
        ax.grid(ls="--")
        # ax.tick_params(axis='y', which='major', labelsize=fs*ticks_multiplier)

    # sns.barplot(data=all_df, x="Layer", y="Pruning Rate",color="cornflowerblue")
    plt.ylabel("Pruning Rate", fontsize=20)
    plt.xlabel("Layer", fontsize=20)
    # plt.ylabel("Pruning Rate",fontsize=20)
    # plt.xlabel("Layer",fontsize=20)
    # ax.xaxis.set_major_locator(ticker.MultipleLocator(2))
    # ax.xaxis.set_minor_locator(ticker.MultipleLocator(1))
    # # plt.legend()
    # # plt.xlim(-5,200)
    # ax.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    # fig.set_figheight(10)
    # fig.set_figwidth(15)
    # fig.tight_layout()

    plt.savefig(
        f"/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resne25_small_small_imagenet_pr_per_layer_res_224_pr_0.9.pdf")
    plt.close()

    Level5

    Level8


def flops():
    """# TODO: Flops

    ## Resnet25 Small Imagenet
    """

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker

    flops_df = pd.read_csv("resnet25_small_imagenet_flops_by_rf.csv", delimiter=",")


def variance_explosion_tables():
    """# TODO: Variance Collapse

    ## Original paper

    ## Variance of the difference between dterminisitc pruning and original model and between the stochatic pruning and the noisy dense model

    ### ResNet18 X Cifar10 (Golden case) $\sigma=0.005,\gamma=0.9$
    """

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/resnet18_cifar10_noisy_sto_pr_0.9_sigma_0.005.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/resnet18_cifar10_original_deter.csv", delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)

    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")
    plt.close()

    """### Resent18 x CIFAR100 $\sigma=0.003,\gamma=0.9$"""

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/resnet18_cifar100_noisy_sto_pr_0.9_sigma_0.003.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/resnet18_cifar100_original_deter.csv", delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)

    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")
    plt.close()

    """### Vgg19 x CIFAR10 $\sigma=0.003,\gamma=0.95$"""

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/vgg19_cifar10_noisy_sto_pr_0.95_sigma_0.003.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/vgg19_cifar10_original_deter.csv", delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)

    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")
    plt.close()

    """### Vgg19 x CIFAR100 $\sigma=0.001,\gamma=0.8$"""

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/vgg19_cifar100_noisy_sto_pr_0.8_sigma_0.001.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/vgg19_cifar100_original_deter.csv", delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)
    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")

    plt.close()

    """### ResNet 50 x CIFAR10 $\sigma=0.001,\gamma=0.85$

    """

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/resnet50_cifar10_noisy_sto_pr_0.95_sigma_0.003.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/resnet50_cifar10_original_deter.csv", delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    axs.xaxis.set_major_locator(ticker.AutoLocator())
    axs.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)
    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")

    plt.close()

    """
    ### ResNet 50 x CIFAR100 $\sigma=0.001,\gamma=0.85$"""

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/resnet50_cifar100_noisy_sto_pr_0.85_sigma_0.001.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/resnet50_cifar100_original_deter.csv", delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    axs.xaxis.set_major_locator(ticker.AutoLocator())
    axs.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)
    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")

    plt.close()

    """## Mean of absolute value of the difference between dterminisitc pruning and original model and between the stochatic pruning and the noisy dense model

    ### ResNet18 X Cifar10 (Golden case) $\sigma=0.005,\gamma=0.9$
    """

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/resnet18_cifar10_noisy_sto_pr_0.9_sigma_0.005_absolute_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/resnet18_cifar10_original_deter_absolute_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)

    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")
    plt.close()

    """### Resent18 x CIFAR100 $\sigma=0.003,\gamma=0.9$



    """

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/resnet18_cifar100_noisy_sto_pr_0.9_sigma_0.003_absolute_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/resnet18_cifar100_original_deter_absolute_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)

    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")
    plt.close()

    """### Vgg19 x CIFAR10 $\sigma=0.003,\gamma=0.95$"""

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/vgg19_cifar10_noisy_sto_pr_0.95_sigma_0.003_absolute_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/vgg19_cifar10_original_deter_absolute_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)

    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")
    plt.close()

    """### Vgg19 x CIFAR100 $\sigma=0.001,\gamma=0.8$"""

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/vgg19_cifar100_noisy_sto_pr_0.8_sigma_0.001_absolute_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/vgg19_cifar100_original_deter_absolute_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)
    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")

    plt.close()

    """### ResNet 50 x CIFAR10 $\sigma=0.003,\gamma=0.95$

    """

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/resnet50_cifar10_noisy_sto_pr_0.95_sigma_0.003_absolute_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/resnet50_cifar10_original_deter_absolute_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    axs.xaxis.set_major_locator(ticker.AutoLocator())
    axs.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)
    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")

    plt.close()

    """
    ### ResNet 50 x CIFAR100 $\sigma=0.001,\gamma=0.85$"""

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/resnet50_cifar100_noisy_sto_pr_0.85_sigma_0.001_absolute_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/resnet50_cifar100_original_deter_absolute_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    axs.xaxis.set_major_locator(ticker.AutoLocator())
    axs.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)
    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")

    plt.close()

    """## Mean of L-2 norm of the difference between determinisitc pruning and original model and between the stochatic pruning and the noisy dense model

    ### ResNet18 X Cifar10 (Golden case) $\sigma=0.005,\gamma=0.9$
    """

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/resnet18_cifar10_noisy_sto_pr_0.9_sigma_0.005_l2_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/resnet18_cifar10_original_deter_l2_mean.csv", delimiter=",").T.iloc[
                     1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)

    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")
    plt.close()

    """### Resent18 x CIFAR100 $\sigma=0.003,\gamma=0.9$



    """

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/resnet18_cifar100_noisy_sto_pr_0.9_sigma_0.003_l2_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/resnet18_cifar100_original_deter_l2_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)

    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")
    plt.close()

    """### Vgg19 x CIFAR10 $\sigma=0.003,\gamma=0.95$"""

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/vgg19_cifar10_noisy_sto_pr_0.95_sigma_0.003_l2_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/vgg19_cifar10_original_deter_l2_mean.csv", delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)

    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")
    plt.close()

    """### Vgg19 x CIFAR100 $\sigma=0.001,\gamma=0.8$"""

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/vgg19_cifar100_noisy_sto_pr_0.8_sigma_0.001_l2_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/vgg19_cifar100_original_deter_l2_mean.csv", delimiter=",").T.iloc[
                     1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)
    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")

    plt.close()

    """### ResNet 50 x CIFAR10 $\sigma=0.003,\gamma=0.95$

    """

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/resnet50_cifar10_noisy_sto_pr_0.95_sigma_0.003_l2_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/resnet50_cifar10_original_deter_l2_mean.csv", delimiter=",").T.iloc[
                     1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    axs.xaxis.set_major_locator(ticker.AutoLocator())
    axs.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)
    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")

    plt.close()

    """
    ### ResNet 50 x CIFAR100 $\sigma=0.001,\gamma=0.85$"""

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/resnet50_cifar100_noisy_sto_pr_0.85_sigma_0.001_l2_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/resnet50_cifar100_pr_0.85_original_deter_l2_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    axs.xaxis.set_major_locator(ticker.AutoLocator())
    axs.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)
    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")

    plt.close()

    """# TODO: LAMP

    ## Mean of absolute value of the difference between dterminisitc pruning and original model and between the stochatic pruning and the noisy dense model

    ### ResNet18 X Cifar10 (Golden case) $\sigma=0.005,\gamma=0.9$
    """

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/resnet18_cifar10_noisy_sto_pr_0.9_lamp_sigma_0.005_mean_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/resnet18_cifar10_pr_0.9_lamp_original_deter_absolute_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)

    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")
    plt.close()

    """### Resent18 x CIFAR100 $\sigma=0.003,\gamma=0.9$



    """

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/resnet18_cifar100_noisy_sto_pr_0.9_lamp_sigma_0.003_mean_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/resnet18_cifar100_pr_0.9_lamp_original_deter_absolute_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)

    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")
    plt.close()

    """### Vgg19 x CIFAR10 $\sigma=0.003,\gamma=0.95$"""

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/vgg19_cifar10_noisy_sto_pr_0.95_lamp_sigma_0.003_mean_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/vgg19_cifar10_pr_0.95_lamp_original_deter_absolute_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)

    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")
    plt.close()

    noisy_variance

    """### Vgg19 x CIFAR100 $\sigma=0.001,\gamma=0.8$"""

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/vgg19_cifar100_noisy_sto_pr_0.8_lamp_sigma_0.001_mean_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/vgg19_cifar100_pr_0.8_lamp_original_deter_absolute_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)
    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")

    plt.close()

    """### ResNet 50 x CIFAR10 $\sigma=0.003,\gamma=0.95$

    """

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/resnet50_cifar10_noisy_sto_pr_0.95_lamp_sigma_0.003_mean_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/resnet50_cifar10_pr_0.95_lamp_original_deter_absolute_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    axs.xaxis.set_major_locator(ticker.AutoLocator())
    axs.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)
    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")

    plt.close()

    """
    ### ResNet 50 x CIFAR100 $\sigma=0.001,\gamma=0.85$"""

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv("variance_collapse/resnet50_cifar100_noisy_sto_pr_0.85_lamp_sigma_0.001_mean_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/resnet50_cifar100_pr_0.85_lamp_original_deter_absolute_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    axs.xaxis.set_major_locator(ticker.AutoLocator())
    axs.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)
    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")

    plt.close()

    """# TODO: Actual variance feature calculation and comparison

    ##  Average Variance for each layer across all validation dataset

    ##LAMP

    ### ResNet18 X Cifar10 (Golden case) $\sigma=0.005,\gamma=0.9$
    """

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv(
        "variance_collapse/resnet18_cifar10_noisy_sto_pr_0.9_lamp_sigma_0.005_pruned_var_mean.csv",
        delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/resnet18_cifar10_pr_0.9_lamp_original_pruned_deter_var_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)

    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")
    plt.close()

    """### Resent18 x CIFAR100 $\sigma=0.003,\gamma=0.9$



    """

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv(
        "variance_collapse/resnet18_cifar100_noisy_sto_pr_0.9_lamp_sigma_0.003_pruned_var_mean.csv",
        delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/resnet18_cifar100_pr_0.9_lamp_original_pruned_deter_var_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)

    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")
    plt.close()

    """### Vgg19 x CIFAR10 $\sigma=0.003,\gamma=0.95$"""

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv(
        "variance_collapse/vgg19_cifar10_noisy_sto_pr_0.95_lamp_sigma_0.003_pruned_var_mean.csv", delimiter=",").T.iloc[
                     1:]
    clean_variance = pd.read_csv("variance_collapse/vgg19_cifar10_pr_0.95_lamp_original_pruned_deter_var_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)

    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")
    plt.close()

    noisy_variance

    """### Vgg19 x CIFAR100 $\sigma=0.001,\gamma=0.8$"""

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv(
        "variance_collapse/vgg19_cifar100_noisy_sto_pr_0.8_lamp_sigma_0.001_pruned_var_mean.csv", delimiter=",").T.iloc[
                     1:]
    clean_variance = pd.read_csv("variance_collapse/vgg19_cifar100_pr_0.8_lamp_original_pruned_deter_var_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)
    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")

    plt.close()

    """### ResNet 50 x CIFAR10 $\sigma=0.003,\gamma=0.95$

    """

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv(
        "variance_collapse/resnet50_cifar10_noisy_sto_pr_0.95_lamp_sigma_0.003_pruned_var_mean.csv",
        delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/resnet50_cifar10_pr_0.95_lamp_original_pruned_deter_var_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    axs.xaxis.set_major_locator(ticker.AutoLocator())
    axs.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)
    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")

    plt.close()

    """
    ### ResNet 50 x CIFAR100 $\sigma=0.001,\gamma=0.85$"""

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.read_csv(
        "variance_collapse/resnet50_cifar100_noisy_sto_pr_0.85_lamp_sigma_0.001_pruned_var_mean.csv",
        delimiter=",").T.iloc[1:]
    clean_variance = pd.read_csv("variance_collapse/resnet50_cifar100_pr_0.85_lamp_original_pruned_deter_var_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    #

    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    axs.xaxis.set_major_locator(ticker.AutoLocator())
    axs.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)
    clean_mean = clean_variance["Variance"].mean()
    noisy_mean = noisy_variance["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")

    plt.close()

    """## GMP

    ### ResNet18 X Cifar10 (Golden case) $\sigma=0.005,\gamma=0.9$
    """

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.DataFrame(
        pd.read_csv("variance_collapse/resnet18_cifar10_noisy_sto_pr_0.9_global_sigma_0.005_pruned_var_mean.csv",
                    delimiter=",").mean(axis=0).rename("Variance"))
    clean_variance = pd.read_csv("variance_collapse/resnet18_cifar10_pr_0.9_global_original_pruned_deter_var_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    # noisy_variance = noisy_variance.rename(columns={0:"Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    noisy_variance_dense = pd.DataFrame(
        pd.read_csv("variance_collapse/resnet18_cifar10_noisy_sto_pr_0.9_global_sigma_0.005_dense_var_mean.csv",
                    delimiter=",").mean(axis=0).rename("Variance"))
    clean_variance_dense = pd.read_csv(
        "variance_collapse/resnet18_cifar10_pr_0.9_global_original_dense_deter_var_mean.csv", delimiter=",").T.iloc[1:]
    clean_variance_dense = clean_variance_dense.rename(columns={0: "Variance"})
    noisy_variance_dense = noisy_variance_dense.rename(columns={0: "Variance"})
    clean_variance_dense["Layer"] = clean_variance_dense.index
    noisy_variance_dense["Layer"] = noisy_variance_dense.index
    clean_variance_dense.index = range(len(clean_variance_dense))
    noisy_variance_dense.index = range(len(noisy_variance_dense))
    clean_variance_dense["Type"] = ["Deterministic"] * len(clean_variance_dense)
    noisy_variance_dense["Type"] = ["Stochastic"] * len(noisy_variance_dense)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    all_df_dense = pd.concat([clean_variance_dense, noisy_variance_dense], ignore_index=True)
    #
    all_df["Variance"] = all_df["Variance"] / all_df_dense["Variance"]
    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)
    clean_mean = all_df[all_df["Type"] == "Deterministic"]["Variance"].mean()
    noisy_mean = all_df[all_df["Type"] == "Stochastic"]["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")

    plt.close()

    """### Resent18 x CIFAR100 $\sigma=0.003,\gamma=0.9$



    """

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.DataFrame(
        pd.read_csv("variance_collapse/resnet18_cifar100_noisy_sto_pr_0.9_global_sigma_0.003_pruned_var_mean.csv",
                    delimiter=",").mean(axis=1).rename("Variance"))
    clean_variance = pd.read_csv("variance_collapse/resnet18_cifar100_pr_0.9_global_original_pruned_deter_var_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    # noisy_variance = noisy_variance.rename(columns={0:"Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    noisy_variance_dense = pd.DataFrame(
        pd.read_csv("variance_collapse/resnet18_cifar100_noisy_sto_pr_0.9_global_sigma_0.003_dense_var_mean.csv",
                    delimiter=",").mean(axis=1).rename("Variance"))
    clean_variance_dense = pd.read_csv(
        "variance_collapse/resnet18_cifar100_pr_0.9_global_original_dense_deter_var_mean.csv", delimiter=",").T.iloc[1:]
    clean_variance_dense = clean_variance_dense.rename(columns={0: "Variance"})
    # noisy_variance_dense = noisy_variance_dense.rename(columns={0:"Variance"})
    clean_variance_dense["Layer"] = clean_variance_dense.index
    # noisy_variance_dense["Layer"] = noisy_variance_dense.index
    clean_variance_dense.index = range(len(clean_variance_dense))
    noisy_variance_dense.index = range(len(noisy_variance_dense))
    clean_variance_dense["Type"] = ["Deterministic"] * len(clean_variance_dense)
    noisy_variance_dense["Type"] = ["Stochastic"] * len(noisy_variance_dense)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    all_df_dense = pd.concat([clean_variance_dense, noisy_variance_dense], ignore_index=True)
    #
    all_df["Variance"] = all_df["Variance"] / all_df_dense["Variance"]
    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)
    clean_mean = all_df[all_df["Type"] == "Deterministic"]["Variance"].mean()
    noisy_mean = all_df[all_df["Type"] == "Stochastic"]["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")

    plt.close()

    """### Vgg19 x CIFAR10 $\sigma=0.003,\gamma=0.95$"""

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.DataFrame(
        pd.read_csv("variance_collapse/vgg19_cifar10_noisy_sto_pr_0.95_global_sigma_0.003_pruned_var_mean.csv",
                    delimiter=",").mean(axis=1).rename("Variance"))
    clean_variance = pd.read_csv("variance_collapse/vgg19_cifar10_pr_0.95_global_original_pruned_deter_var_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    noisy_variance = noisy_variance.rename(columns={0: "Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))

    noisy_variance_dense = pd.DataFrame(
        pd.read_csv("variance_collapse/vgg19_cifar10_noisy_sto_pr_0.95_global_sigma_0.003_dense_var_mean.csv",
                    delimiter=",").mean(axis=1).rename("Variance"))
    clean_variance_dense = pd.read_csv(
        "variance_collapse/vgg19_cifar10_pr_0.95_global_original_dense_deter_var_mean.csv", delimiter=",").T.iloc[1:]
    clean_variance_dense = clean_variance_dense.rename(columns={0: "Variance"})
    # noisy_variance_dense = noisy_variance_dense.rename(columns={0:"Variance"})
    clean_variance_dense["Layer"] = clean_variance_dense.index
    noisy_variance_dense["Layer"] = noisy_variance_dense.index
    clean_variance_dense.index = range(len(clean_variance_dense))
    noisy_variance_dense.index = range(len(noisy_variance_dense))
    clean_variance_dense["Type"] = ["Deterministic"] * len(clean_variance_dense)
    noisy_variance_dense["Type"] = ["Stochastic"] * len(noisy_variance_dense)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    all_df_dense = pd.concat([clean_variance_dense, noisy_variance_dense], ignore_index=True)
    #
    all_df["Variance"] = all_df["Variance"] / all_df_dense["Variance"]
    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)
    clean_mean = all_df[all_df["Type"] == "Deterministic"]["Variance"].mean()
    noisy_mean = all_df[all_df["Type"] == "Stochastic"]["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")

    plt.close()

    noisy_variance

    """### Vgg19 x CIFAR100 $\sigma=0.001,\gamma=0.8$"""

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.DataFrame(
        pd.read_csv("variance_collapse/vgg19_cifar100_noisy_sto_pr_0.8_global_sigma_0.001_pruned_var_mean.csv",
                    delimiter=",").mean(axis=1).rename("Variance"))
    noisy_variance_dense = pd.DataFrame(
        pd.read_csv("variance_collapse/vgg19_cifar100_noisy_sto_pr_0.8_global_sigma_0.001_dense_var_mean.csv",
                    delimiter=",").mean(axis=1).rename("Variance"))
    clean_variance = pd.read_csv("variance_collapse/vgg19_cifar100_pr_0.8_global_original_pruned_deter_var_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance_dense = pd.read_csv(
        "variance_collapse/vgg19_cifar100_pr_0.8_global_original_dense_deter_var_mean.csv", delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    # noisy_variance = noisy_variance.rename(columns={0:"Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    clean_variance_dense = clean_variance_dense.rename(columns={0: "Variance"})
    noisy_variance_dense = noisy_variance_dense.rename(columns={0: "Variance"})
    clean_variance_dense["Layer"] = clean_variance_dense.index
    noisy_variance_dense["Layer"] = noisy_variance_dense.index
    clean_variance_dense.index = range(len(clean_variance_dense))
    noisy_variance_dense.index = range(len(noisy_variance_dense))
    clean_variance_dense["Type"] = ["Deterministic"] * len(clean_variance_dense)
    noisy_variance_dense["Type"] = ["Stochastic"] * len(noisy_variance_dense)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    all_df_dense = pd.concat([clean_variance_dense, noisy_variance_dense], ignore_index=True)
    #
    all_df["Variance"] = all_df["Variance"] / all_df_dense["Variance"]
    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)
    clean_mean = all_df[all_df["Type"] == "Deterministic"]["Variance"].mean()
    noisy_mean = all_df[all_df["Type"] == "Stochastic"]["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")

    plt.close()

    all_df

    pd.read_csv("variance_collapse/vgg19_cifar100_noisy_sto_pr_0.8_global_sigma_0.001_dense_var_mean.csv",
                delimiter=",")  # .T.iloc[1:]

    pd.read_csv("variance_collapse/vgg19_cifar100_noisy_sto_pr_0.8_global_sigma_0.001_dense_var_mean.csv",
                delimiter=",").mean(axis=0).T.iloc[1:]

    """### ResNet 50 x CIFAR10 $\sigma=0.003,\gamma=0.95$

    """

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.DataFrame(
        pd.read_csv("variance_collapse/resnet50_cifar10_noisy_sto_pr_0.95_global_sigma_0.003_pruned_var_mean.csv",
                    delimiter=",").mean(axis=1).rename("Variance"))
    clean_variance = pd.read_csv("variance_collapse/resnet50_cifar10_pr_0.95_global_original_pruned_deter_var_mean.csv",
                                 delimiter=",").T.iloc[1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    # noisy_variance = noisy_variance.rename(columns={0:"Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)

    noisy_variance_dense = pd.DataFrame(
        pd.read_csv("variance_collapse/resnet50_cifar10_noisy_sto_pr_0.95_global_sigma_0.003_dense_var_mean.csv",
                    delimiter=",").mean(axis=1).rename("Variance"))
    clean_variance_dense = pd.read_csv(
        "variance_collapse/resnet50_cifar10_pr_0.95_global_original_dense_deter_var_mean.csv", delimiter=",").T.iloc[1:]
    clean_variance_dense = clean_variance_dense.rename(columns={0: "Variance"})
    noisy_variance_dense = noisy_variance_dense.rename(columns={0: "Variance"})
    clean_variance_dense["Layer"] = clean_variance_dense.index
    noisy_variance_dense["Layer"] = noisy_variance_dense.index
    clean_variance_dense.index = range(len(clean_variance_dense))
    noisy_variance_dense.index = range(len(noisy_variance_dense))
    clean_variance_dense["Type"] = ["Deterministic"] * len(clean_variance_dense)
    noisy_variance_dense["Type"] = ["Stochastic"] * len(noisy_variance_dense)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    all_df_dense = pd.concat([clean_variance_dense, noisy_variance_dense], ignore_index=True)
    #
    all_df["Variance"] = all_df["Variance"] / all_df_dense["Variance"]
    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)
    clean_mean = all_df[all_df["Type"] == "Deterministic"]["Variance"].mean()
    noisy_mean = all_df[all_df["Type"] == "Stochastic"]["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")

    plt.close()

    """
    ### ResNet 50 x CIFAR100 $\sigma=0.001,\gamma=0.85$"""

    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    import matplotlib.ticker as ticker
    from matplotlib.patches import Patch

    noisy_variance = pd.DataFrame(
        pd.read_csv("variance_collapse/resnet50_cifar100_noisy_sto_pr_0.85_global_sigma_0.001_pruned_var_mean.csv",
                    delimiter=",").mean(axis=1).rename("Variance"))
    clean_variance = pd.read_csv(
        "variance_collapse/resnet50_cifar100_pr_0.85_global_original_pruned_deter_var_mean.csv", delimiter=",").T.iloc[
                     1:]
    clean_variance = clean_variance.rename(columns={0: "Variance"})
    # noisy_variance = noisy_variance.rename(columns={0:"Variance"})
    clean_variance["Layer"] = clean_variance.index
    noisy_variance["Layer"] = noisy_variance.index

    clean_variance.index = range(len(clean_variance))
    noisy_variance.index = range(len(noisy_variance))
    clean_variance["Type"] = ["Deterministic"] * len(clean_variance)
    noisy_variance["Type"] = ["Stochastic"] * len(noisy_variance)
    noisy_variance_dense = pd.DataFrame(
        pd.read_csv("variance_collapse/resnet50_cifar100_noisy_sto_pr_0.85_global_sigma_0.001_dense_var_mean.csv",
                    delimiter=",").mean(axis=1).rename("Variance"))
    clean_variance_dense = pd.read_csv(
        "variance_collapse/resnet50_cifar100_pr_0.85_global_original_dense_deter_var_mean.csv", delimiter=",").T.iloc[
                           1:]
    clean_variance_dense = clean_variance_dense.rename(columns={0: "Variance"})
    noisy_variance_dense = noisy_variance_dense.rename(columns={0: "Variance"})
    clean_variance_dense["Layer"] = clean_variance_dense.index
    noisy_variance_dense["Layer"] = noisy_variance_dense.index
    clean_variance_dense.index = range(len(clean_variance_dense))
    noisy_variance_dense.index = range(len(noisy_variance_dense))
    clean_variance_dense["Type"] = ["Deterministic"] * len(clean_variance_dense)
    noisy_variance_dense["Type"] = ["Stochastic"] * len(noisy_variance_dense)

    all_df = pd.concat([clean_variance, noisy_variance], ignore_index=True)
    all_df_dense = pd.concat([clean_variance_dense, noisy_variance_dense], ignore_index=True)
    #
    all_df["Variance"] = all_df["Variance"] / all_df_dense["Variance"]
    fig, axs = plt.subplots(1, 1, figsize=fig_size, layout="compressed", sharey=True)

    b = sns.barplot(ax=axs, data=all_df, x="Layer", y="Variance", hue="Type", alpha=0.5)
    # b.set_yscale("log")

    axs.legend(prop={"size": fs * 1.7}, loc="upper left")
    axs.set_xlabel("Layer", fontsize=25)
    axs.set_xticklabels([])
    axs.set_xticklabels(range(len(axs.get_xticks())), size=25)

    # for ax in axs.flat:
    axs.tick_params(axis='both', which='major', labelsize=fs * ticks_multiplier)
    # axs.tick_params(axis='x', which='major', labelrotation=90)
    # sns.barplot(ax=axs[1],data=all_df,x="Layer",y="Variance",color="Type",legend=False,alpha=0.3)

    # sns.barplot(ax=axs[1],data=all_df,x="RF",y="Pruned Accuracy",hue="optimiser",legend=False,alpha=0.5)
    clean_mean = all_df[all_df["Type"] == "Deterministic"]["Variance"].mean()
    noisy_mean = all_df[all_df["Type"] == "Stochastic"]["Variance"].mean()
    print(f"Average variance det-original:{clean_mean}")
    print(f"Average variance sto-noisy:{noisy_mean}")


def resnet25_small_imagenet_saturation():
    """## ResNet2t5 z Small ImageNet RESIZED

    # Saturation

    ## Resnet25 x Small ImageNet
    """
    resnet25_all_conv_layers= ['conv1', 'layer1.0.conv1_1x1', 'layer1.0.conv2_1x1', 'layer1.0.conv3_3x3', 'layer1.0.conv4_1x1',
     'layer1.0.conv5_1x1', 'layer1.0.shortcut.0', 'layer2.0.conv1_1x1', 'layer2.0.conv2_1x1', 'layer2.0.conv3_3x3',
     'layer2.0.conv4_1x1', 'layer2.0.conv5_1x1', 'layer2.0.shortcut.0', 'layer3.0.conv1_1x1', 'layer3.0.conv2_1x1',
     'layer3.0.conv3_3x3', 'layer3.0.conv4_1x1', 'layer3.0.conv5_1x1', 'layer3.0.shortcut.0',
     'layer3.1.conv1_1x1', 'layer3.1.conv2_1x1', 'layer3.1.conv3_3x3', 'layer3.1.conv4_1x1', 'layer3.1.conv5_1x1',
     'layer4.0.conv1_1x1', 'layer4.0.conv2_1x1', 'layer4.0.conv3_3x3', 'layer4.0.conv4_1x1',
     'layer4.0.conv5_1x1', 'layer4.0.shortcut.0', 'linear']
    rs25_in_block_layers_index = [resnet25_all_conv_layers.index(l) for l in resnet25_all_conv_layers if not ("conv5_1x1" in l or "shortcut" in l or "conv1"== l)]
    rs25_out_block_layers_index = [resnet25_all_conv_layers.index(l) for l in resnet25_all_conv_layers if "conv5_1x1"in l or "shortcut" in l or "conv1"== l]

    import pandas as pd
    import matplotlib.pyplot as plt
    import seaborn as sns

    resnets_rfs_keys = [5, 6, 7, 8, 10, 11, 12, 13]
    resnets_rfs_values = [128, 153, 178, 203, 253, 1078, 1428, 1954]
    resnet_rfs = dict(zip(resnets_rfs_keys, resnets_rfs_values))
    # preamble = "drive/MyDrive/PhD/solutions_small_imagenet/saturation_resnet25/resnet25_small"
    preamble = "/home/luisaam/Documents/PhD/data/solutions_small_imagenet/saturation_resnet25/resnet25_small"
    #         drive/MyDrive/PhD/solutions_small_imagenet/saturation_resnet25/resnet25_small/resnet25_small_10_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv
    sat_lvl_5_seed_0 = "resnet25_small_5_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_5_seed_1 = "resnet25_small_5_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_5_seed_2 = "resnet25_small_5_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    sat_lvl_6_seed_0 = "resnet25_small_6_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_6_seed_1 = "resnet25_small_6_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_6_seed_2 = "resnet25_small_6_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    sat_lvl_7_seed_0 = "resnet25_small_7_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_7_seed_1 = "resnet25_small_7_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_7_seed_2 = "resnet25_small_7_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    sat_lvl_8_seed_0 = "resnet25_small_8_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_8_seed_1 = "resnet25_small_8_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_8_seed_2 = "resnet25_small_8_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    sat_lvl_10_seed_0 = "resnet25_small_10_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_10_seed_1 = "resnet25_small_10_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_10_seed_2 = "resnet25_small_10_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    sat_lvl_11_seed_0 = "resnet25_small_11_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_11_seed_1 = "resnet25_small_11_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_11_seed_2 = "resnet25_small_11_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    sat_lvl_12_seed_0 = "resnet25_small_12_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_12_seed_1 = "resnet25_small_12_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_12_seed_2 = "resnet25_small_12_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    sat_lvl_13_seed_0 = "resnet25_small_13_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_0.csv"
    sat_lvl_13_seed_1 = "resnet25_small_13_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_1.csv"
    sat_lvl_13_seed_2 = "resnet25_small_13_small_imagenet_sgd_100_res_224_no_ffcv_pr_0.0_saturation_trained_seed_2.csv"

    level5_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_5_seed_0}", delimiter=";")
    level5_seed1 = pd.read_csv(f"{preamble}/{sat_lvl_5_seed_1}", delimiter=";")
    level5_seed2 = pd.read_csv(f"{preamble}/{sat_lvl_5_seed_2}", delimiter=";")

    lvl5 = pd.concat([level5_seed0, level5_seed1, level5_seed2])

    epoch_df_train, pm = extract_layer_stat(lvl5,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl5,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    # lvl5["average-train-sat"] = epoch_df_train.mean(axis=1)
    # lvl5["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl5["RF"] = len(lvl5) * [resnet_rfs[5]]

    level6_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_6_seed_0}", delimiter=";")
    level6_seed1 = pd.read_csv(f"{preamble}/{sat_lvl_6_seed_1}", delimiter=";")
    level6_seed2 = pd.read_csv(f"{preamble}/{sat_lvl_6_seed_2}", delimiter=";")

    lvl6 = pd.concat([level6_seed0, level6_seed1, level6_seed2])
    epoch_df_train, pm = extract_layer_stat(lvl6,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl6,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    # lvl6["average-train-sat"] = epoch_df_train.mean(axis=1)
    # lvl6["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl6["RF"] = len(lvl6) * [resnet_rfs[6]]

    level7_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_7_seed_0}", delimiter=";")
    level7_seed1 = pd.read_csv(f"{preamble}/{sat_lvl_7_seed_1}", delimiter=";")
    level7_seed2 = pd.read_csv(f"{preamble}/{sat_lvl_7_seed_2}", delimiter=";")

    lvl7 = pd.concat([level7_seed0, level7_seed1, level7_seed2])
    epoch_df_train, pm = extract_layer_stat(lvl7,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl7,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    # lvl7["average-train-sat"] = epoch_df_train.mean(axis=1)
    # lvl7["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl7["RF"] = len(lvl7) * [resnet_rfs[7]]

    level8_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_8_seed_0}", delimiter=";")
    level8_seed1 = pd.read_csv(f"{preamble}/{sat_lvl_8_seed_1}", delimiter=";")
    level8_seed2 = pd.read_csv(f"{preamble}/{sat_lvl_8_seed_2}", delimiter=";")

    lvl8 = pd.concat([level8_seed0, level8_seed1, level8_seed2])
    epoch_df_train, pm = extract_layer_stat(lvl8,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl8,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    # lvl8["average-train-sat"] = epoch_df_train.mean(axis=1)
    # lvl8["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl8["RF"] = len(lvl8) * [resnet_rfs[8]]

    level10_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_10_seed_0}", delimiter=";")
    level10_seed1 = pd.read_csv(f"{preamble}/{sat_lvl_10_seed_1}", delimiter=";")
    level10_seed2 = pd.read_csv(f"{preamble}/{sat_lvl_10_seed_2}", delimiter=";")

    lvl10 = pd.concat([level10_seed0, level10_seed1, level10_seed2])

    epoch_df_train, pm = extract_layer_stat(lvl10,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl10,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    # lvl10["average-train-sat"] = epoch_df_train.mean(axis=1)
    # lvl10["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl10["RF"] = len(lvl10) * [resnet_rfs[10]]

    level11_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_11_seed_0}", delimiter=";")
    level11_seed1 = pd.read_csv(f"{preamble}/{sat_lvl_11_seed_1}", delimiter=";")
    level11_seed2 = pd.read_csv(f"{preamble}/{sat_lvl_11_seed_2}", delimiter=";")

    lvl11 = pd.concat([level11_seed0, level11_seed1, level11_seed2])
    epoch_df_train, pm = extract_layer_stat(lvl11,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl11,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    # lvl11["average-train-sat"] = epoch_df_train.mean(axis=1)
    # lvl11["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl11["RF"] = len(lvl11) * [resnet_rfs[11]]

    level12_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_12_seed_0}", delimiter=";")
    level12_seed1 = pd.read_csv(f"{preamble}/{sat_lvl_12_seed_1}", delimiter=";")
    level12_seed2 = pd.read_csv(f"{preamble}/{sat_lvl_12_seed_2}", delimiter=";")

    lvl12 = pd.concat([level12_seed0, level12_seed1, level12_seed2])
    epoch_df_train, pm = extract_layer_stat(lvl12,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl12,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    # lvl12["average-train-sat"] = epoch_df_train.mean(axis=1)
    # lvl12["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl12["RF"] = len(lvl12) * [resnet_rfs[12]]

    level13_seed0 = pd.read_csv(f"{preamble}/{sat_lvl_13_seed_0}", delimiter=";")
    level13_seed1 = pd.read_csv(f"{preamble}/{sat_lvl_13_seed_1}", delimiter=";")
    level13_seed2 = pd.read_csv(f"{preamble}/{sat_lvl_13_seed_2}", delimiter=";")

    lvl13 = pd.concat([level13_seed0, level13_seed1, level13_seed2])
    epoch_df_train, pm = extract_layer_stat(lvl13,
                                            epoch=0,
                                            primary_metric=None,
                                            stat='saturation',
                                            state_mode="train")
    epoch_df_test, pm = extract_layer_stat(lvl13,
                                           epoch=0,
                                           primary_metric=None,
                                           stat='saturation',
                                           state_mode="eval")
    # lvl13["average-train-sat"] = epoch_df_train.mean(axis=1)
    # lvl13["average-eval-sat"] = epoch_df_test.mean(axis=1)
    lvl13["RF"] = len(lvl13) * [resnet_rfs[13]]

    # all_df = pd.concat([lvl5, lvl6, lvl7, lvl8, lvl10, lvl11, lvl12, lvl13], ignore_index=True)
    all_df = pd.concat([lvl5, lvl6, lvl7, lvl8, lvl10], ignore_index=True)

    # fig_size = (7, 5)
    # ticks_multiplier = 1.3
    # labels_multiplier = 1.8
    import matplotlib as mpl
    fig, ax = plt.subplots(1, 1, figsize=fig_size, sharey=True, sharex=True, layout="tight")

    unique_RF = all_df["RF"].unique()
    num_colors = len(unique_RF)
    cm = mpl.cm.get_cmap(name='magma')
    currentColors = [cm(1. * i / num_colors) for i in range(num_colors)]

    # colors = ["blue","red","green","yellow"]
    colors = ["blue", "red", "green", "orange", "yellow"]
    # optimisers = ["SGD"]

    # for i, ax in enumerate(axs.flat):
    for i, color in enumerate(currentColors):
        current_df = all_df[all_df["RF"] == unique_RF[i]]
        current_df = current_df.mean(axis=0).to_frame().T

        epoch_df_dense, pm = extract_layer_stat(current_df,
                                                epoch=0,
                                                primary_metric=None,
                                                stat='saturation',
                                                state_mode="train")
        layer_values=epoch_df_dense.values[0]
        # layer_values = np.flip(layer_values)
        layer_values=layer_values[rs25_out_block_layers_index]

        plot_saturation(epoch_df=epoch_df_dense, ax=ax, log=False, color=color, label=f"{unique_RF[i]}", ewma=False,
                        window=5)
        # ax.scatter(x=range(len(in_block_layers_index)), y=epoch_df_dense.values[0][in_block_layers_index], color=color, marker="o",label=f"{unique_RF[i]}")
        # ax.scatter(x=range(len(layer_values)), y=layer_values, color=color, marker="o",label=f"{unique_RF[i]}")
    # ax.set_title(f"{unique_RF[i]}")
    ax.grid(ls="--", alpha=0.5)
    # ax.set_xlabel("")
    # ax.set_ylabel("")

    # ax.set_xticks(range(len(rs25_out_block_layers_index)), rs25_out_block_layers_index, color="k")
    ax.set_xticklabels(range(len(epoch_df_dense.values[0])))
    ax.set_yticks([0,0.1, 0.2, 0.3, 0.4, 0.5,0.6,0.7], [0,0.1, 0.2, 0.3, 0.4, 0.5,0.6,0.7], color="k")
    # ax.set_xlabel("Layer",fontsize=fs*labels_multiplier)
    # ax.set_ylabel("Saturation",fontsize=fs*labels_multiplier)
    ax.xaxis.set_major_locator(ticker.MultipleLocator(2))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(1))

    # ax.set_yticks([-3, -2.5, -2, -1.5, -1], [-3, -2.5, -2, -1.5, -1], color="k")
    # ax.set_xticks([])
    # ax.tick_params(axis="x",color="w")
    ax.tick_params(axis="both", labelsize=fs * ticks_multiplier)

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet25_small_imagenet_saturation_all_no_scatter_detailed_v2.pdf",
                bbox_inches="tight")
    # fig, axs = plt.subplots(1, 2, figsize=fig_size, sharex="all",sharey=True, layout="compressed")
    #
    # # fig, axes = plt.subplots(3, 2, figsize=fig_size, sharex="all", sharey="all", layout="compressed")
    #
    # sns.barplot(data=all_df, x="RF", y="average-train-sat", ax=axs[0])
    # sns.barplot(data=all_df, x="RF", y="average-eval-sat", ax=axs[1])
    #
    # sns.stripplot(
    #     x="RF",
    #     y="average-train-sat",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)
    #
    # sns.stripplot(
    #     x="RF",
    #     y="average-eval-sat",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)
    #
    # axs[0].set_ylabel('Average Train Saturation',labelsize=fs*labels_multiplier)
    # axs[1].set_ylabel('Average Test Saturation',labelsize=fs*labels_multiplier)
    #
    # axs[0].set_xlabel("")
    # axs[1].set_xlabel("")
    #
    # axs[0].grid(ls="--")
    # axs[1].grid(ls="--")
    #
    # for ax in axs.flat:
    #     ax.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    #     # ax.tick_params(axis='x', which='major', labelrotation=90)
    #
    # fig_multiplier = 1.7
    # fig.text(0.55, -0.019, 'Receptive Field', ha='center', size=fs *labels_multiplier)
    # # fig.text(0.25, 0.5, 'Receptive Field', va='center', rotation="vertical", size=fs * fig_multiplier)
    #
    # # plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_saturation_resnet25_small_imagenet_detailed.pdf")
    plt.close()

############################################kk
    fig, ax = plt.subplots(1, 1, figsize=fig_size, sharey=True, sharex=True, layout="tight")

    unique_RF = all_df["RF"].unique()
    num_colors = len(unique_RF)
    cm = mpl.cm.get_cmap(name='magma')
    currentColors = [cm(1. * i / num_colors) for i in range(num_colors)]

    # colors = ["blue","red","green","yellow"]
    colors = ["blue", "red", "green", "orange", "yellow"]
    # optimisers = ["SGD"]

    # for i, ax in enumerate(axs.flat):
    for i, color in enumerate(currentColors):
        current_df = all_df[all_df["RF"] == unique_RF[i]]
        current_df = current_df.mean(axis=0).to_frame().T

        epoch_df_dense, pm = extract_layer_stat(current_df,
                                                epoch=0,
                                                primary_metric=None,
                                                stat='saturation',
                                                state_mode="train")
        layer_values=epoch_df_dense.values[0]
        # layer_values = np.flip(layer_values)
        layer_values=layer_values[rs25_in_block_layers_index]

        # plot_saturation(epoch_df=epoch_df_dense, ax=ax, log=False, color=color, label=f"{unique_RF[i]}", ewma=False,
        #                 window=5)
        # ax.scatter(x=range(len(in_block_layers_index)), y=epoch_df_dense.values[0][in_block_layers_index], color=color, marker="o",label=f"{unique_RF[i]}")
        ax.scatter(x=range(len(layer_values)), y=layer_values, color=color, marker="o",label=f"{unique_RF[i]}")
    # ax.set_title(f"{unique_RF[i]}")
    ax.grid(ls="--", alpha=0.5)
    # ax.set_xlabel("")
    # ax.set_ylabel("")

    ax.set_xticks(range(len(rs25_in_block_layers_index)), rs25_in_block_layers_index, color="k")
    ax.set_yticks([0,0.1, 0.2, 0.3, 0.4, 0.5,0.6,0.7], [0,0.1, 0.2, 0.3, 0.4, 0.5,0.6,0.7], color="k")
    ax.set_xlabel("Layer",fontsize=fs*labels_multiplier)
    ax.set_ylabel("Saturation",fontsize=fs*labels_multiplier)
    ax.xaxis.set_major_locator(ticker.MultipleLocator(3))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(1))

    # ax.set_yticks([-3, -2.5, -2, -1.5, -1], [-3, -2.5, -2, -1.5, -1], color="k")
    # ax.set_xticks([])
    # ax.tick_params(axis="x",color="w")
    ax.tick_params(axis="both", labelsize=fs * ticks_multiplier)
    # plt.legend()
    # ax.legend()

    # Y axis

    # fig.text(-0.015, 0.5, '$\log($Saturation$)$', va='center', rotation="vertical", size=fs * labels_multiplier
    #          )
    #
    # # X axis
    # fig.text(0.5, -0.04, 'Layer', ha='center', size=fs * labels_multiplier)

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet25_small_imagenet_saturation_inblock_detailed_v2.pdf",
                bbox_inches="tight")
    # fig, axs = plt.subplots(1, 2, figsize=fig_size, sharex="all",sharey=True, layout="compressed")
    #
    # # fig, axes = plt.subplots(3, 2, figsize=fig_size, sharex="all", sharey="all", layout="compressed")
    #
    # sns.barplot(data=all_df, x="RF", y="average-train-sat", ax=axs[0])
    # sns.barplot(data=all_df, x="RF", y="average-eval-sat", ax=axs[1])
    #
    # sns.stripplot(
    #     x="RF",
    #     y="average-train-sat",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[0], legend=False)
    #
    # sns.stripplot(
    #     x="RF",
    #     y="average-eval-sat",
    #     data=all_df, dodge=True, alpha=0.6, ax=axs[1], legend=False)
    #
    # axs[0].set_ylabel('Average Train Saturation',labelsize=fs*labels_multiplier)
    # axs[1].set_ylabel('Average Test Saturation',labelsize=fs*labels_multiplier)
    #
    # axs[0].set_xlabel("")
    # axs[1].set_xlabel("")
    #
    # axs[0].grid(ls="--")
    # axs[1].grid(ls="--")
    #
    # for ax in axs.flat:
    #     ax.tick_params(axis='both', which='major', labelsize=fs*ticks_multiplier)
    #     # ax.tick_params(axis='x', which='major', labelrotation=90)
    #
    # fig_multiplier = 1.7
    # fig.text(0.55, -0.019, 'Receptive Field', ha='center', size=fs *labels_multiplier)
    # # fig.text(0.25, 0.5, 'Receptive Field', va='center', rotation="vertical", size=fs * fig_multiplier)
    #
    # # plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/average_saturation_resnet25_small_imagenet_detailed.pdf")
    plt.close()

    fig, ax = plt.subplots(1, 1, figsize=fig_size, sharey=True, sharex=True, layout="tight")

    unique_RF = all_df["RF"].unique()
    num_colors = len(unique_RF)
    cm = mpl.cm.get_cmap(name='magma')
    currentColors = [cm(1. * i / num_colors) for i in range(num_colors)]

    # colors = ["blue","red","green","yellow"]
    colors = ["blue", "red", "green", "orange", "yellow"]
    # optimisers = ["SGD"]

    # for i, ax in enumerate(axs.flat):
    for i, color in enumerate(currentColors):
        current_df = all_df[all_df["RF"] == unique_RF[i]]
        current_df = current_df.mean(axis=0).to_frame().T

        epoch_df_dense, pm = extract_layer_stat(current_df,
                                                epoch=0,
                                                primary_metric=None,
                                                stat='saturation',
                                                state_mode="train")
        layer_values=epoch_df_dense.values[0]
        # layer_values = np.flip(layer_values)
        layer_values=layer_values[rs25_out_block_layers_index]

        # plot_saturation(epoch_df=epoch_df_dense, ax=ax, log=False, color=color, label=f"{unique_RF[i]}", ewma=False,
        #                 window=5)
        # ax.scatter(x=range(len(in_block_layers_index)), y=epoch_df_dense.values[0][in_block_layers_index], color=color, marker="o",label=f"{unique_RF[i]}")
        ax.scatter(x=range(len(layer_values)), y=layer_values, color=color, marker="o",label=f"{unique_RF[i]}")
    # ax.set_title(f"{unique_RF[i]}")
    ax.grid(ls="--", alpha=0.5)
    # ax.set_xlabel("")
    # ax.set_ylabel("")

    ax.set_xticks(range(len(rs25_out_block_layers_index)), rs25_out_block_layers_index, color="k")
    ax.set_yticks([0,0.1, 0.2, 0.3, 0.4, 0.5,0.6,0.7], [0,0.1, 0.2, 0.3, 0.4, 0.5,0.6,0.7], color="k")
    ax.set_xlabel("Layer",fontsize=fs*labels_multiplier)
    ax.set_ylabel("Saturation",fontsize=fs*labels_multiplier)
    ax.xaxis.set_major_locator(ticker.MultipleLocator(3))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(1))

    # ax.set_yticks([-3, -2.5, -2, -1.5, -1], [-3, -2.5, -2, -1.5, -1], color="k")
    # ax.set_xticks([])
    # ax.tick_params(axis="x",color="w")
    ax.tick_params(axis="both", labelsize=fs * ticks_multiplier)
    plt.legend()
    # ax.legend()

    # Y axis

    # fig.text(-0.015, 0.5, '$\log($Saturation$)$', va='center', rotation="vertical", size=fs * labels_multiplier
    #          )
    #
    # # X axis
    # fig.text(0.5, -0.04, 'Layer', ha='center', size=fs * labels_multiplier)

    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/resnet25_small_imagenet_saturation_outblock_detailed_v2.pdf",
                bbox_inches="tight")
    # fig, axs = plt.subplots(1, 2, fig25_small_imagenet_detailed.pdf")
    plt.close()
def weights_resnet50_vgg19():

    cfg_resnet50 = omegaconf.DictConfig(
        {"architecture": "resnet50",
         "model_type": "alternative",
         # "model_type": "hub",
         "solution": "",
         # "solution": "trained_m
         "dataset": "cifar10",
         # "batch_size": 128,
         # "num_workers": args.num_workers,
         # "amount": args.pruning_rate,
         # "noise": "gaussian",
         # "sigma": 0.005,
         # "pruner": "global",
         # # "pruner": "lamp",
         # "exclude_layers": exclude_layers,
         # "data_path": args.data_folder,
         # "input_resolution": args.input_resolution
         })
    from main import get_model,get_layer_dict
    resnet50_net = get_model(cfg_resnet50)
    cfg_vgg = omegaconf.DictConfig(
        {"architecture": "vgg19",
         "model_type": "alternative",
         "solution": "",
         "dataset": "cifar10",
         # "batch_size": 128,
         # "num_workers": args.num_workers,
         # "amount": args.pruning_rate,
         # "noise": "gaussian",
         # "sigma": 0.005,
         # "pruner": "global",
         # # "pruner": "lamp",
         # "exclude_layers": exclude_layers,
         # "data_path": args.data_folder,
         # "input_resolution": args.input_resolution
         })
    vgg_net =   get_model(cfg_vgg)

    names_rs50,weights_rs50 = zip(*get_layer_dict(resnet50_net))
    names_vgg19,weights_vgg19 = zip(*get_layer_dict(vgg_net))
    count_f =lambda x: x.nelement()
    count_weights_rs50 = list(map(count_f,weights_rs50))
    count_weights_vgg  =  list(map(count_f,weights_vgg19))
    rs50_df  = pd.DataFrame({"layer_index":list(range(len(names_rs50))),"layer_name":names_rs50,"weight_count":count_weights_rs50})
    vgg19_df = pd.DataFrame({"layer_index":list(range(len(names_vgg19))),"layer_name":names_vgg19,"weight_count":count_weights_vgg})

    rs50_df['cumperc_inv'] = rs50_df['weight_count'].iloc[::-1].cumsum().values / rs50_df['weight_count'].sum() * 100
    vgg19_df['cumperc_inv'] = vgg19_df['weight_count'].iloc[::-1].cumsum().values / vgg19_df['weight_count'].sum() * 100
    rs50_df["totperc"] = rs50_df['weight_count'] / rs50_df['weight_count'].sum() * 100
    vgg19_df["totperc"] = vgg19_df['weight_count'] / vgg19_df['weight_count'].sum() * 100
    y1 = list(rs50_df['cumperc_inv'].values)
    y2 = list(vgg19_df['cumperc_inv'].values)

    y3 = list(rs50_df['totperc'].values)
    y4 = list(vgg19_df['totperc'].values)
    x1 = range(len(rs50_df['cumperc_inv'].values))
    x2 = range(len(vgg19_df['cumperc_inv'].values))
    #########  ResNet 50 ###################
    #### CUMSUM#####
    fig,ax =plt.subplots(1,1,figsize=fig_size,layout="compressed")
    ax.plot(x1,y1, color="salmon", marker="D", ms=3)
    ax.yaxis.set_major_formatter(PercentFormatter())
    ax.set_ylabel(r"Cumulative $\%$ of weights", fontsize=fs * labels_multiplier)
    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)
    ax.xaxis.set_major_locator(ticker.MultipleLocator(5))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(2))
    ax.tick_params(axis='both', labelsize=fs * ticks_multiplier)
    plt.grid(ls="--",alpha=0.5)
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/weights_pruned_resnet50_cumsum_inv.pdf")
    plt.close()
    #### total percentage#####

    fig,ax =plt.subplots(1,1,figsize=fig_size,layout="compressed")
    ax.bar(x1,y3, color="salmon")
    ax.set_ylabel(r"$\%$ of total weights", fontsize=fs * labels_multiplier)
    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)
    ax.xaxis.set_major_locator(ticker.MultipleLocator(5))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(2))
    ax.tick_params(axis='both', labelsize=fs * ticks_multiplier)
    plt.grid(ls="--",alpha=0.5)
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/weights_pruned_resnet50_totperc.pdf")
    plt.close()
    ####  VGG19  ###################
    #### CUMSUM#####
    fig,ax =plt.subplots(1,1,figsize=fig_size,layout="compressed")
    ax.plot(x2,y2, color="salmon", marker="D", ms=3)
    ax.yaxis.set_major_formatter(PercentFormatter())
    ax.set_ylabel(r"Cumulative $\%$ of weights", fontsize=fs * labels_multiplier)
    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)
    ax.xaxis.set_major_locator(ticker.MultipleLocator(2))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(1))
    ax.tick_params(axis='both', labelsize=fs * ticks_multiplier)
    plt.grid(ls="--",alpha=0.5)
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/weights_pruned_vgg19_cumsu_inv.pdf")
    plt.close()
    #### total percentage#####
    fig,ax =plt.subplots(1,1,figsize=fig_size,layout="compressed")
    ax.bar(x2,y4, color="salmon")
    ax.set_ylabel(r"$\%$ of total weights", fontsize=fs * labels_multiplier)
    ax.set_xlabel("Layer", fontsize=fs * labels_multiplier)
    ax.xaxis.set_major_locator(ticker.MultipleLocator(2))
    ax.xaxis.set_minor_locator(ticker.MultipleLocator(1))
    ax.tick_params(axis='both', labelsize=fs * ticks_multiplier)
    plt.grid(ls="--",alpha=0.5)
    plt.savefig("/home/luisaam/Documents/PhD/AA_ICCV_RF_2/figures/weights_pruned_vgg19_totperc.pdf")
    plt.close()
def plot_pareto(df, title: str):
    # define aesthetics for plot
    color1 = 'steelblue'
    color2 = 'red'
    line_size = 4
    fig, ax = plt.subplots()
    ax.bar(df.index, df['count'], color=color1)

    # add cumulative percentage line to plot
    ax2 = ax.twinx()
    ax2.plot(df.index, df['cumperc'], color=color2, marker="D", ms=line_size)
    ax2.yaxis.set_major_formatter(PercentFormatter())

    # specify axis colors
    ax.tick_params(axis='y', colors=color1)
    ax2.tick_params(axis='y', colors=color2)

    ax.tick_params(axis="x", labelrotation=90)
    ax2.tick_params(axis="x", labelrotation=90)
    plt.title(title, fontsize=20)
    # display Pareto chart
    plt.show()

#
# level8_seed0.sum(axis=1)
#


if __name__ == '__main__':
    # vgg19_cifar10_saturation()
    # resnet50_cifar10_saturation_different_rf()
    # resnet25_small_imagenet_saturation()
    # saturation_accuracy_plots()

    saturation_accuracy_resnet50_plots()

    saturation_accuracy_vgg19_plots()

    # probes_accuracy()
    # large_input_experiments()
    # large_input_experiments_only_sgd_paper()
    # weights_resnet50_vgg19()

